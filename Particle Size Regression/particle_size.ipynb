{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_regression import *\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n",
      "Epoch [1/200], Train Loss: 1.2602, Val Loss: 1.1800, Val R2: -0.1370, Val MAPE: 2.5052, Val RMSE: 144.4700, Val MAE: 132.8363, Val MSE: 20871.5801\n",
      "Epoch [2/200], Train Loss: 1.1395, Val Loss: 1.5611, Val R2: -0.5042, Val MAPE: 3.1643, Val RMSE: 166.1674, Val MAE: 153.8841, Val MSE: 27611.6211\n",
      "Epoch [3/200], Train Loss: 1.0655, Val Loss: 1.0543, Val R2: -0.0158, Val MAPE: 1.8844, Val RMSE: 136.5564, Val MAE: 118.3272, Val MSE: 18647.6367\n",
      "Epoch [4/200], Train Loss: 1.0082, Val Loss: 1.0442, Val R2: -0.0061, Val MAPE: 1.7110, Val RMSE: 135.9018, Val MAE: 114.6675, Val MSE: 18469.2988\n",
      "Epoch [5/200], Train Loss: 1.0038, Val Loss: 1.3572, Val R2: -0.3078, Val MAPE: 2.8413, Val RMSE: 154.9397, Val MAE: 143.1626, Val MSE: 24006.3203\n",
      "Epoch [6/200], Train Loss: 0.9560, Val Loss: 0.8423, Val R2: 0.1884, Val MAPE: 1.7164, Val RMSE: 122.0580, Val MAE: 106.7106, Val MSE: 14898.1602\n",
      "Epoch [7/200], Train Loss: 0.6098, Val Loss: 0.5088, Val R2: 0.5097, Val MAPE: 1.2682, Val RMSE: 94.8672, Val MAE: 81.1847, Val MSE: 8999.7773\n",
      "Epoch [8/200], Train Loss: 0.2884, Val Loss: 0.3841, Val R2: 0.6299, Val MAPE: 0.7578, Val RMSE: 82.4293, Val MAE: 64.1452, Val MSE: 6794.5884\n",
      "Epoch [9/200], Train Loss: 0.3350, Val Loss: 0.3478, Val R2: 0.6649, Val MAPE: 0.8499, Val RMSE: 78.4335, Val MAE: 68.2210, Val MSE: 6151.8096\n",
      "Epoch [10/200], Train Loss: 0.2615, Val Loss: 0.2823, Val R2: 0.7280, Val MAPE: 0.5082, Val RMSE: 70.6644, Val MAE: 46.8513, Val MSE: 4993.4624\n",
      "Epoch [11/200], Train Loss: 0.2266, Val Loss: 0.3484, Val R2: 0.6643, Val MAPE: 0.4072, Val RMSE: 78.4966, Val MAE: 43.7203, Val MSE: 6161.7231\n",
      "Epoch [12/200], Train Loss: 0.1946, Val Loss: 0.2547, Val R2: 0.7546, Val MAPE: 0.3384, Val RMSE: 67.1181, Val MAE: 36.0498, Val MSE: 4504.8457\n",
      "Epoch [13/200], Train Loss: 0.1350, Val Loss: 0.2286, Val R2: 0.7798, Val MAPE: 0.3857, Val RMSE: 63.5832, Val MAE: 34.5764, Val MSE: 4042.8264\n",
      "Epoch [14/200], Train Loss: 0.1320, Val Loss: 0.2534, Val R2: 0.7559, Val MAPE: 0.3245, Val RMSE: 66.9440, Val MAE: 37.9986, Val MSE: 4481.5024\n",
      "Epoch [15/200], Train Loss: 0.1427, Val Loss: 0.3106, Val R2: 0.7007, Val MAPE: 0.4623, Val RMSE: 74.1246, Val MAE: 49.2956, Val MSE: 5494.4512\n",
      "Epoch [16/200], Train Loss: 0.1521, Val Loss: 0.2532, Val R2: 0.7560, Val MAPE: 0.3363, Val RMSE: 66.9222, Val MAE: 40.6305, Val MSE: 4478.5854\n",
      "Epoch [17/200], Train Loss: 0.1328, Val Loss: 0.1168, Val R2: 0.8875, Val MAPE: 0.2181, Val RMSE: 45.4439, Val MAE: 24.0587, Val MSE: 2065.1470\n",
      "Epoch [18/200], Train Loss: 0.0614, Val Loss: 0.1033, Val R2: 0.9005, Val MAPE: 0.1814, Val RMSE: 42.7362, Val MAE: 22.3034, Val MSE: 1826.3812\n",
      "Epoch [19/200], Train Loss: 0.0508, Val Loss: 0.0569, Val R2: 0.9452, Val MAPE: 0.1387, Val RMSE: 31.7143, Val MAE: 16.0448, Val MSE: 1005.7960\n",
      "Epoch [20/200], Train Loss: 0.0589, Val Loss: 0.0534, Val R2: 0.9486, Val MAPE: 0.2090, Val RMSE: 30.7262, Val MAE: 20.7910, Val MSE: 944.0985\n",
      "Epoch [21/200], Train Loss: 0.0436, Val Loss: 0.0584, Val R2: 0.9438, Val MAPE: 0.3826, Val RMSE: 32.1272, Val MAE: 27.5321, Val MSE: 1032.1566\n",
      "Epoch [22/200], Train Loss: 0.0457, Val Loss: 0.0496, Val R2: 0.9522, Val MAPE: 0.2388, Val RMSE: 29.6305, Val MAE: 19.1451, Val MSE: 877.9649\n",
      "Epoch [23/200], Train Loss: 0.0322, Val Loss: 0.0508, Val R2: 0.9511, Val MAPE: 0.2527, Val RMSE: 29.9750, Val MAE: 20.1857, Val MSE: 898.4982\n",
      "Epoch [24/200], Train Loss: 0.0302, Val Loss: 0.0330, Val R2: 0.9682, Val MAPE: 0.1417, Val RMSE: 24.1466, Val MAE: 13.5651, Val MSE: 583.0588\n",
      "Epoch [25/200], Train Loss: 0.0326, Val Loss: 0.0416, Val R2: 0.9599, Val MAPE: 0.3605, Val RMSE: 27.1262, Val MAE: 22.4964, Val MSE: 735.8329\n",
      "Epoch [26/200], Train Loss: 0.0339, Val Loss: 0.0320, Val R2: 0.9692, Val MAPE: 0.1723, Val RMSE: 23.7749, Val MAE: 16.8946, Val MSE: 565.2446\n",
      "Epoch [27/200], Train Loss: 0.0437, Val Loss: 0.0278, Val R2: 0.9732, Val MAPE: 0.1505, Val RMSE: 22.1664, Val MAE: 13.6870, Val MSE: 491.3480\n",
      "Epoch [28/200], Train Loss: 0.0339, Val Loss: 0.0402, Val R2: 0.9612, Val MAPE: 0.3470, Val RMSE: 26.6762, Val MAE: 22.8267, Val MSE: 711.6191\n",
      "Epoch [29/200], Train Loss: 0.0405, Val Loss: 0.0458, Val R2: 0.9559, Val MAPE: 0.3785, Val RMSE: 28.4517, Val MAE: 25.4796, Val MSE: 809.4964\n",
      "Epoch [30/200], Train Loss: 0.0595, Val Loss: 0.0489, Val R2: 0.9529, Val MAPE: 0.2284, Val RMSE: 29.4063, Val MAE: 22.1671, Val MSE: 864.7319\n",
      "Epoch [31/200], Train Loss: 0.0658, Val Loss: 0.0615, Val R2: 0.9407, Val MAPE: 0.4682, Val RMSE: 32.9931, Val MAE: 29.4147, Val MSE: 1088.5441\n",
      "Epoch [32/200], Train Loss: 0.0410, Val Loss: 0.0290, Val R2: 0.9720, Val MAPE: 0.1789, Val RMSE: 22.6667, Val MAE: 13.3533, Val MSE: 513.7800\n",
      "Epoch [33/200], Train Loss: 0.0240, Val Loss: 0.0369, Val R2: 0.9644, Val MAPE: 0.1835, Val RMSE: 25.5646, Val MAE: 16.3626, Val MSE: 653.5472\n",
      "Epoch [34/200], Train Loss: 0.0233, Val Loss: 0.0246, Val R2: 0.9763, Val MAPE: 0.2702, Val RMSE: 20.8629, Val MAE: 15.2701, Val MSE: 435.2605\n",
      "Epoch [35/200], Train Loss: 0.0190, Val Loss: 0.0207, Val R2: 0.9800, Val MAPE: 0.1300, Val RMSE: 19.1562, Val MAE: 11.0087, Val MSE: 366.9596\n",
      "Epoch [36/200], Train Loss: 0.0211, Val Loss: 0.0185, Val R2: 0.9822, Val MAPE: 0.1617, Val RMSE: 18.0819, Val MAE: 10.7697, Val MSE: 326.9537\n",
      "Epoch [37/200], Train Loss: 0.0228, Val Loss: 0.0260, Val R2: 0.9750, Val MAPE: 0.1700, Val RMSE: 21.4420, Val MAE: 12.9524, Val MSE: 459.7606\n",
      "Epoch [38/200], Train Loss: 0.0200, Val Loss: 0.0222, Val R2: 0.9786, Val MAPE: 0.1985, Val RMSE: 19.7992, Val MAE: 12.8604, Val MSE: 392.0075\n",
      "Epoch [39/200], Train Loss: 0.0192, Val Loss: 0.0318, Val R2: 0.9694, Val MAPE: 0.2133, Val RMSE: 23.7120, Val MAE: 15.9530, Val MSE: 562.2599\n",
      "Epoch [40/200], Train Loss: 0.0134, Val Loss: 0.0169, Val R2: 0.9838, Val MAPE: 0.1575, Val RMSE: 17.2700, Val MAE: 11.3129, Val MSE: 298.2536\n",
      "Epoch [41/200], Train Loss: 0.0135, Val Loss: 0.0243, Val R2: 0.9765, Val MAPE: 0.1222, Val RMSE: 20.7523, Val MAE: 11.7907, Val MSE: 430.6575\n",
      "Epoch [42/200], Train Loss: 0.0125, Val Loss: 0.0200, Val R2: 0.9808, Val MAPE: 0.1917, Val RMSE: 18.7946, Val MAE: 12.3430, Val MSE: 353.2352\n",
      "Epoch [43/200], Train Loss: 0.0119, Val Loss: 0.0152, Val R2: 0.9853, Val MAPE: 0.1226, Val RMSE: 16.4212, Val MAE: 9.8602, Val MSE: 269.6554\n",
      "Epoch [44/200], Train Loss: 0.0120, Val Loss: 0.0122, Val R2: 0.9882, Val MAPE: 0.1290, Val RMSE: 14.7057, Val MAE: 8.9633, Val MSE: 216.2569\n",
      "Epoch [45/200], Train Loss: 0.0154, Val Loss: 0.0220, Val R2: 0.9788, Val MAPE: 0.2904, Val RMSE: 19.7383, Val MAE: 16.8691, Val MSE: 389.6003\n",
      "Epoch [46/200], Train Loss: 0.0165, Val Loss: 0.0211, Val R2: 0.9797, Val MAPE: 0.2066, Val RMSE: 19.3085, Val MAE: 14.3220, Val MSE: 372.8175\n",
      "Epoch [47/200], Train Loss: 0.0204, Val Loss: 0.0200, Val R2: 0.9807, Val MAPE: 0.2521, Val RMSE: 18.8211, Val MAE: 14.7550, Val MSE: 354.2328\n",
      "Epoch [48/200], Train Loss: 0.0144, Val Loss: 0.0198, Val R2: 0.9809, Val MAPE: 0.2834, Val RMSE: 18.7022, Val MAE: 14.3285, Val MSE: 349.7705\n",
      "Epoch [49/200], Train Loss: 0.0116, Val Loss: 0.0104, Val R2: 0.9900, Val MAPE: 0.1135, Val RMSE: 13.5816, Val MAE: 8.1599, Val MSE: 184.4587\n",
      "Epoch [50/200], Train Loss: 0.0085, Val Loss: 0.0126, Val R2: 0.9879, Val MAPE: 0.1308, Val RMSE: 14.9131, Val MAE: 9.0920, Val MSE: 222.4008\n",
      "Epoch [51/200], Train Loss: 0.0084, Val Loss: 0.0121, Val R2: 0.9883, Val MAPE: 0.1844, Val RMSE: 14.6255, Val MAE: 9.8024, Val MSE: 213.9046\n",
      "Epoch [52/200], Train Loss: 0.0077, Val Loss: 0.0102, Val R2: 0.9902, Val MAPE: 0.1272, Val RMSE: 13.3995, Val MAE: 7.8470, Val MSE: 179.5464\n",
      "Epoch [53/200], Train Loss: 0.0065, Val Loss: 0.0089, Val R2: 0.9914, Val MAPE: 0.1147, Val RMSE: 12.5728, Val MAE: 7.6819, Val MSE: 158.0758\n",
      "Epoch [54/200], Train Loss: 0.0060, Val Loss: 0.0106, Val R2: 0.9898, Val MAPE: 0.1568, Val RMSE: 13.7028, Val MAE: 9.8187, Val MSE: 187.7680\n",
      "Epoch [55/200], Train Loss: 0.0082, Val Loss: 0.0111, Val R2: 0.9893, Val MAPE: 0.1689, Val RMSE: 14.0194, Val MAE: 10.3898, Val MSE: 196.5448\n",
      "Epoch [56/200], Train Loss: 0.0103, Val Loss: 0.0110, Val R2: 0.9894, Val MAPE: 0.1353, Val RMSE: 13.9781, Val MAE: 9.7218, Val MSE: 195.3862\n",
      "Epoch [57/200], Train Loss: 0.0153, Val Loss: 0.0193, Val R2: 0.9814, Val MAPE: 0.2861, Val RMSE: 18.4870, Val MAE: 15.7255, Val MSE: 341.7701\n",
      "Epoch [58/200], Train Loss: 0.0136, Val Loss: 0.0130, Val R2: 0.9875, Val MAPE: 0.1767, Val RMSE: 15.1422, Val MAE: 10.4410, Val MSE: 229.2848\n",
      "Epoch [59/200], Train Loss: 0.0127, Val Loss: 0.0179, Val R2: 0.9827, Val MAPE: 0.1261, Val RMSE: 17.8069, Val MAE: 10.5367, Val MSE: 317.0871\n",
      "Epoch [60/200], Train Loss: 0.0098, Val Loss: 0.0172, Val R2: 0.9835, Val MAPE: 0.1335, Val RMSE: 17.4258, Val MAE: 10.5800, Val MSE: 303.6583\n",
      "Epoch [61/200], Train Loss: 0.0102, Val Loss: 0.0219, Val R2: 0.9789, Val MAPE: 0.1680, Val RMSE: 19.6777, Val MAE: 13.6760, Val MSE: 387.2122\n",
      "Epoch [62/200], Train Loss: 0.0123, Val Loss: 0.0124, Val R2: 0.9881, Val MAPE: 0.1545, Val RMSE: 14.8028, Val MAE: 9.0666, Val MSE: 219.1237\n",
      "Epoch [63/200], Train Loss: 0.0125, Val Loss: 0.0092, Val R2: 0.9911, Val MAPE: 0.1417, Val RMSE: 12.7506, Val MAE: 9.2702, Val MSE: 162.5768\n",
      "Epoch [64/200], Train Loss: 0.0136, Val Loss: 0.0120, Val R2: 0.9884, Val MAPE: 0.1399, Val RMSE: 14.5811, Val MAE: 9.9863, Val MSE: 212.6072\n",
      "Epoch [65/200], Train Loss: 0.0145, Val Loss: 0.0122, Val R2: 0.9882, Val MAPE: 0.1784, Val RMSE: 14.7038, Val MAE: 10.5668, Val MSE: 216.2016\n",
      "Epoch [66/200], Train Loss: 0.0085, Val Loss: 0.0121, Val R2: 0.9884, Val MAPE: 0.1639, Val RMSE: 14.6090, Val MAE: 10.1658, Val MSE: 213.4224\n",
      "Epoch [67/200], Train Loss: 0.0054, Val Loss: 0.0094, Val R2: 0.9909, Val MAPE: 0.1279, Val RMSE: 12.8898, Val MAE: 8.8618, Val MSE: 166.1472\n",
      "Epoch [68/200], Train Loss: 0.0054, Val Loss: 0.0118, Val R2: 0.9886, Val MAPE: 0.1343, Val RMSE: 14.4722, Val MAE: 8.9413, Val MSE: 209.4436\n",
      "Epoch [69/200], Train Loss: 0.0060, Val Loss: 0.0147, Val R2: 0.9858, Val MAPE: 0.1324, Val RMSE: 16.1231, Val MAE: 10.8350, Val MSE: 259.9533\n",
      "Epoch [70/200], Train Loss: 0.0068, Val Loss: 0.0083, Val R2: 0.9920, Val MAPE: 0.1337, Val RMSE: 12.1272, Val MAE: 7.8564, Val MSE: 147.0686\n",
      "Epoch [71/200], Train Loss: 0.0053, Val Loss: 0.0112, Val R2: 0.9893, Val MAPE: 0.2015, Val RMSE: 14.0467, Val MAE: 11.2358, Val MSE: 197.3108\n",
      "Epoch [72/200], Train Loss: 0.0065, Val Loss: 0.0075, Val R2: 0.9928, Val MAPE: 0.1206, Val RMSE: 11.5195, Val MAE: 7.5505, Val MSE: 132.6994\n",
      "Epoch [73/200], Train Loss: 0.0046, Val Loss: 0.0089, Val R2: 0.9914, Val MAPE: 0.1168, Val RMSE: 12.5502, Val MAE: 8.4900, Val MSE: 157.5085\n",
      "Epoch [74/200], Train Loss: 0.0047, Val Loss: 0.0132, Val R2: 0.9873, Val MAPE: 0.1510, Val RMSE: 15.2632, Val MAE: 9.6653, Val MSE: 232.9641\n",
      "Epoch [75/200], Train Loss: 0.0058, Val Loss: 0.0091, Val R2: 0.9912, Val MAPE: 0.1293, Val RMSE: 12.7189, Val MAE: 9.1335, Val MSE: 161.7693\n",
      "Epoch [76/200], Train Loss: 0.0051, Val Loss: 0.0088, Val R2: 0.9915, Val MAPE: 0.1487, Val RMSE: 12.4688, Val MAE: 9.3564, Val MSE: 155.4715\n",
      "Epoch [77/200], Train Loss: 0.0059, Val Loss: 0.0090, Val R2: 0.9913, Val MAPE: 0.1619, Val RMSE: 12.6184, Val MAE: 9.3584, Val MSE: 159.2228\n",
      "Epoch [78/200], Train Loss: 0.0054, Val Loss: 0.0092, Val R2: 0.9912, Val MAPE: 0.1151, Val RMSE: 12.7409, Val MAE: 8.3359, Val MSE: 162.3299\n",
      "Epoch [79/200], Train Loss: 0.0041, Val Loss: 0.0105, Val R2: 0.9899, Val MAPE: 0.1268, Val RMSE: 13.6445, Val MAE: 8.8225, Val MSE: 186.1735\n",
      "Epoch [80/200], Train Loss: 0.0051, Val Loss: 0.0082, Val R2: 0.9921, Val MAPE: 0.1152, Val RMSE: 12.0415, Val MAE: 7.5759, Val MSE: 144.9971\n",
      "Epoch [81/200], Train Loss: 0.0032, Val Loss: 0.0068, Val R2: 0.9935, Val MAPE: 0.1276, Val RMSE: 10.9321, Val MAE: 7.7854, Val MSE: 119.5111\n",
      "Epoch [82/200], Train Loss: 0.0036, Val Loss: 0.0066, Val R2: 0.9936, Val MAPE: 0.1245, Val RMSE: 10.8229, Val MAE: 7.2951, Val MSE: 117.1360\n",
      "Epoch [83/200], Train Loss: 0.0029, Val Loss: 0.0074, Val R2: 0.9929, Val MAPE: 0.1389, Val RMSE: 11.4069, Val MAE: 7.9247, Val MSE: 130.1178\n",
      "Epoch [84/200], Train Loss: 0.0027, Val Loss: 0.0070, Val R2: 0.9933, Val MAPE: 0.1238, Val RMSE: 11.1303, Val MAE: 7.3101, Val MSE: 123.8832\n",
      "Epoch [85/200], Train Loss: 0.0025, Val Loss: 0.0067, Val R2: 0.9936, Val MAPE: 0.1112, Val RMSE: 10.8672, Val MAE: 7.2572, Val MSE: 118.0957\n",
      "Epoch [86/200], Train Loss: 0.0024, Val Loss: 0.0063, Val R2: 0.9939, Val MAPE: 0.1197, Val RMSE: 10.5769, Val MAE: 7.2554, Val MSE: 111.8717\n",
      "Epoch [87/200], Train Loss: 0.0032, Val Loss: 0.0070, Val R2: 0.9932, Val MAPE: 0.1349, Val RMSE: 11.1561, Val MAE: 7.8513, Val MSE: 124.4589\n",
      "Epoch [88/200], Train Loss: 0.0031, Val Loss: 0.0076, Val R2: 0.9926, Val MAPE: 0.1176, Val RMSE: 11.6277, Val MAE: 7.3820, Val MSE: 135.2038\n",
      "Epoch [89/200], Train Loss: 0.0025, Val Loss: 0.0074, Val R2: 0.9929, Val MAPE: 0.1217, Val RMSE: 11.4104, Val MAE: 7.9202, Val MSE: 130.1982\n",
      "Epoch [90/200], Train Loss: 0.0028, Val Loss: 0.0080, Val R2: 0.9923, Val MAPE: 0.1258, Val RMSE: 11.9138, Val MAE: 7.7077, Val MSE: 141.9395\n",
      "Epoch [91/200], Train Loss: 0.0029, Val Loss: 0.0063, Val R2: 0.9940, Val MAPE: 0.1243, Val RMSE: 10.5301, Val MAE: 7.7214, Val MSE: 110.8826\n",
      "Epoch [92/200], Train Loss: 0.0023, Val Loss: 0.0061, Val R2: 0.9941, Val MAPE: 0.1231, Val RMSE: 10.3874, Val MAE: 7.3837, Val MSE: 107.8979\n",
      "Epoch [93/200], Train Loss: 0.0019, Val Loss: 0.0069, Val R2: 0.9933, Val MAPE: 0.1158, Val RMSE: 11.0676, Val MAE: 7.2201, Val MSE: 122.4911\n",
      "Epoch [94/200], Train Loss: 0.0022, Val Loss: 0.0059, Val R2: 0.9943, Val MAPE: 0.1208, Val RMSE: 10.2124, Val MAE: 7.4134, Val MSE: 104.2929\n",
      "Epoch [95/200], Train Loss: 0.0022, Val Loss: 0.0067, Val R2: 0.9936, Val MAPE: 0.1345, Val RMSE: 10.8802, Val MAE: 7.6191, Val MSE: 118.3789\n",
      "Epoch [96/200], Train Loss: 0.0022, Val Loss: 0.0071, Val R2: 0.9932, Val MAPE: 0.1122, Val RMSE: 11.2102, Val MAE: 7.9276, Val MSE: 125.6676\n",
      "Epoch [97/200], Train Loss: 0.0022, Val Loss: 0.0067, Val R2: 0.9935, Val MAPE: 0.1441, Val RMSE: 10.9012, Val MAE: 8.1304, Val MSE: 118.8360\n",
      "Epoch [98/200], Train Loss: 0.0023, Val Loss: 0.0060, Val R2: 0.9943, Val MAPE: 0.1143, Val RMSE: 10.2720, Val MAE: 7.9026, Val MSE: 105.5144\n",
      "Epoch [99/200], Train Loss: 0.0027, Val Loss: 0.0073, Val R2: 0.9930, Val MAPE: 0.1264, Val RMSE: 11.3464, Val MAE: 7.4875, Val MSE: 128.7409\n",
      "Epoch [100/200], Train Loss: 0.0029, Val Loss: 0.0070, Val R2: 0.9933, Val MAPE: 0.1153, Val RMSE: 11.1103, Val MAE: 7.9008, Val MSE: 123.4382\n",
      "Epoch [101/200], Train Loss: 0.0027, Val Loss: 0.0056, Val R2: 0.9946, Val MAPE: 0.1166, Val RMSE: 9.9334, Val MAE: 7.4605, Val MSE: 98.6723\n",
      "Epoch [102/200], Train Loss: 0.0025, Val Loss: 0.0063, Val R2: 0.9939, Val MAPE: 0.1307, Val RMSE: 10.5421, Val MAE: 7.6687, Val MSE: 111.1350\n",
      "Epoch [103/200], Train Loss: 0.0021, Val Loss: 0.0071, Val R2: 0.9932, Val MAPE: 0.1250, Val RMSE: 11.1792, Val MAE: 7.9250, Val MSE: 124.9735\n",
      "Epoch [104/200], Train Loss: 0.0020, Val Loss: 0.0057, Val R2: 0.9945, Val MAPE: 0.1214, Val RMSE: 10.0303, Val MAE: 7.0195, Val MSE: 100.6068\n",
      "Epoch [105/200], Train Loss: 0.0015, Val Loss: 0.0052, Val R2: 0.9950, Val MAPE: 0.1071, Val RMSE: 9.6012, Val MAE: 6.6424, Val MSE: 92.1828\n",
      "Epoch [106/200], Train Loss: 0.0015, Val Loss: 0.0057, Val R2: 0.9945, Val MAPE: 0.1073, Val RMSE: 10.0224, Val MAE: 6.8853, Val MSE: 100.4483\n",
      "Epoch [107/200], Train Loss: 0.0014, Val Loss: 0.0064, Val R2: 0.9938, Val MAPE: 0.1279, Val RMSE: 10.6504, Val MAE: 7.3570, Val MSE: 113.4313\n",
      "Epoch [108/200], Train Loss: 0.0014, Val Loss: 0.0056, Val R2: 0.9946, Val MAPE: 0.1113, Val RMSE: 9.9899, Val MAE: 7.0559, Val MSE: 99.7991\n",
      "Epoch [109/200], Train Loss: 0.0014, Val Loss: 0.0065, Val R2: 0.9937, Val MAPE: 0.1154, Val RMSE: 10.7165, Val MAE: 7.0621, Val MSE: 114.8443\n",
      "Epoch [110/200], Train Loss: 0.0014, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1103, Val RMSE: 9.8145, Val MAE: 7.0158, Val MSE: 96.3248\n",
      "Epoch [111/200], Train Loss: 0.0014, Val Loss: 0.0061, Val R2: 0.9942, Val MAPE: 0.1300, Val RMSE: 10.3450, Val MAE: 7.3257, Val MSE: 107.0194\n",
      "Epoch [112/200], Train Loss: 0.0013, Val Loss: 0.0057, Val R2: 0.9945, Val MAPE: 0.1136, Val RMSE: 10.0246, Val MAE: 7.1513, Val MSE: 100.4926\n",
      "Epoch [113/200], Train Loss: 0.0014, Val Loss: 0.0059, Val R2: 0.9943, Val MAPE: 0.1226, Val RMSE: 10.1992, Val MAE: 7.2206, Val MSE: 104.0239\n",
      "Epoch [114/200], Train Loss: 0.0013, Val Loss: 0.0055, Val R2: 0.9947, Val MAPE: 0.1046, Val RMSE: 9.8967, Val MAE: 6.7221, Val MSE: 97.9437\n",
      "Epoch [115/200], Train Loss: 0.0013, Val Loss: 0.0058, Val R2: 0.9944, Val MAPE: 0.1206, Val RMSE: 10.1657, Val MAE: 7.0413, Val MSE: 103.3412\n",
      "Epoch [116/200], Train Loss: 0.0012, Val Loss: 0.0053, Val R2: 0.9949, Val MAPE: 0.1095, Val RMSE: 9.7018, Val MAE: 6.7287, Val MSE: 94.1246\n",
      "Epoch [117/200], Train Loss: 0.0012, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1065, Val RMSE: 9.8070, Val MAE: 6.6564, Val MSE: 96.1776\n",
      "Epoch [118/200], Train Loss: 0.0012, Val Loss: 0.0055, Val R2: 0.9947, Val MAPE: 0.1092, Val RMSE: 9.8679, Val MAE: 6.7548, Val MSE: 97.3753\n",
      "Epoch [119/200], Train Loss: 0.0011, Val Loss: 0.0053, Val R2: 0.9949, Val MAPE: 0.1146, Val RMSE: 9.7135, Val MAE: 6.8212, Val MSE: 94.3525\n",
      "Epoch [120/200], Train Loss: 0.0011, Val Loss: 0.0058, Val R2: 0.9944, Val MAPE: 0.1131, Val RMSE: 10.1549, Val MAE: 7.0170, Val MSE: 103.1217\n",
      "Epoch [121/200], Train Loss: 0.0010, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1076, Val RMSE: 9.5103, Val MAE: 6.7051, Val MSE: 90.4454\n",
      "Epoch [122/200], Train Loss: 0.0011, Val Loss: 0.0055, Val R2: 0.9947, Val MAPE: 0.1073, Val RMSE: 9.8992, Val MAE: 6.6772, Val MSE: 97.9933\n",
      "Epoch [123/200], Train Loss: 0.0012, Val Loss: 0.0053, Val R2: 0.9948, Val MAPE: 0.1157, Val RMSE: 9.7276, Val MAE: 6.9419, Val MSE: 94.6268\n",
      "Epoch [124/200], Train Loss: 0.0012, Val Loss: 0.0053, Val R2: 0.9949, Val MAPE: 0.1061, Val RMSE: 9.6759, Val MAE: 6.5931, Val MSE: 93.6239\n",
      "Epoch [125/200], Train Loss: 0.0011, Val Loss: 0.0052, Val R2: 0.9950, Val MAPE: 0.1192, Val RMSE: 9.6063, Val MAE: 6.9829, Val MSE: 92.2804\n",
      "Epoch [126/200], Train Loss: 0.0011, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1020, Val RMSE: 9.7703, Val MAE: 6.8213, Val MSE: 95.4588\n",
      "Epoch [127/200], Train Loss: 0.0010, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1082, Val RMSE: 9.7937, Val MAE: 6.7246, Val MSE: 95.9165\n",
      "Epoch [128/200], Train Loss: 0.0010, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1110, Val RMSE: 9.7963, Val MAE: 6.7838, Val MSE: 95.9668\n",
      "Epoch [129/200], Train Loss: 0.0009, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1100, Val RMSE: 9.7374, Val MAE: 6.8522, Val MSE: 94.8172\n",
      "Epoch [130/200], Train Loss: 0.0010, Val Loss: 0.0053, Val R2: 0.9949, Val MAPE: 0.1164, Val RMSE: 9.7102, Val MAE: 6.8335, Val MSE: 94.2873\n",
      "Epoch [131/200], Train Loss: 0.0009, Val Loss: 0.0052, Val R2: 0.9950, Val MAPE: 0.1045, Val RMSE: 9.6190, Val MAE: 6.5744, Val MSE: 92.5246\n",
      "Epoch [132/200], Train Loss: 0.0009, Val Loss: 0.0052, Val R2: 0.9949, Val MAPE: 0.1062, Val RMSE: 9.6293, Val MAE: 6.7932, Val MSE: 92.7237\n",
      "Epoch [133/200], Train Loss: 0.0009, Val Loss: 0.0057, Val R2: 0.9945, Val MAPE: 0.1177, Val RMSE: 10.0538, Val MAE: 7.0276, Val MSE: 101.0790\n",
      "Epoch [134/200], Train Loss: 0.0010, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1092, Val RMSE: 9.5155, Val MAE: 6.6948, Val MSE: 90.5441\n",
      "Epoch [135/200], Train Loss: 0.0010, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1086, Val RMSE: 9.5243, Val MAE: 6.7054, Val MSE: 90.7124\n",
      "Epoch [136/200], Train Loss: 0.0011, Val Loss: 0.0055, Val R2: 0.9947, Val MAPE: 0.1139, Val RMSE: 9.9062, Val MAE: 6.8454, Val MSE: 98.1323\n",
      "Epoch [137/200], Train Loss: 0.0009, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1061, Val RMSE: 9.2848, Val MAE: 6.6254, Val MSE: 86.2068\n",
      "Epoch [138/200], Train Loss: 0.0010, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1028, Val RMSE: 9.5213, Val MAE: 6.5451, Val MSE: 90.6552\n",
      "Epoch [139/200], Train Loss: 0.0008, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1231, Val RMSE: 9.7519, Val MAE: 6.9816, Val MSE: 95.1000\n",
      "Epoch [140/200], Train Loss: 0.0008, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1025, Val RMSE: 9.5034, Val MAE: 6.4628, Val MSE: 90.3152\n",
      "Epoch [141/200], Train Loss: 0.0009, Val Loss: 0.0050, Val R2: 0.9951, Val MAPE: 0.1046, Val RMSE: 9.4443, Val MAE: 6.5913, Val MSE: 89.1943\n",
      "Epoch [142/200], Train Loss: 0.0010, Val Loss: 0.0054, Val R2: 0.9948, Val MAPE: 0.1166, Val RMSE: 9.7971, Val MAE: 6.9552, Val MSE: 95.9834\n",
      "Epoch [143/200], Train Loss: 0.0010, Val Loss: 0.0055, Val R2: 0.9947, Val MAPE: 0.1028, Val RMSE: 9.8391, Val MAE: 6.6562, Val MSE: 96.8080\n",
      "Epoch [144/200], Train Loss: 0.0008, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1116, Val RMSE: 9.3794, Val MAE: 6.7273, Val MSE: 87.9737\n",
      "Epoch [145/200], Train Loss: 0.0008, Val Loss: 0.0053, Val R2: 0.9949, Val MAPE: 0.1128, Val RMSE: 9.6823, Val MAE: 6.7428, Val MSE: 93.7473\n",
      "Epoch [146/200], Train Loss: 0.0008, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1092, Val RMSE: 9.5213, Val MAE: 6.6186, Val MSE: 90.6544\n",
      "Epoch [147/200], Train Loss: 0.0009, Val Loss: 0.0048, Val R2: 0.9954, Val MAPE: 0.1041, Val RMSE: 9.1959, Val MAE: 6.4879, Val MSE: 84.5651\n",
      "Epoch [148/200], Train Loss: 0.0008, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1015, Val RMSE: 9.4576, Val MAE: 6.4599, Val MSE: 89.4461\n",
      "Epoch [149/200], Train Loss: 0.0008, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1091, Val RMSE: 9.4730, Val MAE: 6.6315, Val MSE: 89.7374\n",
      "Epoch [150/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1084, Val RMSE: 9.3544, Val MAE: 6.6207, Val MSE: 87.5054\n",
      "Epoch [151/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1084, Val RMSE: 9.4279, Val MAE: 6.6442, Val MSE: 88.8855\n",
      "Epoch [152/200], Train Loss: 0.0008, Val Loss: 0.0053, Val R2: 0.9948, Val MAPE: 0.1094, Val RMSE: 9.7260, Val MAE: 6.7272, Val MSE: 94.5950\n",
      "Epoch [153/200], Train Loss: 0.0008, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1108, Val RMSE: 9.5207, Val MAE: 6.7054, Val MSE: 90.6436\n",
      "Epoch [154/200], Train Loss: 0.0008, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1036, Val RMSE: 9.3746, Val MAE: 6.5419, Val MSE: 87.8833\n",
      "Epoch [155/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1035, Val RMSE: 9.4304, Val MAE: 6.5505, Val MSE: 88.9316\n",
      "Epoch [156/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9951, Val MAPE: 0.1090, Val RMSE: 9.4472, Val MAE: 6.6276, Val MSE: 89.2491\n",
      "Epoch [157/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1092, Val RMSE: 9.2950, Val MAE: 6.6024, Val MSE: 86.3972\n",
      "Epoch [158/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1048, Val RMSE: 9.2784, Val MAE: 6.4727, Val MSE: 86.0880\n",
      "Epoch [159/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1071, Val RMSE: 9.4001, Val MAE: 6.5478, Val MSE: 88.3627\n",
      "Epoch [160/200], Train Loss: 0.0006, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1114, Val RMSE: 9.5311, Val MAE: 6.6732, Val MSE: 90.8425\n",
      "Epoch [161/200], Train Loss: 0.0008, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1124, Val RMSE: 9.4995, Val MAE: 6.7106, Val MSE: 90.2407\n",
      "Epoch [162/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1050, Val RMSE: 9.3516, Val MAE: 6.5246, Val MSE: 87.4519\n",
      "Epoch [163/200], Train Loss: 0.0006, Val Loss: 0.0048, Val R2: 0.9953, Val MAPE: 0.1017, Val RMSE: 9.2520, Val MAE: 6.4099, Val MSE: 85.6002\n",
      "Epoch [164/200], Train Loss: 0.0008, Val Loss: 0.0048, Val R2: 0.9953, Val MAPE: 0.1061, Val RMSE: 9.2577, Val MAE: 6.4900, Val MSE: 85.7048\n",
      "Epoch [165/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1103, Val RMSE: 9.3626, Val MAE: 6.6172, Val MSE: 87.6573\n",
      "Epoch [166/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1090, Val RMSE: 9.3529, Val MAE: 6.5943, Val MSE: 87.4774\n",
      "Epoch [167/200], Train Loss: 0.0006, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1063, Val RMSE: 9.3578, Val MAE: 6.5580, Val MSE: 87.5691\n",
      "Epoch [168/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1048, Val RMSE: 9.3282, Val MAE: 6.5088, Val MSE: 87.0162\n",
      "Epoch [169/200], Train Loss: 0.0007, Val Loss: 0.0048, Val R2: 0.9954, Val MAPE: 0.1059, Val RMSE: 9.2357, Val MAE: 6.4992, Val MSE: 85.2984\n",
      "Epoch [170/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1075, Val RMSE: 9.2799, Val MAE: 6.5395, Val MSE: 86.1164\n",
      "Epoch [171/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1076, Val RMSE: 9.3475, Val MAE: 6.5549, Val MSE: 87.3762\n",
      "Epoch [172/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1069, Val RMSE: 9.4252, Val MAE: 6.5656, Val MSE: 88.8342\n",
      "Epoch [173/200], Train Loss: 0.0006, Val Loss: 0.0051, Val R2: 0.9951, Val MAPE: 0.1067, Val RMSE: 9.4614, Val MAE: 6.5789, Val MSE: 89.5172\n",
      "Epoch [174/200], Train Loss: 0.0006, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1072, Val RMSE: 9.4151, Val MAE: 6.5722, Val MSE: 88.6441\n",
      "Epoch [175/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1077, Val RMSE: 9.3512, Val MAE: 6.5635, Val MSE: 87.4449\n",
      "Epoch [176/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1082, Val RMSE: 9.3573, Val MAE: 6.5706, Val MSE: 87.5586\n",
      "Epoch [177/200], Train Loss: 0.0006, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1083, Val RMSE: 9.3673, Val MAE: 6.5688, Val MSE: 87.7461\n",
      "Epoch [178/200], Train Loss: 0.0006, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1081, Val RMSE: 9.3760, Val MAE: 6.5641, Val MSE: 87.9099\n",
      "Epoch [179/200], Train Loss: 0.0006, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1087, Val RMSE: 9.3961, Val MAE: 6.5787, Val MSE: 88.2874\n",
      "Epoch [180/200], Train Loss: 0.0006, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1083, Val RMSE: 9.4040, Val MAE: 6.5714, Val MSE: 88.4358\n",
      "Epoch [181/200], Train Loss: 0.0007, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1079, Val RMSE: 9.3813, Val MAE: 6.5631, Val MSE: 88.0079\n",
      "Epoch [182/200], Train Loss: 0.0006, Val Loss: 0.0050, Val R2: 0.9952, Val MAPE: 0.1077, Val RMSE: 9.3607, Val MAE: 6.5603, Val MSE: 87.6232\n",
      "Epoch [183/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1072, Val RMSE: 9.3417, Val MAE: 6.5527, Val MSE: 87.2671\n",
      "Epoch [184/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1069, Val RMSE: 9.3286, Val MAE: 6.5485, Val MSE: 87.0234\n",
      "Epoch [185/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1068, Val RMSE: 9.3297, Val MAE: 6.5478, Val MSE: 87.0440\n",
      "Epoch [186/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1067, Val RMSE: 9.3270, Val MAE: 6.5445, Val MSE: 86.9931\n",
      "Epoch [187/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1067, Val RMSE: 9.3211, Val MAE: 6.5412, Val MSE: 86.8834\n",
      "Epoch [188/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1067, Val RMSE: 9.3195, Val MAE: 6.5412, Val MSE: 86.8526\n",
      "Epoch [189/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1068, Val RMSE: 9.3221, Val MAE: 6.5427, Val MSE: 86.9019\n",
      "Epoch [190/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1070, Val RMSE: 9.3251, Val MAE: 6.5477, Val MSE: 86.9576\n",
      "Epoch [191/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1071, Val RMSE: 9.3310, Val MAE: 6.5500, Val MSE: 87.0684\n",
      "Epoch [192/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9953, Val MAPE: 0.1072, Val RMSE: 9.3362, Val MAE: 6.5524, Val MSE: 87.1655\n",
      "Epoch [193/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1073, Val RMSE: 9.3378, Val MAE: 6.5545, Val MSE: 87.1951\n",
      "Epoch [194/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1074, Val RMSE: 9.3405, Val MAE: 6.5565, Val MSE: 87.2451\n",
      "Epoch [195/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1075, Val RMSE: 9.3407, Val MAE: 6.5574, Val MSE: 87.2478\n",
      "Epoch [196/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1075, Val RMSE: 9.3402, Val MAE: 6.5578, Val MSE: 87.2401\n",
      "Epoch [197/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1075, Val RMSE: 9.3397, Val MAE: 6.5580, Val MSE: 87.2303\n",
      "Epoch [198/200], Train Loss: 0.0007, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1075, Val RMSE: 9.3399, Val MAE: 6.5583, Val MSE: 87.2331\n",
      "Epoch [199/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1075, Val RMSE: 9.3398, Val MAE: 6.5583, Val MSE: 87.2323\n",
      "Epoch [200/200], Train Loss: 0.0006, Val Loss: 0.0049, Val R2: 0.9952, Val MAPE: 0.1075, Val RMSE: 9.3398, Val MAE: 6.5583, Val MSE: 87.2323\n",
      "Training complete!\n",
      "Test (Normalized) Loss: 0.0049, Test R2: 0.9952, Test MAPE: 0.1075, Test RMSE: 9.3398, Test MAE: 6.5583, Test MSE: 87.2323\n",
      "Random seed set as 0\n",
      "Epoch [1/200], Train Loss: 1.0641, Val Loss: 0.8812, Val R2: -0.1695, Val MAPE: 1.4567, Val RMSE: 129.3330, Val MAE: 107.9457, Val MSE: 16727.0273\n",
      "Epoch [2/200], Train Loss: 1.2149, Val Loss: 0.7366, Val R2: 0.0223, Val MAPE: 1.1473, Val RMSE: 118.2517, Val MAE: 103.8460, Val MSE: 13983.4580\n",
      "Epoch [3/200], Train Loss: 1.1419, Val Loss: 1.0125, Val R2: -0.3438, Val MAPE: 0.6938, Val RMSE: 138.6391, Val MAE: 109.1015, Val MSE: 19220.7949\n",
      "Epoch [4/200], Train Loss: 1.0234, Val Loss: 0.7080, Val R2: 0.0603, Val MAPE: 1.2371, Val RMSE: 115.9297, Val MAE: 99.5265, Val MSE: 13439.6914\n",
      "Epoch [5/200], Train Loss: 1.0557, Val Loss: 0.5917, Val R2: 0.2147, Val MAPE: 1.0705, Val RMSE: 105.9804, Val MAE: 91.3759, Val MSE: 11231.8398\n",
      "Epoch [6/200], Train Loss: 0.8053, Val Loss: 0.4338, Val R2: 0.4243, Val MAPE: 0.5241, Val RMSE: 90.7432, Val MAE: 70.6994, Val MSE: 8234.3369\n",
      "Epoch [7/200], Train Loss: 0.4885, Val Loss: 0.2094, Val R2: 0.7221, Val MAPE: 0.4337, Val RMSE: 63.0428, Val MAE: 57.3677, Val MSE: 3974.3916\n",
      "Epoch [8/200], Train Loss: 0.2311, Val Loss: 0.4391, Val R2: 0.4172, Val MAPE: 0.4981, Val RMSE: 91.3023, Val MAE: 71.6521, Val MSE: 8336.1172\n",
      "Epoch [9/200], Train Loss: 0.3479, Val Loss: 0.3557, Val R2: 0.5279, Val MAPE: 0.5854, Val RMSE: 82.1692, Val MAE: 73.3361, Val MSE: 6751.7769\n",
      "Epoch [10/200], Train Loss: 0.2721, Val Loss: 0.1514, Val R2: 0.7991, Val MAPE: 0.1959, Val RMSE: 53.6045, Val MAE: 35.1618, Val MSE: 2873.4426\n",
      "Epoch [11/200], Train Loss: 0.2085, Val Loss: 0.1139, Val R2: 0.8489, Val MAPE: 0.2437, Val RMSE: 46.4920, Val MAE: 36.6552, Val MSE: 2161.5044\n",
      "Epoch [12/200], Train Loss: 0.1747, Val Loss: 0.1169, Val R2: 0.8448, Val MAPE: 0.1654, Val RMSE: 47.1162, Val MAE: 30.7605, Val MSE: 2219.9399\n",
      "Epoch [13/200], Train Loss: 0.1506, Val Loss: 0.0886, Val R2: 0.8824, Val MAPE: 0.1323, Val RMSE: 41.0104, Val MAE: 25.0794, Val MSE: 1681.8502\n",
      "Epoch [14/200], Train Loss: 0.1189, Val Loss: 0.0687, Val R2: 0.9088, Val MAPE: 0.1835, Val RMSE: 36.1178, Val MAE: 29.2602, Val MSE: 1304.4982\n",
      "Epoch [15/200], Train Loss: 0.1296, Val Loss: 0.1003, Val R2: 0.8669, Val MAPE: 0.1524, Val RMSE: 43.6361, Val MAE: 28.5666, Val MSE: 1904.1129\n",
      "Epoch [16/200], Train Loss: 0.1160, Val Loss: 0.0793, Val R2: 0.8947, Val MAPE: 0.2176, Val RMSE: 38.8047, Val MAE: 29.5345, Val MSE: 1505.8083\n",
      "Epoch [17/200], Train Loss: 0.0817, Val Loss: 0.0543, Val R2: 0.9279, Val MAPE: 0.1425, Val RMSE: 32.1110, Val MAE: 20.7405, Val MSE: 1031.1161\n",
      "Epoch [18/200], Train Loss: 0.0467, Val Loss: 0.0457, Val R2: 0.9393, Val MAPE: 0.1355, Val RMSE: 29.4620, Val MAE: 22.3274, Val MSE: 868.0087\n",
      "Epoch [19/200], Train Loss: 0.0499, Val Loss: 0.1526, Val R2: 0.7975, Val MAPE: 0.2756, Val RMSE: 53.8140, Val MAE: 44.2060, Val MSE: 2895.9504\n",
      "Epoch [20/200], Train Loss: 0.1233, Val Loss: 0.0829, Val R2: 0.8900, Val MAPE: 0.3409, Val RMSE: 39.6601, Val MAE: 32.4744, Val MSE: 1572.9247\n",
      "Epoch [21/200], Train Loss: 0.0858, Val Loss: 0.0606, Val R2: 0.9196, Val MAPE: 0.1516, Val RMSE: 33.9065, Val MAE: 24.6245, Val MSE: 1149.6493\n",
      "Epoch [22/200], Train Loss: 0.0710, Val Loss: 0.0618, Val R2: 0.9179, Val MAPE: 0.1869, Val RMSE: 34.2620, Val MAE: 26.4702, Val MSE: 1173.8812\n",
      "Epoch [23/200], Train Loss: 0.0520, Val Loss: 0.0710, Val R2: 0.9058, Val MAPE: 0.2119, Val RMSE: 36.7050, Val MAE: 30.4563, Val MSE: 1347.2606\n",
      "Epoch [24/200], Train Loss: 0.0528, Val Loss: 0.0875, Val R2: 0.8839, Val MAPE: 0.2633, Val RMSE: 40.7578, Val MAE: 35.0262, Val MSE: 1661.1953\n",
      "Epoch [25/200], Train Loss: 0.0516, Val Loss: 0.0376, Val R2: 0.9501, Val MAPE: 0.1380, Val RMSE: 26.7021, Val MAE: 19.2751, Val MSE: 713.0037\n",
      "Epoch [26/200], Train Loss: 0.0334, Val Loss: 0.0383, Val R2: 0.9491, Val MAPE: 0.1076, Val RMSE: 26.9783, Val MAE: 18.2031, Val MSE: 727.8278\n",
      "Epoch [27/200], Train Loss: 0.0290, Val Loss: 0.0307, Val R2: 0.9593, Val MAPE: 0.0984, Val RMSE: 24.1406, Val MAE: 16.8612, Val MSE: 582.7708\n",
      "Epoch [28/200], Train Loss: 0.0188, Val Loss: 0.0336, Val R2: 0.9555, Val MAPE: 0.1429, Val RMSE: 25.2406, Val MAE: 19.3579, Val MSE: 637.0861\n",
      "Epoch [29/200], Train Loss: 0.0189, Val Loss: 0.0295, Val R2: 0.9608, Val MAPE: 0.1344, Val RMSE: 23.6668, Val MAE: 18.2294, Val MSE: 560.1197\n",
      "Epoch [30/200], Train Loss: 0.0184, Val Loss: 0.0250, Val R2: 0.9669, Val MAPE: 0.0868, Val RMSE: 21.7736, Val MAE: 15.9661, Val MSE: 474.0887\n",
      "Epoch [31/200], Train Loss: 0.0158, Val Loss: 0.0234, Val R2: 0.9690, Val MAPE: 0.0913, Val RMSE: 21.0658, Val MAE: 15.1004, Val MSE: 443.7685\n",
      "Epoch [32/200], Train Loss: 0.0126, Val Loss: 0.0265, Val R2: 0.9649, Val MAPE: 0.1099, Val RMSE: 22.4103, Val MAE: 16.4114, Val MSE: 502.2234\n",
      "Epoch [33/200], Train Loss: 0.0157, Val Loss: 0.0310, Val R2: 0.9588, Val MAPE: 0.0823, Val RMSE: 24.2704, Val MAE: 15.4160, Val MSE: 589.0502\n",
      "Epoch [34/200], Train Loss: 0.0134, Val Loss: 0.0225, Val R2: 0.9701, Val MAPE: 0.0964, Val RMSE: 20.6882, Val MAE: 14.7258, Val MSE: 428.0005\n",
      "Epoch [35/200], Train Loss: 0.0143, Val Loss: 0.0250, Val R2: 0.9668, Val MAPE: 0.0823, Val RMSE: 21.8056, Val MAE: 15.3646, Val MSE: 475.4849\n",
      "Epoch [36/200], Train Loss: 0.0126, Val Loss: 0.0241, Val R2: 0.9680, Val MAPE: 0.0955, Val RMSE: 21.3961, Val MAE: 15.7927, Val MSE: 457.7943\n",
      "Epoch [37/200], Train Loss: 0.0104, Val Loss: 0.0217, Val R2: 0.9711, Val MAPE: 0.0849, Val RMSE: 20.3149, Val MAE: 14.3887, Val MSE: 412.6940\n",
      "Epoch [38/200], Train Loss: 0.0085, Val Loss: 0.0190, Val R2: 0.9748, Val MAPE: 0.0881, Val RMSE: 18.9888, Val MAE: 13.3986, Val MSE: 360.5739\n",
      "Epoch [39/200], Train Loss: 0.0095, Val Loss: 0.0246, Val R2: 0.9673, Val MAPE: 0.0973, Val RMSE: 21.6103, Val MAE: 15.2243, Val MSE: 467.0072\n",
      "Epoch [40/200], Train Loss: 0.0098, Val Loss: 0.0189, Val R2: 0.9750, Val MAPE: 0.0917, Val RMSE: 18.9243, Val MAE: 13.9345, Val MSE: 358.1280\n",
      "Epoch [41/200], Train Loss: 0.0096, Val Loss: 0.0250, Val R2: 0.9669, Val MAPE: 0.0835, Val RMSE: 21.7658, Val MAE: 14.1799, Val MSE: 473.7497\n",
      "Epoch [42/200], Train Loss: 0.0100, Val Loss: 0.0187, Val R2: 0.9752, Val MAPE: 0.0739, Val RMSE: 18.8318, Val MAE: 12.8340, Val MSE: 354.6366\n",
      "Epoch [43/200], Train Loss: 0.0074, Val Loss: 0.0229, Val R2: 0.9696, Val MAPE: 0.0745, Val RMSE: 20.8419, Val MAE: 13.8314, Val MSE: 434.3852\n",
      "Epoch [44/200], Train Loss: 0.0075, Val Loss: 0.0189, Val R2: 0.9750, Val MAPE: 0.0846, Val RMSE: 18.9198, Val MAE: 14.0733, Val MSE: 357.9603\n",
      "Epoch [45/200], Train Loss: 0.0076, Val Loss: 0.0219, Val R2: 0.9710, Val MAPE: 0.0935, Val RMSE: 20.3673, Val MAE: 14.8374, Val MSE: 414.8272\n",
      "Epoch [46/200], Train Loss: 0.0072, Val Loss: 0.0173, Val R2: 0.9770, Val MAPE: 0.0727, Val RMSE: 18.1246, Val MAE: 12.5153, Val MSE: 328.5020\n",
      "Epoch [47/200], Train Loss: 0.0079, Val Loss: 0.0218, Val R2: 0.9711, Val MAPE: 0.0777, Val RMSE: 20.3426, Val MAE: 14.3432, Val MSE: 413.8224\n",
      "Epoch [48/200], Train Loss: 0.0126, Val Loss: 0.0161, Val R2: 0.9787, Val MAPE: 0.0755, Val RMSE: 17.4651, Val MAE: 12.3537, Val MSE: 305.0289\n",
      "Epoch [49/200], Train Loss: 0.0084, Val Loss: 0.0247, Val R2: 0.9672, Val MAPE: 0.0786, Val RMSE: 21.6611, Val MAE: 14.8812, Val MSE: 469.2015\n",
      "Epoch [50/200], Train Loss: 0.0114, Val Loss: 0.0211, Val R2: 0.9720, Val MAPE: 0.0784, Val RMSE: 20.0199, Val MAE: 13.3936, Val MSE: 400.7981\n",
      "Epoch [51/200], Train Loss: 0.0077, Val Loss: 0.0170, Val R2: 0.9774, Val MAPE: 0.0965, Val RMSE: 17.9736, Val MAE: 13.6929, Val MSE: 323.0503\n",
      "Epoch [52/200], Train Loss: 0.0064, Val Loss: 0.0164, Val R2: 0.9782, Val MAPE: 0.0653, Val RMSE: 17.6578, Val MAE: 11.9241, Val MSE: 311.7983\n",
      "Epoch [53/200], Train Loss: 0.0060, Val Loss: 0.0164, Val R2: 0.9782, Val MAPE: 0.0691, Val RMSE: 17.6387, Val MAE: 12.4168, Val MSE: 311.1227\n",
      "Epoch [54/200], Train Loss: 0.0068, Val Loss: 0.0181, Val R2: 0.9759, Val MAPE: 0.0691, Val RMSE: 18.5555, Val MAE: 12.1401, Val MSE: 344.3059\n",
      "Epoch [55/200], Train Loss: 0.0064, Val Loss: 0.0166, Val R2: 0.9779, Val MAPE: 0.0823, Val RMSE: 17.7700, Val MAE: 12.9165, Val MSE: 315.7738\n",
      "Epoch [56/200], Train Loss: 0.0060, Val Loss: 0.0241, Val R2: 0.9680, Val MAPE: 0.0735, Val RMSE: 21.4095, Val MAE: 14.4389, Val MSE: 458.3672\n",
      "Epoch [57/200], Train Loss: 0.0091, Val Loss: 0.0179, Val R2: 0.9762, Val MAPE: 0.0818, Val RMSE: 18.4373, Val MAE: 13.2653, Val MSE: 339.9349\n",
      "Epoch [58/200], Train Loss: 0.0067, Val Loss: 0.0219, Val R2: 0.9710, Val MAPE: 0.0858, Val RMSE: 20.3810, Val MAE: 13.4281, Val MSE: 415.3832\n",
      "Epoch [59/200], Train Loss: 0.0071, Val Loss: 0.0278, Val R2: 0.9631, Val MAPE: 0.1039, Val RMSE: 22.9811, Val MAE: 16.9821, Val MSE: 528.1300\n",
      "Epoch [60/200], Train Loss: 0.0104, Val Loss: 0.0263, Val R2: 0.9651, Val MAPE: 0.0716, Val RMSE: 22.3465, Val MAE: 14.0732, Val MSE: 499.3644\n",
      "Epoch [61/200], Train Loss: 0.0073, Val Loss: 0.0203, Val R2: 0.9731, Val MAPE: 0.0940, Val RMSE: 19.6287, Val MAE: 13.9672, Val MSE: 385.2845\n",
      "Epoch [62/200], Train Loss: 0.0090, Val Loss: 0.0234, Val R2: 0.9690, Val MAPE: 0.0650, Val RMSE: 21.0570, Val MAE: 13.1626, Val MSE: 443.3965\n",
      "Epoch [63/200], Train Loss: 0.0096, Val Loss: 0.0209, Val R2: 0.9722, Val MAPE: 0.0686, Val RMSE: 19.9284, Val MAE: 13.3023, Val MSE: 397.1405\n",
      "Epoch [64/200], Train Loss: 0.0089, Val Loss: 0.0154, Val R2: 0.9796, Val MAPE: 0.0909, Val RMSE: 17.0942, Val MAE: 12.3784, Val MSE: 292.2130\n",
      "Epoch [65/200], Train Loss: 0.0075, Val Loss: 0.0165, Val R2: 0.9781, Val MAPE: 0.0704, Val RMSE: 17.6951, Val MAE: 12.4394, Val MSE: 313.1150\n",
      "Epoch [66/200], Train Loss: 0.0052, Val Loss: 0.0156, Val R2: 0.9792, Val MAPE: 0.0583, Val RMSE: 17.2320, Val MAE: 11.2369, Val MSE: 296.9421\n",
      "Epoch [67/200], Train Loss: 0.0044, Val Loss: 0.0148, Val R2: 0.9803, Val MAPE: 0.0709, Val RMSE: 16.7764, Val MAE: 12.1322, Val MSE: 281.4480\n",
      "Epoch [68/200], Train Loss: 0.0034, Val Loss: 0.0184, Val R2: 0.9756, Val MAPE: 0.0685, Val RMSE: 18.6857, Val MAE: 12.6782, Val MSE: 349.1538\n",
      "Epoch [69/200], Train Loss: 0.0037, Val Loss: 0.0153, Val R2: 0.9798, Val MAPE: 0.0592, Val RMSE: 17.0172, Val MAE: 11.3632, Val MSE: 289.5853\n",
      "Epoch [70/200], Train Loss: 0.0049, Val Loss: 0.0162, Val R2: 0.9784, Val MAPE: 0.0621, Val RMSE: 17.5593, Val MAE: 11.5168, Val MSE: 308.3288\n",
      "Epoch [71/200], Train Loss: 0.0042, Val Loss: 0.0148, Val R2: 0.9804, Val MAPE: 0.0678, Val RMSE: 16.7461, Val MAE: 11.9792, Val MSE: 280.4335\n",
      "Epoch [72/200], Train Loss: 0.0035, Val Loss: 0.0136, Val R2: 0.9819, Val MAPE: 0.0647, Val RMSE: 16.0891, Val MAE: 11.3698, Val MSE: 258.8586\n",
      "Epoch [73/200], Train Loss: 0.0036, Val Loss: 0.0140, Val R2: 0.9814, Val MAPE: 0.0652, Val RMSE: 16.3009, Val MAE: 11.4768, Val MSE: 265.7196\n",
      "Epoch [74/200], Train Loss: 0.0048, Val Loss: 0.0141, Val R2: 0.9813, Val MAPE: 0.0810, Val RMSE: 16.3737, Val MAE: 12.4579, Val MSE: 268.0979\n",
      "Epoch [75/200], Train Loss: 0.0037, Val Loss: 0.0143, Val R2: 0.9810, Val MAPE: 0.0726, Val RMSE: 16.4891, Val MAE: 11.5015, Val MSE: 271.8893\n",
      "Epoch [76/200], Train Loss: 0.0043, Val Loss: 0.0148, Val R2: 0.9804, Val MAPE: 0.0669, Val RMSE: 16.7509, Val MAE: 11.1682, Val MSE: 280.5910\n",
      "Epoch [77/200], Train Loss: 0.0041, Val Loss: 0.0157, Val R2: 0.9792, Val MAPE: 0.0754, Val RMSE: 17.2534, Val MAE: 11.7108, Val MSE: 297.6792\n",
      "Epoch [78/200], Train Loss: 0.0033, Val Loss: 0.0129, Val R2: 0.9829, Val MAPE: 0.0605, Val RMSE: 15.6502, Val MAE: 10.5732, Val MSE: 244.9301\n",
      "Epoch [79/200], Train Loss: 0.0031, Val Loss: 0.0142, Val R2: 0.9812, Val MAPE: 0.0615, Val RMSE: 16.3947, Val MAE: 10.9938, Val MSE: 268.7870\n",
      "Epoch [80/200], Train Loss: 0.0035, Val Loss: 0.0127, Val R2: 0.9832, Val MAPE: 0.0685, Val RMSE: 15.5220, Val MAE: 10.7085, Val MSE: 240.9324\n",
      "Epoch [81/200], Train Loss: 0.0026, Val Loss: 0.0125, Val R2: 0.9835, Val MAPE: 0.0581, Val RMSE: 15.3749, Val MAE: 10.9770, Val MSE: 236.3880\n",
      "Epoch [82/200], Train Loss: 0.0027, Val Loss: 0.0125, Val R2: 0.9834, Val MAPE: 0.0596, Val RMSE: 15.4044, Val MAE: 11.0450, Val MSE: 237.2966\n",
      "Epoch [83/200], Train Loss: 0.0024, Val Loss: 0.0141, Val R2: 0.9813, Val MAPE: 0.0583, Val RMSE: 16.3355, Val MAE: 10.9217, Val MSE: 266.8477\n",
      "Epoch [84/200], Train Loss: 0.0028, Val Loss: 0.0113, Val R2: 0.9850, Val MAPE: 0.0656, Val RMSE: 14.6270, Val MAE: 10.4479, Val MSE: 213.9505\n",
      "Epoch [85/200], Train Loss: 0.0028, Val Loss: 0.0129, Val R2: 0.9829, Val MAPE: 0.0545, Val RMSE: 15.6199, Val MAE: 10.3071, Val MSE: 243.9822\n",
      "Epoch [86/200], Train Loss: 0.0018, Val Loss: 0.0123, Val R2: 0.9836, Val MAPE: 0.0595, Val RMSE: 15.2962, Val MAE: 10.6406, Val MSE: 233.9737\n",
      "Epoch [87/200], Train Loss: 0.0021, Val Loss: 0.0122, Val R2: 0.9838, Val MAPE: 0.0607, Val RMSE: 15.2143, Val MAE: 10.3691, Val MSE: 231.4751\n",
      "Epoch [88/200], Train Loss: 0.0021, Val Loss: 0.0112, Val R2: 0.9851, Val MAPE: 0.0586, Val RMSE: 14.6110, Val MAE: 10.3592, Val MSE: 213.4815\n",
      "Epoch [89/200], Train Loss: 0.0017, Val Loss: 0.0126, Val R2: 0.9832, Val MAPE: 0.0576, Val RMSE: 15.4910, Val MAE: 10.3639, Val MSE: 239.9696\n",
      "Epoch [90/200], Train Loss: 0.0028, Val Loss: 0.0125, Val R2: 0.9834, Val MAPE: 0.0601, Val RMSE: 15.4073, Val MAE: 10.2785, Val MSE: 237.3848\n",
      "Epoch [91/200], Train Loss: 0.0028, Val Loss: 0.0107, Val R2: 0.9858, Val MAPE: 0.0585, Val RMSE: 14.2449, Val MAE: 9.6288, Val MSE: 202.9165\n",
      "Epoch [92/200], Train Loss: 0.0025, Val Loss: 0.0119, Val R2: 0.9842, Val MAPE: 0.0606, Val RMSE: 15.0229, Val MAE: 10.9341, Val MSE: 225.6888\n",
      "Epoch [93/200], Train Loss: 0.0024, Val Loss: 0.0122, Val R2: 0.9838, Val MAPE: 0.0627, Val RMSE: 15.2216, Val MAE: 11.2065, Val MSE: 231.6957\n",
      "Epoch [94/200], Train Loss: 0.0024, Val Loss: 0.0097, Val R2: 0.9872, Val MAPE: 0.0570, Val RMSE: 13.5533, Val MAE: 9.6893, Val MSE: 183.6909\n",
      "Epoch [95/200], Train Loss: 0.0030, Val Loss: 0.0105, Val R2: 0.9861, Val MAPE: 0.0543, Val RMSE: 14.1226, Val MAE: 9.6671, Val MSE: 199.4475\n",
      "Epoch [96/200], Train Loss: 0.0026, Val Loss: 0.0128, Val R2: 0.9830, Val MAPE: 0.0653, Val RMSE: 15.5748, Val MAE: 10.6422, Val MSE: 242.5735\n",
      "Epoch [97/200], Train Loss: 0.0025, Val Loss: 0.0096, Val R2: 0.9872, Val MAPE: 0.0524, Val RMSE: 13.5328, Val MAE: 9.3184, Val MSE: 183.1380\n",
      "Epoch [98/200], Train Loss: 0.0018, Val Loss: 0.0112, Val R2: 0.9851, Val MAPE: 0.0579, Val RMSE: 14.5830, Val MAE: 10.4901, Val MSE: 212.6631\n",
      "Epoch [99/200], Train Loss: 0.0019, Val Loss: 0.0102, Val R2: 0.9865, Val MAPE: 0.0569, Val RMSE: 13.9018, Val MAE: 10.1402, Val MSE: 193.2599\n",
      "Epoch [100/200], Train Loss: 0.0020, Val Loss: 0.0107, Val R2: 0.9859, Val MAPE: 0.0572, Val RMSE: 14.2241, Val MAE: 9.5667, Val MSE: 202.3259\n",
      "Epoch [101/200], Train Loss: 0.0026, Val Loss: 0.0107, Val R2: 0.9858, Val MAPE: 0.0637, Val RMSE: 14.2352, Val MAE: 9.8089, Val MSE: 202.6407\n",
      "Epoch [102/200], Train Loss: 0.0025, Val Loss: 0.0108, Val R2: 0.9857, Val MAPE: 0.0632, Val RMSE: 14.2900, Val MAE: 10.6786, Val MSE: 204.2043\n",
      "Epoch [103/200], Train Loss: 0.0024, Val Loss: 0.0103, Val R2: 0.9863, Val MAPE: 0.0558, Val RMSE: 13.9916, Val MAE: 10.1207, Val MSE: 195.7652\n",
      "Epoch [104/200], Train Loss: 0.0023, Val Loss: 0.0099, Val R2: 0.9868, Val MAPE: 0.0551, Val RMSE: 13.7148, Val MAE: 9.3224, Val MSE: 188.0971\n",
      "Epoch [105/200], Train Loss: 0.0021, Val Loss: 0.0116, Val R2: 0.9846, Val MAPE: 0.0572, Val RMSE: 14.8482, Val MAE: 9.9336, Val MSE: 220.4692\n",
      "Epoch [106/200], Train Loss: 0.0020, Val Loss: 0.0110, Val R2: 0.9854, Val MAPE: 0.0598, Val RMSE: 14.4651, Val MAE: 10.5268, Val MSE: 209.2398\n",
      "Epoch [107/200], Train Loss: 0.0016, Val Loss: 0.0089, Val R2: 0.9881, Val MAPE: 0.0506, Val RMSE: 13.0334, Val MAE: 9.0481, Val MSE: 169.8697\n",
      "Epoch [108/200], Train Loss: 0.0013, Val Loss: 0.0107, Val R2: 0.9858, Val MAPE: 0.0538, Val RMSE: 14.2622, Val MAE: 9.6187, Val MSE: 203.4114\n",
      "Epoch [109/200], Train Loss: 0.0014, Val Loss: 0.0102, Val R2: 0.9864, Val MAPE: 0.0553, Val RMSE: 13.9311, Val MAE: 9.7082, Val MSE: 194.0758\n",
      "Epoch [110/200], Train Loss: 0.0014, Val Loss: 0.0091, Val R2: 0.9879, Val MAPE: 0.0590, Val RMSE: 13.1495, Val MAE: 9.6418, Val MSE: 172.9099\n",
      "Epoch [111/200], Train Loss: 0.0013, Val Loss: 0.0090, Val R2: 0.9880, Val MAPE: 0.0520, Val RMSE: 13.0858, Val MAE: 8.9575, Val MSE: 171.2369\n",
      "Epoch [112/200], Train Loss: 0.0010, Val Loss: 0.0093, Val R2: 0.9876, Val MAPE: 0.0483, Val RMSE: 13.2967, Val MAE: 8.9266, Val MSE: 176.8035\n",
      "Epoch [113/200], Train Loss: 0.0012, Val Loss: 0.0091, Val R2: 0.9879, Val MAPE: 0.0524, Val RMSE: 13.1603, Val MAE: 9.3881, Val MSE: 173.1938\n",
      "Epoch [114/200], Train Loss: 0.0010, Val Loss: 0.0086, Val R2: 0.9886, Val MAPE: 0.0522, Val RMSE: 12.7809, Val MAE: 8.8914, Val MSE: 163.3525\n",
      "Epoch [115/200], Train Loss: 0.0010, Val Loss: 0.0082, Val R2: 0.9891, Val MAPE: 0.0562, Val RMSE: 12.4895, Val MAE: 8.9292, Val MSE: 155.9867\n",
      "Epoch [116/200], Train Loss: 0.0011, Val Loss: 0.0084, Val R2: 0.9889, Val MAPE: 0.0533, Val RMSE: 12.6276, Val MAE: 9.2273, Val MSE: 159.4557\n",
      "Epoch [117/200], Train Loss: 0.0010, Val Loss: 0.0099, Val R2: 0.9869, Val MAPE: 0.0578, Val RMSE: 13.7077, Val MAE: 9.3302, Val MSE: 187.9008\n",
      "Epoch [118/200], Train Loss: 0.0012, Val Loss: 0.0084, Val R2: 0.9888, Val MAPE: 0.0535, Val RMSE: 12.6442, Val MAE: 9.2134, Val MSE: 159.8757\n",
      "Epoch [119/200], Train Loss: 0.0010, Val Loss: 0.0082, Val R2: 0.9892, Val MAPE: 0.0524, Val RMSE: 12.4417, Val MAE: 8.7620, Val MSE: 154.7954\n",
      "Epoch [120/200], Train Loss: 0.0008, Val Loss: 0.0084, Val R2: 0.9888, Val MAPE: 0.0517, Val RMSE: 12.6362, Val MAE: 8.7125, Val MSE: 159.6728\n",
      "Epoch [121/200], Train Loss: 0.0007, Val Loss: 0.0081, Val R2: 0.9893, Val MAPE: 0.0488, Val RMSE: 12.3767, Val MAE: 8.6738, Val MSE: 153.1823\n",
      "Epoch [122/200], Train Loss: 0.0008, Val Loss: 0.0083, Val R2: 0.9890, Val MAPE: 0.0498, Val RMSE: 12.5320, Val MAE: 8.6915, Val MSE: 157.0511\n",
      "Epoch [123/200], Train Loss: 0.0008, Val Loss: 0.0082, Val R2: 0.9891, Val MAPE: 0.0504, Val RMSE: 12.5038, Val MAE: 8.7400, Val MSE: 156.3461\n",
      "Epoch [124/200], Train Loss: 0.0008, Val Loss: 0.0081, Val R2: 0.9893, Val MAPE: 0.0529, Val RMSE: 12.3706, Val MAE: 8.6137, Val MSE: 153.0316\n",
      "Epoch [125/200], Train Loss: 0.0009, Val Loss: 0.0082, Val R2: 0.9891, Val MAPE: 0.0526, Val RMSE: 12.4912, Val MAE: 9.1340, Val MSE: 156.0295\n",
      "Epoch [126/200], Train Loss: 0.0009, Val Loss: 0.0093, Val R2: 0.9877, Val MAPE: 0.0548, Val RMSE: 13.2607, Val MAE: 9.0684, Val MSE: 175.8454\n",
      "Epoch [127/200], Train Loss: 0.0008, Val Loss: 0.0079, Val R2: 0.9895, Val MAPE: 0.0524, Val RMSE: 12.2715, Val MAE: 8.8331, Val MSE: 150.5907\n",
      "Epoch [128/200], Train Loss: 0.0007, Val Loss: 0.0078, Val R2: 0.9896, Val MAPE: 0.0500, Val RMSE: 12.1875, Val MAE: 8.4722, Val MSE: 148.5359\n",
      "Epoch [129/200], Train Loss: 0.0007, Val Loss: 0.0083, Val R2: 0.9890, Val MAPE: 0.0501, Val RMSE: 12.5306, Val MAE: 8.8513, Val MSE: 157.0159\n",
      "Epoch [130/200], Train Loss: 0.0007, Val Loss: 0.0082, Val R2: 0.9891, Val MAPE: 0.0486, Val RMSE: 12.4627, Val MAE: 8.5268, Val MSE: 155.3197\n",
      "Epoch [131/200], Train Loss: 0.0007, Val Loss: 0.0078, Val R2: 0.9897, Val MAPE: 0.0490, Val RMSE: 12.1574, Val MAE: 8.6218, Val MSE: 147.8030\n",
      "Epoch [132/200], Train Loss: 0.0007, Val Loss: 0.0079, Val R2: 0.9895, Val MAPE: 0.0533, Val RMSE: 12.2711, Val MAE: 8.7752, Val MSE: 150.5789\n",
      "Epoch [133/200], Train Loss: 0.0006, Val Loss: 0.0075, Val R2: 0.9900, Val MAPE: 0.0491, Val RMSE: 11.9338, Val MAE: 8.3958, Val MSE: 142.4160\n",
      "Epoch [134/200], Train Loss: 0.0007, Val Loss: 0.0076, Val R2: 0.9899, Val MAPE: 0.0507, Val RMSE: 12.0425, Val MAE: 8.5860, Val MSE: 145.0229\n",
      "Epoch [135/200], Train Loss: 0.0007, Val Loss: 0.0083, Val R2: 0.9890, Val MAPE: 0.0510, Val RMSE: 12.5493, Val MAE: 8.7522, Val MSE: 157.4850\n",
      "Epoch [136/200], Train Loss: 0.0007, Val Loss: 0.0080, Val R2: 0.9893, Val MAPE: 0.0493, Val RMSE: 12.3455, Val MAE: 8.6481, Val MSE: 152.4102\n",
      "Epoch [137/200], Train Loss: 0.0006, Val Loss: 0.0076, Val R2: 0.9899, Val MAPE: 0.0508, Val RMSE: 12.0368, Val MAE: 8.5485, Val MSE: 144.8848\n",
      "Epoch [138/200], Train Loss: 0.0007, Val Loss: 0.0077, Val R2: 0.9898, Val MAPE: 0.0495, Val RMSE: 12.0866, Val MAE: 8.4158, Val MSE: 146.0865\n",
      "Epoch [139/200], Train Loss: 0.0006, Val Loss: 0.0080, Val R2: 0.9894, Val MAPE: 0.0479, Val RMSE: 12.3283, Val MAE: 8.5508, Val MSE: 151.9866\n",
      "Epoch [140/200], Train Loss: 0.0006, Val Loss: 0.0079, Val R2: 0.9895, Val MAPE: 0.0507, Val RMSE: 12.2650, Val MAE: 8.5540, Val MSE: 150.4299\n",
      "Epoch [141/200], Train Loss: 0.0007, Val Loss: 0.0075, Val R2: 0.9900, Val MAPE: 0.0511, Val RMSE: 11.9367, Val MAE: 8.5019, Val MSE: 142.4851\n",
      "Epoch [142/200], Train Loss: 0.0006, Val Loss: 0.0076, Val R2: 0.9899, Val MAPE: 0.0484, Val RMSE: 12.0103, Val MAE: 8.2608, Val MSE: 144.2479\n",
      "Epoch [143/200], Train Loss: 0.0005, Val Loss: 0.0077, Val R2: 0.9897, Val MAPE: 0.0501, Val RMSE: 12.1095, Val MAE: 8.5506, Val MSE: 146.6401\n",
      "Epoch [144/200], Train Loss: 0.0006, Val Loss: 0.0076, Val R2: 0.9899, Val MAPE: 0.0505, Val RMSE: 12.0021, Val MAE: 8.4957, Val MSE: 144.0503\n",
      "Epoch [145/200], Train Loss: 0.0005, Val Loss: 0.0075, Val R2: 0.9900, Val MAPE: 0.0482, Val RMSE: 11.9398, Val MAE: 8.2529, Val MSE: 142.5600\n",
      "Epoch [146/200], Train Loss: 0.0006, Val Loss: 0.0075, Val R2: 0.9900, Val MAPE: 0.0483, Val RMSE: 11.9502, Val MAE: 8.4636, Val MSE: 142.8064\n",
      "Epoch [147/200], Train Loss: 0.0006, Val Loss: 0.0078, Val R2: 0.9897, Val MAPE: 0.0516, Val RMSE: 12.1346, Val MAE: 8.6122, Val MSE: 147.2480\n",
      "Epoch [148/200], Train Loss: 0.0006, Val Loss: 0.0077, Val R2: 0.9897, Val MAPE: 0.0503, Val RMSE: 12.1118, Val MAE: 8.4575, Val MSE: 146.6957\n",
      "Epoch [149/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9901, Val MAPE: 0.0499, Val RMSE: 11.8759, Val MAE: 8.5218, Val MSE: 141.0365\n",
      "Epoch [150/200], Train Loss: 0.0006, Val Loss: 0.0076, Val R2: 0.9900, Val MAPE: 0.0501, Val RMSE: 11.9769, Val MAE: 8.3102, Val MSE: 143.4468\n",
      "Epoch [151/200], Train Loss: 0.0006, Val Loss: 0.0077, Val R2: 0.9897, Val MAPE: 0.0511, Val RMSE: 12.1092, Val MAE: 8.5709, Val MSE: 146.6335\n",
      "Epoch [152/200], Train Loss: 0.0006, Val Loss: 0.0077, Val R2: 0.9898, Val MAPE: 0.0498, Val RMSE: 12.0678, Val MAE: 8.5221, Val MSE: 145.6324\n",
      "Epoch [153/200], Train Loss: 0.0005, Val Loss: 0.0075, Val R2: 0.9901, Val MAPE: 0.0485, Val RMSE: 11.9034, Val MAE: 8.3037, Val MSE: 141.6920\n",
      "Epoch [154/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0479, Val RMSE: 11.7971, Val MAE: 8.2178, Val MSE: 139.1725\n",
      "Epoch [155/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9902, Val MAPE: 0.0488, Val RMSE: 11.8210, Val MAE: 8.3669, Val MSE: 139.7356\n",
      "Epoch [156/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9901, Val MAPE: 0.0490, Val RMSE: 11.8867, Val MAE: 8.3416, Val MSE: 141.2932\n",
      "Epoch [157/200], Train Loss: 0.0005, Val Loss: 0.0075, Val R2: 0.9900, Val MAPE: 0.0485, Val RMSE: 11.9576, Val MAE: 8.2873, Val MSE: 142.9852\n",
      "Epoch [158/200], Train Loss: 0.0005, Val Loss: 0.0075, Val R2: 0.9901, Val MAPE: 0.0488, Val RMSE: 11.9253, Val MAE: 8.3713, Val MSE: 142.2116\n",
      "Epoch [159/200], Train Loss: 0.0005, Val Loss: 0.0075, Val R2: 0.9901, Val MAPE: 0.0493, Val RMSE: 11.9070, Val MAE: 8.3984, Val MSE: 141.7766\n",
      "Epoch [160/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9901, Val MAPE: 0.0495, Val RMSE: 11.8895, Val MAE: 8.3823, Val MSE: 141.3592\n",
      "Epoch [161/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9902, Val MAPE: 0.0487, Val RMSE: 11.8671, Val MAE: 8.2721, Val MSE: 140.8287\n",
      "Epoch [162/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9902, Val MAPE: 0.0489, Val RMSE: 11.8582, Val MAE: 8.2652, Val MSE: 140.6159\n",
      "Epoch [163/200], Train Loss: 0.0004, Val Loss: 0.0074, Val R2: 0.9902, Val MAPE: 0.0494, Val RMSE: 11.8122, Val MAE: 8.3450, Val MSE: 139.5283\n",
      "Epoch [164/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9902, Val MAPE: 0.0490, Val RMSE: 11.8241, Val MAE: 8.3602, Val MSE: 139.8091\n",
      "Epoch [165/200], Train Loss: 0.0005, Val Loss: 0.0075, Val R2: 0.9901, Val MAPE: 0.0488, Val RMSE: 11.9044, Val MAE: 8.3015, Val MSE: 141.7158\n",
      "Epoch [166/200], Train Loss: 0.0005, Val Loss: 0.0075, Val R2: 0.9901, Val MAPE: 0.0489, Val RMSE: 11.9141, Val MAE: 8.3325, Val MSE: 141.9457\n",
      "Epoch [167/200], Train Loss: 0.0004, Val Loss: 0.0075, Val R2: 0.9901, Val MAPE: 0.0490, Val RMSE: 11.8968, Val MAE: 8.3758, Val MSE: 141.5330\n",
      "Epoch [168/200], Train Loss: 0.0004, Val Loss: 0.0075, Val R2: 0.9901, Val MAPE: 0.0491, Val RMSE: 11.8964, Val MAE: 8.4107, Val MSE: 141.5248\n",
      "Epoch [169/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9901, Val MAPE: 0.0490, Val RMSE: 11.8720, Val MAE: 8.3851, Val MSE: 140.9435\n",
      "Epoch [170/200], Train Loss: 0.0005, Val Loss: 0.0074, Val R2: 0.9902, Val MAPE: 0.0488, Val RMSE: 11.8574, Val MAE: 8.2700, Val MSE: 140.5982\n",
      "Epoch [171/200], Train Loss: 0.0004, Val Loss: 0.0074, Val R2: 0.9902, Val MAPE: 0.0490, Val RMSE: 11.8245, Val MAE: 8.2264, Val MSE: 139.8199\n",
      "Epoch [172/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0489, Val RMSE: 11.7561, Val MAE: 8.2355, Val MSE: 138.2055\n",
      "Epoch [173/200], Train Loss: 0.0005, Val Loss: 0.0072, Val R2: 0.9904, Val MAPE: 0.0488, Val RMSE: 11.7272, Val MAE: 8.2504, Val MSE: 137.5279\n",
      "Epoch [174/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9904, Val MAPE: 0.0484, Val RMSE: 11.7318, Val MAE: 8.2231, Val MSE: 137.6340\n",
      "Epoch [175/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9904, Val MAPE: 0.0483, Val RMSE: 11.7450, Val MAE: 8.2178, Val MSE: 137.9440\n",
      "Epoch [176/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0481, Val RMSE: 11.7602, Val MAE: 8.2081, Val MSE: 138.3028\n",
      "Epoch [177/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0482, Val RMSE: 11.7769, Val MAE: 8.2232, Val MSE: 138.6965\n",
      "Epoch [178/200], Train Loss: 0.0004, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0481, Val RMSE: 11.7861, Val MAE: 8.2334, Val MSE: 138.9127\n",
      "Epoch [179/200], Train Loss: 0.0004, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0479, Val RMSE: 11.7849, Val MAE: 8.2522, Val MSE: 138.8833\n",
      "Epoch [180/200], Train Loss: 0.0004, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0480, Val RMSE: 11.7846, Val MAE: 8.2687, Val MSE: 138.8779\n",
      "Epoch [181/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0480, Val RMSE: 11.7939, Val MAE: 8.2779, Val MSE: 139.0949\n",
      "Epoch [182/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0481, Val RMSE: 11.7974, Val MAE: 8.2725, Val MSE: 139.1780\n",
      "Epoch [183/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0482, Val RMSE: 11.8010, Val MAE: 8.2541, Val MSE: 139.2647\n",
      "Epoch [184/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0482, Val RMSE: 11.7960, Val MAE: 8.2364, Val MSE: 139.1467\n",
      "Epoch [185/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0482, Val RMSE: 11.7890, Val MAE: 8.2269, Val MSE: 138.9797\n",
      "Epoch [186/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0483, Val RMSE: 11.7825, Val MAE: 8.2303, Val MSE: 138.8282\n",
      "Epoch [187/200], Train Loss: 0.0004, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0483, Val RMSE: 11.7768, Val MAE: 8.2405, Val MSE: 138.6932\n",
      "Epoch [188/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0484, Val RMSE: 11.7725, Val MAE: 8.2541, Val MSE: 138.5909\n",
      "Epoch [189/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7699, Val MAE: 8.2653, Val MSE: 138.5313\n",
      "Epoch [190/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7681, Val MAE: 8.2674, Val MSE: 138.4892\n",
      "Epoch [191/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0486, Val RMSE: 11.7686, Val MAE: 8.2648, Val MSE: 138.5010\n",
      "Epoch [192/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7690, Val MAE: 8.2610, Val MSE: 138.5097\n",
      "Epoch [193/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7701, Val MAE: 8.2582, Val MSE: 138.5354\n",
      "Epoch [194/200], Train Loss: 0.0004, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7729, Val MAE: 8.2573, Val MSE: 138.6010\n",
      "Epoch [195/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7739, Val MAE: 8.2561, Val MSE: 138.6241\n",
      "Epoch [196/200], Train Loss: 0.0004, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7747, Val MAE: 8.2547, Val MSE: 138.6443\n",
      "Epoch [197/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7752, Val MAE: 8.2538, Val MSE: 138.6549\n",
      "Epoch [198/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7755, Val MAE: 8.2536, Val MSE: 138.6621\n",
      "Epoch [199/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7755, Val MAE: 8.2536, Val MSE: 138.6624\n",
      "Epoch [200/200], Train Loss: 0.0005, Val Loss: 0.0073, Val R2: 0.9903, Val MAPE: 0.0485, Val RMSE: 11.7755, Val MAE: 8.2536, Val MSE: 138.6630\n",
      "Training complete!\n",
      "Test (Normalized) Loss: 0.0073, Test R2: 0.9903, Test MAPE: 0.0485, Test RMSE: 11.7755, Test MAE: 8.2536, Test MSE: 138.6630\n",
      "Random seed set as 0\n",
      "Epoch [1/200], Train Loss: 1.1501, Val Loss: 1.3258, Val R2: 0.0039, Val MAPE: 1.7476, Val RMSE: 149.4715, Val MAE: 132.6809, Val MSE: 22341.7422\n",
      "Epoch [2/200], Train Loss: 1.1522, Val Loss: 1.3107, Val R2: 0.0152, Val MAPE: 1.8154, Val RMSE: 148.6165, Val MAE: 132.4329, Val MSE: 22086.8750\n",
      "Epoch [3/200], Train Loss: 1.0049, Val Loss: 1.6286, Val R2: -0.2236, Val MAPE: 1.0715, Val RMSE: 165.6641, Val MAE: 130.6241, Val MSE: 27444.5840\n",
      "Epoch [4/200], Train Loss: 1.0624, Val Loss: 1.2659, Val R2: 0.0489, Val MAPE: 1.4595, Val RMSE: 146.0539, Val MAE: 125.2823, Val MSE: 21331.7305\n",
      "Epoch [5/200], Train Loss: 0.9184, Val Loss: 1.1175, Val R2: 0.1604, Val MAPE: 1.6247, Val RMSE: 137.2242, Val MAE: 121.5706, Val MSE: 18830.4922\n",
      "Epoch [6/200], Train Loss: 0.8024, Val Loss: 0.9177, Val R2: 0.3105, Val MAPE: 0.8404, Val RMSE: 124.3576, Val MAE: 94.9259, Val MSE: 15464.8154\n",
      "Epoch [7/200], Train Loss: 0.4783, Val Loss: 0.4121, Val R2: 0.6904, Val MAPE: 0.3105, Val RMSE: 83.3306, Val MAE: 58.8472, Val MSE: 6943.9897\n",
      "Epoch [8/200], Train Loss: 0.2658, Val Loss: 0.3837, Val R2: 0.7117, Val MAPE: 0.6490, Val RMSE: 80.4093, Val MAE: 65.6657, Val MSE: 6465.6538\n",
      "Epoch [9/200], Train Loss: 0.2491, Val Loss: 0.3950, Val R2: 0.7032, Val MAPE: 0.5554, Val RMSE: 81.5879, Val MAE: 64.9163, Val MSE: 6656.5801\n",
      "Epoch [10/200], Train Loss: 0.2256, Val Loss: 0.3637, Val R2: 0.7268, Val MAPE: 0.5113, Val RMSE: 78.2846, Val MAE: 63.1368, Val MSE: 6128.4844\n",
      "Epoch [11/200], Train Loss: 0.1750, Val Loss: 0.2990, Val R2: 0.7754, Val MAPE: 0.3302, Val RMSE: 70.9771, Val MAE: 53.4292, Val MSE: 5037.7520\n",
      "Epoch [12/200], Train Loss: 0.1631, Val Loss: 0.3563, Val R2: 0.7323, Val MAPE: 0.6590, Val RMSE: 77.4905, Val MAE: 67.4329, Val MSE: 6004.7734\n",
      "Epoch [13/200], Train Loss: 0.2860, Val Loss: 0.2318, Val R2: 0.8259, Val MAPE: 0.3435, Val RMSE: 62.4931, Val MAE: 47.2796, Val MSE: 3905.3877\n",
      "Epoch [14/200], Train Loss: 0.1443, Val Loss: 0.2590, Val R2: 0.8054, Val MAPE: 0.5563, Val RMSE: 66.0601, Val MAE: 57.8448, Val MSE: 4363.9307\n",
      "Epoch [15/200], Train Loss: 0.1413, Val Loss: 0.2025, Val R2: 0.8479, Val MAPE: 0.4257, Val RMSE: 58.4123, Val MAE: 48.1968, Val MSE: 3411.9995\n",
      "Epoch [16/200], Train Loss: 0.1189, Val Loss: 0.1433, Val R2: 0.8924, Val MAPE: 0.3020, Val RMSE: 49.1330, Val MAE: 38.5081, Val MSE: 2414.0520\n",
      "Epoch [17/200], Train Loss: 0.0976, Val Loss: 0.2063, Val R2: 0.8450, Val MAPE: 0.2553, Val RMSE: 58.9647, Val MAE: 36.9124, Val MSE: 3476.8318\n",
      "Epoch [18/200], Train Loss: 0.0650, Val Loss: 0.1090, Val R2: 0.9181, Val MAPE: 0.2393, Val RMSE: 42.8592, Val MAE: 30.7933, Val MSE: 1836.9119\n",
      "Epoch [19/200], Train Loss: 0.0610, Val Loss: 0.2318, Val R2: 0.8258, Val MAPE: 0.2355, Val RMSE: 62.5050, Val MAE: 41.2692, Val MSE: 3906.8782\n",
      "Epoch [20/200], Train Loss: 0.0963, Val Loss: 0.4146, Val R2: 0.6885, Val MAPE: 0.4375, Val RMSE: 83.5889, Val MAE: 67.4112, Val MSE: 6987.1050\n",
      "Epoch [21/200], Train Loss: 0.1932, Val Loss: 0.3102, Val R2: 0.7669, Val MAPE: 0.4474, Val RMSE: 72.2987, Val MAE: 54.9586, Val MSE: 5227.1001\n",
      "Epoch [22/200], Train Loss: 0.1158, Val Loss: 0.1127, Val R2: 0.9153, Val MAPE: 0.2511, Val RMSE: 43.5863, Val MAE: 33.4038, Val MSE: 1899.7662\n",
      "Epoch [23/200], Train Loss: 0.0538, Val Loss: 0.1288, Val R2: 0.9032, Val MAPE: 0.3801, Val RMSE: 46.5959, Val MAE: 35.9919, Val MSE: 2171.1775\n",
      "Epoch [24/200], Train Loss: 0.0555, Val Loss: 0.0950, Val R2: 0.9286, Val MAPE: 0.2381, Val RMSE: 40.0208, Val MAE: 27.4960, Val MSE: 1601.6633\n",
      "Epoch [25/200], Train Loss: 0.0570, Val Loss: 0.1342, Val R2: 0.8992, Val MAPE: 0.2114, Val RMSE: 47.5483, Val MAE: 29.3445, Val MSE: 2260.8435\n",
      "Epoch [26/200], Train Loss: 0.0338, Val Loss: 0.1065, Val R2: 0.9200, Val MAPE: 0.2023, Val RMSE: 42.3699, Val MAE: 26.1773, Val MSE: 1795.2109\n",
      "Epoch [27/200], Train Loss: 0.0271, Val Loss: 0.0875, Val R2: 0.9343, Val MAPE: 0.1867, Val RMSE: 38.3901, Val MAE: 26.0389, Val MSE: 1473.7981\n",
      "Epoch [28/200], Train Loss: 0.0187, Val Loss: 0.0668, Val R2: 0.9498, Val MAPE: 0.1959, Val RMSE: 33.5494, Val MAE: 23.9385, Val MSE: 1125.5621\n",
      "Epoch [29/200], Train Loss: 0.0189, Val Loss: 0.0929, Val R2: 0.9302, Val MAPE: 0.2114, Val RMSE: 39.5581, Val MAE: 26.2617, Val MSE: 1564.8427\n",
      "Epoch [30/200], Train Loss: 0.0171, Val Loss: 0.0762, Val R2: 0.9428, Val MAPE: 0.2192, Val RMSE: 35.8229, Val MAE: 25.9273, Val MSE: 1283.2789\n",
      "Epoch [31/200], Train Loss: 0.0230, Val Loss: 0.0791, Val R2: 0.9406, Val MAPE: 0.1931, Val RMSE: 36.5134, Val MAE: 25.6478, Val MSE: 1333.2299\n",
      "Epoch [32/200], Train Loss: 0.0283, Val Loss: 0.1001, Val R2: 0.9248, Val MAPE: 0.1946, Val RMSE: 41.0745, Val MAE: 25.0689, Val MSE: 1687.1177\n",
      "Epoch [33/200], Train Loss: 0.0204, Val Loss: 0.0987, Val R2: 0.9258, Val MAPE: 0.1638, Val RMSE: 40.7877, Val MAE: 25.3245, Val MSE: 1663.6327\n",
      "Epoch [34/200], Train Loss: 0.0249, Val Loss: 0.0707, Val R2: 0.9469, Val MAPE: 0.1667, Val RMSE: 34.5205, Val MAE: 23.7759, Val MSE: 1191.6659\n",
      "Epoch [35/200], Train Loss: 0.0175, Val Loss: 0.0895, Val R2: 0.9327, Val MAPE: 0.2786, Val RMSE: 38.8375, Val MAE: 28.1536, Val MSE: 1508.3502\n",
      "Epoch [36/200], Train Loss: 0.0134, Val Loss: 0.0654, Val R2: 0.9509, Val MAPE: 0.1587, Val RMSE: 33.1991, Val MAE: 22.0528, Val MSE: 1102.1788\n",
      "Epoch [37/200], Train Loss: 0.0110, Val Loss: 0.0738, Val R2: 0.9445, Val MAPE: 0.1521, Val RMSE: 35.2687, Val MAE: 22.5070, Val MSE: 1243.8807\n",
      "Epoch [38/200], Train Loss: 0.0094, Val Loss: 0.0619, Val R2: 0.9535, Val MAPE: 0.1631, Val RMSE: 32.3036, Val MAE: 21.1945, Val MSE: 1043.5201\n",
      "Epoch [39/200], Train Loss: 0.0110, Val Loss: 0.0763, Val R2: 0.9427, Val MAPE: 0.1882, Val RMSE: 35.8458, Val MAE: 24.2432, Val MSE: 1284.9202\n",
      "Epoch [40/200], Train Loss: 0.0126, Val Loss: 0.0572, Val R2: 0.9570, Val MAPE: 0.1618, Val RMSE: 31.0561, Val MAE: 21.2703, Val MSE: 964.4832\n",
      "Epoch [41/200], Train Loss: 0.0094, Val Loss: 0.0740, Val R2: 0.9444, Val MAPE: 0.1605, Val RMSE: 35.3101, Val MAE: 22.2482, Val MSE: 1246.8062\n",
      "Epoch [42/200], Train Loss: 0.0085, Val Loss: 0.0601, Val R2: 0.9548, Val MAPE: 0.1386, Val RMSE: 31.8236, Val MAE: 20.7652, Val MSE: 1012.7399\n",
      "Epoch [43/200], Train Loss: 0.0082, Val Loss: 0.0695, Val R2: 0.9478, Val MAPE: 0.1288, Val RMSE: 34.2219, Val MAE: 21.5796, Val MSE: 1171.1387\n",
      "Epoch [44/200], Train Loss: 0.0085, Val Loss: 0.0579, Val R2: 0.9565, Val MAPE: 0.1452, Val RMSE: 31.2426, Val MAE: 20.4476, Val MSE: 976.0989\n",
      "Epoch [45/200], Train Loss: 0.0069, Val Loss: 0.0613, Val R2: 0.9539, Val MAPE: 0.1534, Val RMSE: 32.1414, Val MAE: 21.2248, Val MSE: 1033.0673\n",
      "Epoch [46/200], Train Loss: 0.0072, Val Loss: 0.0482, Val R2: 0.9638, Val MAPE: 0.1305, Val RMSE: 28.5126, Val MAE: 19.3974, Val MSE: 812.9690\n",
      "Epoch [47/200], Train Loss: 0.0092, Val Loss: 0.0678, Val R2: 0.9491, Val MAPE: 0.1795, Val RMSE: 33.7899, Val MAE: 22.7349, Val MSE: 1141.7563\n",
      "Epoch [48/200], Train Loss: 0.0076, Val Loss: 0.0509, Val R2: 0.9617, Val MAPE: 0.1650, Val RMSE: 29.2904, Val MAE: 20.6497, Val MSE: 857.9247\n",
      "Epoch [49/200], Train Loss: 0.0065, Val Loss: 0.0633, Val R2: 0.9524, Val MAPE: 0.1331, Val RMSE: 32.6638, Val MAE: 21.1472, Val MSE: 1066.9260\n",
      "Epoch [50/200], Train Loss: 0.0062, Val Loss: 0.0550, Val R2: 0.9587, Val MAPE: 0.1676, Val RMSE: 30.4368, Val MAE: 20.4552, Val MSE: 926.3984\n",
      "Epoch [51/200], Train Loss: 0.0061, Val Loss: 0.0641, Val R2: 0.9518, Val MAPE: 0.1429, Val RMSE: 32.8744, Val MAE: 20.7291, Val MSE: 1080.7280\n",
      "Epoch [52/200], Train Loss: 0.0061, Val Loss: 0.0464, Val R2: 0.9652, Val MAPE: 0.1266, Val RMSE: 27.9525, Val MAE: 18.5703, Val MSE: 781.3431\n",
      "Epoch [53/200], Train Loss: 0.0049, Val Loss: 0.0520, Val R2: 0.9609, Val MAPE: 0.1211, Val RMSE: 29.6131, Val MAE: 19.1460, Val MSE: 876.9371\n",
      "Epoch [54/200], Train Loss: 0.0050, Val Loss: 0.0543, Val R2: 0.9592, Val MAPE: 0.1584, Val RMSE: 30.2419, Val MAE: 20.1629, Val MSE: 914.5740\n",
      "Epoch [55/200], Train Loss: 0.0051, Val Loss: 0.0454, Val R2: 0.9659, Val MAPE: 0.1279, Val RMSE: 27.6495, Val MAE: 18.3986, Val MSE: 764.4969\n",
      "Epoch [56/200], Train Loss: 0.0047, Val Loss: 0.0575, Val R2: 0.9568, Val MAPE: 0.1252, Val RMSE: 31.1237, Val MAE: 19.6895, Val MSE: 968.6848\n",
      "Epoch [57/200], Train Loss: 0.0043, Val Loss: 0.0462, Val R2: 0.9653, Val MAPE: 0.1284, Val RMSE: 27.8981, Val MAE: 18.0763, Val MSE: 778.3013\n",
      "Epoch [58/200], Train Loss: 0.0063, Val Loss: 0.0467, Val R2: 0.9649, Val MAPE: 0.1195, Val RMSE: 28.0575, Val MAE: 18.0301, Val MSE: 787.2219\n",
      "Epoch [59/200], Train Loss: 0.0039, Val Loss: 0.0600, Val R2: 0.9549, Val MAPE: 0.1152, Val RMSE: 31.8105, Val MAE: 19.3009, Val MSE: 1011.9072\n",
      "Epoch [60/200], Train Loss: 0.0043, Val Loss: 0.0460, Val R2: 0.9654, Val MAPE: 0.1237, Val RMSE: 27.8451, Val MAE: 18.3577, Val MSE: 775.3479\n",
      "Epoch [61/200], Train Loss: 0.0059, Val Loss: 0.0590, Val R2: 0.9557, Val MAPE: 0.1206, Val RMSE: 31.5182, Val MAE: 19.5328, Val MSE: 993.3962\n",
      "Epoch [62/200], Train Loss: 0.0072, Val Loss: 0.0711, Val R2: 0.9466, Val MAPE: 0.1213, Val RMSE: 34.6023, Val MAE: 20.9513, Val MSE: 1197.3226\n",
      "Epoch [63/200], Train Loss: 0.0132, Val Loss: 0.0687, Val R2: 0.9484, Val MAPE: 0.1228, Val RMSE: 34.0197, Val MAE: 20.2588, Val MSE: 1157.3430\n",
      "Epoch [64/200], Train Loss: 0.0136, Val Loss: 0.0484, Val R2: 0.9636, Val MAPE: 0.1129, Val RMSE: 28.5556, Val MAE: 18.0878, Val MSE: 815.4246\n",
      "Epoch [65/200], Train Loss: 0.0079, Val Loss: 0.0472, Val R2: 0.9646, Val MAPE: 0.1708, Val RMSE: 28.1965, Val MAE: 20.0647, Val MSE: 795.0445\n",
      "Epoch [66/200], Train Loss: 0.0080, Val Loss: 0.0517, Val R2: 0.9612, Val MAPE: 0.1721, Val RMSE: 29.5144, Val MAE: 20.7098, Val MSE: 871.0995\n",
      "Epoch [67/200], Train Loss: 0.0083, Val Loss: 0.0471, Val R2: 0.9646, Val MAPE: 0.1514, Val RMSE: 28.1713, Val MAE: 19.9332, Val MSE: 793.6205\n",
      "Epoch [68/200], Train Loss: 0.0084, Val Loss: 0.0488, Val R2: 0.9633, Val MAPE: 0.1565, Val RMSE: 28.6743, Val MAE: 19.5139, Val MSE: 822.2149\n",
      "Epoch [69/200], Train Loss: 0.0082, Val Loss: 0.0596, Val R2: 0.9552, Val MAPE: 0.1423, Val RMSE: 31.6935, Val MAE: 18.9414, Val MSE: 1004.4759\n",
      "Epoch [70/200], Train Loss: 0.0064, Val Loss: 0.0500, Val R2: 0.9624, Val MAPE: 0.1452, Val RMSE: 29.0379, Val MAE: 19.8414, Val MSE: 843.2011\n",
      "Epoch [71/200], Train Loss: 0.0059, Val Loss: 0.0515, Val R2: 0.9613, Val MAPE: 0.1274, Val RMSE: 29.4690, Val MAE: 18.5021, Val MSE: 868.4215\n",
      "Epoch [72/200], Train Loss: 0.0057, Val Loss: 0.0477, Val R2: 0.9642, Val MAPE: 0.1864, Val RMSE: 28.3500, Val MAE: 20.5897, Val MSE: 803.7203\n",
      "Epoch [73/200], Train Loss: 0.0057, Val Loss: 0.0450, Val R2: 0.9662, Val MAPE: 0.1208, Val RMSE: 27.5521, Val MAE: 18.1967, Val MSE: 759.1173\n",
      "Epoch [74/200], Train Loss: 0.0061, Val Loss: 0.0488, Val R2: 0.9633, Val MAPE: 0.1658, Val RMSE: 28.6867, Val MAE: 18.7701, Val MSE: 822.9242\n",
      "Epoch [75/200], Train Loss: 0.0047, Val Loss: 0.0483, Val R2: 0.9637, Val MAPE: 0.1131, Val RMSE: 28.5431, Val MAE: 17.8821, Val MSE: 814.7086\n",
      "Epoch [76/200], Train Loss: 0.0050, Val Loss: 0.0463, Val R2: 0.9652, Val MAPE: 0.1298, Val RMSE: 27.9193, Val MAE: 17.4004, Val MSE: 779.4891\n",
      "Epoch [77/200], Train Loss: 0.0033, Val Loss: 0.0454, Val R2: 0.9659, Val MAPE: 0.1241, Val RMSE: 27.6566, Val MAE: 17.8715, Val MSE: 764.8892\n",
      "Epoch [78/200], Train Loss: 0.0038, Val Loss: 0.0405, Val R2: 0.9695, Val MAPE: 0.1139, Val RMSE: 26.1337, Val MAE: 16.9132, Val MSE: 682.9724\n",
      "Epoch [79/200], Train Loss: 0.0035, Val Loss: 0.0482, Val R2: 0.9638, Val MAPE: 0.1357, Val RMSE: 28.4893, Val MAE: 18.6202, Val MSE: 811.6404\n",
      "Epoch [80/200], Train Loss: 0.0034, Val Loss: 0.0434, Val R2: 0.9674, Val MAPE: 0.1174, Val RMSE: 27.0496, Val MAE: 16.7124, Val MSE: 731.6815\n",
      "Epoch [81/200], Train Loss: 0.0028, Val Loss: 0.0432, Val R2: 0.9676, Val MAPE: 0.1101, Val RMSE: 26.9764, Val MAE: 16.6840, Val MSE: 727.7277\n",
      "Epoch [82/200], Train Loss: 0.0025, Val Loss: 0.0444, Val R2: 0.9667, Val MAPE: 0.1216, Val RMSE: 27.3442, Val MAE: 16.8805, Val MSE: 747.7047\n",
      "Epoch [83/200], Train Loss: 0.0032, Val Loss: 0.0443, Val R2: 0.9667, Val MAPE: 0.1195, Val RMSE: 27.3215, Val MAE: 17.0687, Val MSE: 746.4670\n",
      "Epoch [84/200], Train Loss: 0.0025, Val Loss: 0.0424, Val R2: 0.9682, Val MAPE: 0.1123, Val RMSE: 26.7267, Val MAE: 16.9123, Val MSE: 714.3148\n",
      "Epoch [85/200], Train Loss: 0.0027, Val Loss: 0.0428, Val R2: 0.9678, Val MAPE: 0.1283, Val RMSE: 26.8639, Val MAE: 16.8551, Val MSE: 721.6670\n",
      "Epoch [86/200], Train Loss: 0.0021, Val Loss: 0.0435, Val R2: 0.9673, Val MAPE: 0.1060, Val RMSE: 27.0869, Val MAE: 16.5992, Val MSE: 733.6976\n",
      "Epoch [87/200], Train Loss: 0.0022, Val Loss: 0.0405, Val R2: 0.9696, Val MAPE: 0.1071, Val RMSE: 26.1250, Val MAE: 15.9545, Val MSE: 682.5149\n",
      "Epoch [88/200], Train Loss: 0.0025, Val Loss: 0.0426, Val R2: 0.9680, Val MAPE: 0.1124, Val RMSE: 26.7837, Val MAE: 16.6471, Val MSE: 717.3683\n",
      "Epoch [89/200], Train Loss: 0.0025, Val Loss: 0.0398, Val R2: 0.9701, Val MAPE: 0.1170, Val RMSE: 25.8837, Val MAE: 16.4994, Val MSE: 669.9678\n",
      "Epoch [90/200], Train Loss: 0.0020, Val Loss: 0.0457, Val R2: 0.9657, Val MAPE: 0.1062, Val RMSE: 27.7439, Val MAE: 16.7745, Val MSE: 769.7233\n",
      "Epoch [91/200], Train Loss: 0.0025, Val Loss: 0.0407, Val R2: 0.9694, Val MAPE: 0.1241, Val RMSE: 26.2021, Val MAE: 16.4482, Val MSE: 686.5519\n",
      "Epoch [92/200], Train Loss: 0.0026, Val Loss: 0.0397, Val R2: 0.9702, Val MAPE: 0.1257, Val RMSE: 25.8711, Val MAE: 17.1496, Val MSE: 669.3144\n",
      "Epoch [93/200], Train Loss: 0.0032, Val Loss: 0.0395, Val R2: 0.9703, Val MAPE: 0.1082, Val RMSE: 25.7979, Val MAE: 15.7142, Val MSE: 665.5297\n",
      "Epoch [94/200], Train Loss: 0.0024, Val Loss: 0.0455, Val R2: 0.9658, Val MAPE: 0.0998, Val RMSE: 27.6912, Val MAE: 15.9378, Val MSE: 766.8052\n",
      "Epoch [95/200], Train Loss: 0.0026, Val Loss: 0.0391, Val R2: 0.9706, Val MAPE: 0.1154, Val RMSE: 25.6701, Val MAE: 15.9525, Val MSE: 658.9539\n",
      "Epoch [96/200], Train Loss: 0.0020, Val Loss: 0.0392, Val R2: 0.9705, Val MAPE: 0.1068, Val RMSE: 25.7109, Val MAE: 16.1985, Val MSE: 661.0512\n",
      "Epoch [97/200], Train Loss: 0.0025, Val Loss: 0.0446, Val R2: 0.9665, Val MAPE: 0.1359, Val RMSE: 27.4075, Val MAE: 17.2577, Val MSE: 751.1718\n",
      "Epoch [98/200], Train Loss: 0.0025, Val Loss: 0.0438, Val R2: 0.9671, Val MAPE: 0.1060, Val RMSE: 27.1599, Val MAE: 16.4531, Val MSE: 737.6600\n",
      "Epoch [99/200], Train Loss: 0.0028, Val Loss: 0.0372, Val R2: 0.9720, Val MAPE: 0.1079, Val RMSE: 25.0489, Val MAE: 15.1123, Val MSE: 627.4464\n",
      "Epoch [100/200], Train Loss: 0.0018, Val Loss: 0.0437, Val R2: 0.9672, Val MAPE: 0.1194, Val RMSE: 27.1307, Val MAE: 16.8419, Val MSE: 736.0750\n",
      "Epoch [101/200], Train Loss: 0.0030, Val Loss: 0.0402, Val R2: 0.9698, Val MAPE: 0.1041, Val RMSE: 26.0183, Val MAE: 15.4584, Val MSE: 676.9543\n",
      "Epoch [102/200], Train Loss: 0.0020, Val Loss: 0.0397, Val R2: 0.9701, Val MAPE: 0.1040, Val RMSE: 25.8751, Val MAE: 15.6540, Val MSE: 669.5209\n",
      "Epoch [103/200], Train Loss: 0.0019, Val Loss: 0.0416, Val R2: 0.9688, Val MAPE: 0.1198, Val RMSE: 26.4665, Val MAE: 16.3631, Val MSE: 700.4777\n",
      "Epoch [104/200], Train Loss: 0.0015, Val Loss: 0.0403, Val R2: 0.9697, Val MAPE: 0.0981, Val RMSE: 26.0737, Val MAE: 15.0865, Val MSE: 679.8354\n",
      "Epoch [105/200], Train Loss: 0.0018, Val Loss: 0.0410, Val R2: 0.9692, Val MAPE: 0.1127, Val RMSE: 26.2817, Val MAE: 15.8318, Val MSE: 690.7267\n",
      "Epoch [106/200], Train Loss: 0.0016, Val Loss: 0.0432, Val R2: 0.9676, Val MAPE: 0.1005, Val RMSE: 26.9658, Val MAE: 15.8937, Val MSE: 727.1540\n",
      "Epoch [107/200], Train Loss: 0.0015, Val Loss: 0.0397, Val R2: 0.9702, Val MAPE: 0.1133, Val RMSE: 25.8727, Val MAE: 15.5085, Val MSE: 669.3990\n",
      "Epoch [108/200], Train Loss: 0.0018, Val Loss: 0.0422, Val R2: 0.9683, Val MAPE: 0.1059, Val RMSE: 26.6552, Val MAE: 16.3060, Val MSE: 710.4986\n",
      "Epoch [109/200], Train Loss: 0.0015, Val Loss: 0.0394, Val R2: 0.9704, Val MAPE: 0.1162, Val RMSE: 25.7514, Val MAE: 15.7268, Val MSE: 663.1334\n",
      "Epoch [110/200], Train Loss: 0.0015, Val Loss: 0.0389, Val R2: 0.9708, Val MAPE: 0.1003, Val RMSE: 25.6011, Val MAE: 15.2996, Val MSE: 655.4144\n",
      "Epoch [111/200], Train Loss: 0.0015, Val Loss: 0.0404, Val R2: 0.9696, Val MAPE: 0.1152, Val RMSE: 26.1050, Val MAE: 15.9376, Val MSE: 681.4725\n",
      "Epoch [112/200], Train Loss: 0.0013, Val Loss: 0.0380, Val R2: 0.9715, Val MAPE: 0.1012, Val RMSE: 25.2967, Val MAE: 14.8494, Val MSE: 639.9233\n",
      "Epoch [113/200], Train Loss: 0.0013, Val Loss: 0.0409, Val R2: 0.9693, Val MAPE: 0.1125, Val RMSE: 26.2443, Val MAE: 15.6946, Val MSE: 688.7640\n",
      "Epoch [114/200], Train Loss: 0.0013, Val Loss: 0.0371, Val R2: 0.9721, Val MAPE: 0.1038, Val RMSE: 24.9980, Val MAE: 15.0851, Val MSE: 624.9006\n",
      "Epoch [115/200], Train Loss: 0.0013, Val Loss: 0.0398, Val R2: 0.9701, Val MAPE: 0.1053, Val RMSE: 25.8992, Val MAE: 15.4792, Val MSE: 670.7674\n",
      "Epoch [116/200], Train Loss: 0.0012, Val Loss: 0.0388, Val R2: 0.9708, Val MAPE: 0.1076, Val RMSE: 25.5740, Val MAE: 15.4806, Val MSE: 654.0285\n",
      "Epoch [117/200], Train Loss: 0.0012, Val Loss: 0.0403, Val R2: 0.9697, Val MAPE: 0.1020, Val RMSE: 26.0715, Val MAE: 15.3664, Val MSE: 679.7216\n",
      "Epoch [118/200], Train Loss: 0.0012, Val Loss: 0.0377, Val R2: 0.9716, Val MAPE: 0.1026, Val RMSE: 25.2163, Val MAE: 15.0894, Val MSE: 635.8594\n",
      "Epoch [119/200], Train Loss: 0.0011, Val Loss: 0.0376, Val R2: 0.9717, Val MAPE: 0.1009, Val RMSE: 25.1716, Val MAE: 15.0257, Val MSE: 633.6072\n",
      "Epoch [120/200], Train Loss: 0.0012, Val Loss: 0.0400, Val R2: 0.9700, Val MAPE: 0.1045, Val RMSE: 25.9481, Val MAE: 15.2928, Val MSE: 673.3055\n",
      "Epoch [121/200], Train Loss: 0.0010, Val Loss: 0.0380, Val R2: 0.9714, Val MAPE: 0.1034, Val RMSE: 25.3127, Val MAE: 14.9601, Val MSE: 640.7303\n",
      "Epoch [122/200], Train Loss: 0.0012, Val Loss: 0.0376, Val R2: 0.9717, Val MAPE: 0.1099, Val RMSE: 25.1826, Val MAE: 15.1958, Val MSE: 634.1645\n",
      "Epoch [123/200], Train Loss: 0.0012, Val Loss: 0.0384, Val R2: 0.9712, Val MAPE: 0.0987, Val RMSE: 25.4257, Val MAE: 15.0426, Val MSE: 646.4655\n",
      "Epoch [124/200], Train Loss: 0.0012, Val Loss: 0.0358, Val R2: 0.9731, Val MAPE: 0.1061, Val RMSE: 24.5500, Val MAE: 14.8922, Val MSE: 602.7044\n",
      "Epoch [125/200], Train Loss: 0.0011, Val Loss: 0.0390, Val R2: 0.9707, Val MAPE: 0.1014, Val RMSE: 25.6436, Val MAE: 14.9556, Val MSE: 657.5954\n",
      "Epoch [126/200], Train Loss: 0.0013, Val Loss: 0.0400, Val R2: 0.9700, Val MAPE: 0.1025, Val RMSE: 25.9494, Val MAE: 15.3817, Val MSE: 673.3734\n",
      "Epoch [127/200], Train Loss: 0.0011, Val Loss: 0.0383, Val R2: 0.9712, Val MAPE: 0.1053, Val RMSE: 25.3939, Val MAE: 14.9781, Val MSE: 644.8509\n",
      "Epoch [128/200], Train Loss: 0.0012, Val Loss: 0.0375, Val R2: 0.9718, Val MAPE: 0.1031, Val RMSE: 25.1538, Val MAE: 14.9742, Val MSE: 632.7139\n",
      "Epoch [129/200], Train Loss: 0.0010, Val Loss: 0.0389, Val R2: 0.9707, Val MAPE: 0.1004, Val RMSE: 25.6141, Val MAE: 15.1436, Val MSE: 656.0839\n",
      "Epoch [130/200], Train Loss: 0.0010, Val Loss: 0.0377, Val R2: 0.9716, Val MAPE: 0.1040, Val RMSE: 25.2197, Val MAE: 15.0373, Val MSE: 636.0316\n",
      "Epoch [131/200], Train Loss: 0.0010, Val Loss: 0.0387, Val R2: 0.9709, Val MAPE: 0.1014, Val RMSE: 25.5374, Val MAE: 14.8775, Val MSE: 652.1594\n",
      "Epoch [132/200], Train Loss: 0.0009, Val Loss: 0.0390, Val R2: 0.9707, Val MAPE: 0.1006, Val RMSE: 25.6392, Val MAE: 15.0368, Val MSE: 657.3676\n",
      "Epoch [133/200], Train Loss: 0.0009, Val Loss: 0.0387, Val R2: 0.9709, Val MAPE: 0.1033, Val RMSE: 25.5275, Val MAE: 14.9897, Val MSE: 651.6532\n",
      "Epoch [134/200], Train Loss: 0.0009, Val Loss: 0.0357, Val R2: 0.9731, Val MAPE: 0.1044, Val RMSE: 24.5424, Val MAE: 14.6891, Val MSE: 602.3290\n",
      "Epoch [135/200], Train Loss: 0.0010, Val Loss: 0.0384, Val R2: 0.9712, Val MAPE: 0.0993, Val RMSE: 25.4263, Val MAE: 14.7542, Val MSE: 646.4957\n",
      "Epoch [136/200], Train Loss: 0.0010, Val Loss: 0.0394, Val R2: 0.9704, Val MAPE: 0.1044, Val RMSE: 25.7621, Val MAE: 15.1778, Val MSE: 663.6843\n",
      "Epoch [137/200], Train Loss: 0.0009, Val Loss: 0.0385, Val R2: 0.9711, Val MAPE: 0.0975, Val RMSE: 25.4607, Val MAE: 14.6233, Val MSE: 648.2468\n",
      "Epoch [138/200], Train Loss: 0.0009, Val Loss: 0.0364, Val R2: 0.9726, Val MAPE: 0.1028, Val RMSE: 24.7817, Val MAE: 14.6659, Val MSE: 614.1337\n",
      "Epoch [139/200], Train Loss: 0.0009, Val Loss: 0.0380, Val R2: 0.9714, Val MAPE: 0.1012, Val RMSE: 25.3122, Val MAE: 14.9374, Val MSE: 640.7081\n",
      "Epoch [140/200], Train Loss: 0.0010, Val Loss: 0.0371, Val R2: 0.9721, Val MAPE: 0.0991, Val RMSE: 25.0048, Val MAE: 14.7718, Val MSE: 625.2390\n",
      "Epoch [141/200], Train Loss: 0.0009, Val Loss: 0.0367, Val R2: 0.9724, Val MAPE: 0.1041, Val RMSE: 24.8598, Val MAE: 14.7848, Val MSE: 618.0108\n",
      "Epoch [142/200], Train Loss: 0.0008, Val Loss: 0.0383, Val R2: 0.9712, Val MAPE: 0.0991, Val RMSE: 25.4142, Val MAE: 14.7496, Val MSE: 645.8832\n",
      "Epoch [143/200], Train Loss: 0.0008, Val Loss: 0.0383, Val R2: 0.9712, Val MAPE: 0.1006, Val RMSE: 25.4052, Val MAE: 14.9319, Val MSE: 645.4260\n",
      "Epoch [144/200], Train Loss: 0.0010, Val Loss: 0.0388, Val R2: 0.9709, Val MAPE: 0.1013, Val RMSE: 25.5571, Val MAE: 14.9314, Val MSE: 653.1642\n",
      "Epoch [145/200], Train Loss: 0.0008, Val Loss: 0.0371, Val R2: 0.9721, Val MAPE: 0.0978, Val RMSE: 25.0200, Val MAE: 14.4528, Val MSE: 626.0009\n",
      "Epoch [146/200], Train Loss: 0.0009, Val Loss: 0.0362, Val R2: 0.9728, Val MAPE: 0.1013, Val RMSE: 24.6976, Val MAE: 14.5549, Val MSE: 609.9723\n",
      "Epoch [147/200], Train Loss: 0.0008, Val Loss: 0.0379, Val R2: 0.9715, Val MAPE: 0.0997, Val RMSE: 25.2650, Val MAE: 14.7010, Val MSE: 638.3204\n",
      "Epoch [148/200], Train Loss: 0.0007, Val Loss: 0.0371, Val R2: 0.9721, Val MAPE: 0.0981, Val RMSE: 25.0022, Val MAE: 14.6191, Val MSE: 625.1080\n",
      "Epoch [149/200], Train Loss: 0.0008, Val Loss: 0.0366, Val R2: 0.9725, Val MAPE: 0.0988, Val RMSE: 24.8247, Val MAE: 14.5150, Val MSE: 616.2673\n",
      "Epoch [150/200], Train Loss: 0.0009, Val Loss: 0.0367, Val R2: 0.9725, Val MAPE: 0.0998, Val RMSE: 24.8550, Val MAE: 14.4242, Val MSE: 617.7701\n",
      "Epoch [151/200], Train Loss: 0.0008, Val Loss: 0.0365, Val R2: 0.9726, Val MAPE: 0.1036, Val RMSE: 24.7948, Val MAE: 14.7270, Val MSE: 614.7842\n",
      "Epoch [152/200], Train Loss: 0.0008, Val Loss: 0.0373, Val R2: 0.9719, Val MAPE: 0.0980, Val RMSE: 25.0855, Val MAE: 14.6565, Val MSE: 629.2838\n",
      "Epoch [153/200], Train Loss: 0.0008, Val Loss: 0.0382, Val R2: 0.9713, Val MAPE: 0.0970, Val RMSE: 25.3687, Val MAE: 14.6507, Val MSE: 643.5731\n",
      "Epoch [154/200], Train Loss: 0.0009, Val Loss: 0.0372, Val R2: 0.9721, Val MAPE: 0.1019, Val RMSE: 25.0249, Val MAE: 14.7109, Val MSE: 626.2434\n",
      "Epoch [155/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.1002, Val RMSE: 24.9389, Val MAE: 14.5963, Val MSE: 621.9487\n",
      "Epoch [156/200], Train Loss: 0.0007, Val Loss: 0.0373, Val R2: 0.9720, Val MAPE: 0.0968, Val RMSE: 25.0695, Val MAE: 14.4993, Val MSE: 628.4783\n",
      "Epoch [157/200], Train Loss: 0.0007, Val Loss: 0.0380, Val R2: 0.9715, Val MAPE: 0.0990, Val RMSE: 25.2997, Val MAE: 14.6605, Val MSE: 640.0750\n",
      "Epoch [158/200], Train Loss: 0.0007, Val Loss: 0.0378, Val R2: 0.9716, Val MAPE: 0.1020, Val RMSE: 25.2470, Val MAE: 14.7678, Val MSE: 637.4114\n",
      "Epoch [159/200], Train Loss: 0.0008, Val Loss: 0.0374, Val R2: 0.9719, Val MAPE: 0.1002, Val RMSE: 25.0990, Val MAE: 14.6499, Val MSE: 629.9593\n",
      "Epoch [160/200], Train Loss: 0.0007, Val Loss: 0.0375, Val R2: 0.9718, Val MAPE: 0.0984, Val RMSE: 25.1493, Val MAE: 14.6266, Val MSE: 632.4875\n",
      "Epoch [161/200], Train Loss: 0.0008, Val Loss: 0.0376, Val R2: 0.9718, Val MAPE: 0.0990, Val RMSE: 25.1555, Val MAE: 14.6799, Val MSE: 632.8005\n",
      "Epoch [162/200], Train Loss: 0.0007, Val Loss: 0.0372, Val R2: 0.9720, Val MAPE: 0.0985, Val RMSE: 25.0466, Val MAE: 14.5640, Val MSE: 627.3338\n",
      "Epoch [163/200], Train Loss: 0.0007, Val Loss: 0.0367, Val R2: 0.9724, Val MAPE: 0.0986, Val RMSE: 24.8781, Val MAE: 14.5291, Val MSE: 618.9206\n",
      "Epoch [164/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0997, Val RMSE: 24.9399, Val MAE: 14.6252, Val MSE: 621.9999\n",
      "Epoch [165/200], Train Loss: 0.0007, Val Loss: 0.0373, Val R2: 0.9720, Val MAPE: 0.0994, Val RMSE: 25.0762, Val MAE: 14.6598, Val MSE: 628.8151\n",
      "Epoch [166/200], Train Loss: 0.0007, Val Loss: 0.0374, Val R2: 0.9719, Val MAPE: 0.0976, Val RMSE: 25.1075, Val MAE: 14.5706, Val MSE: 630.3874\n",
      "Epoch [167/200], Train Loss: 0.0007, Val Loss: 0.0373, Val R2: 0.9720, Val MAPE: 0.0975, Val RMSE: 25.0609, Val MAE: 14.5245, Val MSE: 628.0479\n",
      "Epoch [168/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9722, Val MAPE: 0.0994, Val RMSE: 24.9514, Val MAE: 14.5669, Val MSE: 622.5728\n",
      "Epoch [169/200], Train Loss: 0.0007, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.1015, Val RMSE: 24.9560, Val MAE: 14.6868, Val MSE: 622.8038\n",
      "Epoch [170/200], Train Loss: 0.0007, Val Loss: 0.0372, Val R2: 0.9721, Val MAPE: 0.1010, Val RMSE: 25.0366, Val MAE: 14.6778, Val MSE: 626.8329\n",
      "Epoch [171/200], Train Loss: 0.0006, Val Loss: 0.0376, Val R2: 0.9718, Val MAPE: 0.0992, Val RMSE: 25.1697, Val MAE: 14.6120, Val MSE: 633.5157\n",
      "Epoch [172/200], Train Loss: 0.0007, Val Loss: 0.0376, Val R2: 0.9717, Val MAPE: 0.0977, Val RMSE: 25.1734, Val MAE: 14.5495, Val MSE: 633.7001\n",
      "Epoch [173/200], Train Loss: 0.0007, Val Loss: 0.0372, Val R2: 0.9720, Val MAPE: 0.0984, Val RMSE: 25.0462, Val MAE: 14.5554, Val MSE: 627.3096\n",
      "Epoch [174/200], Train Loss: 0.0007, Val Loss: 0.0368, Val R2: 0.9723, Val MAPE: 0.0990, Val RMSE: 24.9180, Val MAE: 14.5478, Val MSE: 620.9053\n",
      "Epoch [175/200], Train Loss: 0.0007, Val Loss: 0.0367, Val R2: 0.9724, Val MAPE: 0.0989, Val RMSE: 24.8814, Val MAE: 14.5041, Val MSE: 619.0844\n",
      "Epoch [176/200], Train Loss: 0.0007, Val Loss: 0.0368, Val R2: 0.9723, Val MAPE: 0.0990, Val RMSE: 24.9164, Val MAE: 14.5073, Val MSE: 620.8279\n",
      "Epoch [177/200], Train Loss: 0.0007, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0990, Val RMSE: 24.9841, Val MAE: 14.5057, Val MSE: 624.2061\n",
      "Epoch [178/200], Train Loss: 0.0006, Val Loss: 0.0372, Val R2: 0.9721, Val MAPE: 0.0991, Val RMSE: 25.0262, Val MAE: 14.5210, Val MSE: 626.3095\n",
      "Epoch [179/200], Train Loss: 0.0007, Val Loss: 0.0372, Val R2: 0.9720, Val MAPE: 0.0994, Val RMSE: 25.0401, Val MAE: 14.5491, Val MSE: 627.0090\n",
      "Epoch [180/200], Train Loss: 0.0007, Val Loss: 0.0372, Val R2: 0.9721, Val MAPE: 0.0991, Val RMSE: 25.0307, Val MAE: 14.5502, Val MSE: 626.5372\n",
      "Epoch [181/200], Train Loss: 0.0006, Val Loss: 0.0371, Val R2: 0.9721, Val MAPE: 0.0990, Val RMSE: 25.0170, Val MAE: 14.5532, Val MSE: 625.8497\n",
      "Epoch [182/200], Train Loss: 0.0007, Val Loss: 0.0371, Val R2: 0.9721, Val MAPE: 0.0988, Val RMSE: 25.0060, Val MAE: 14.5598, Val MSE: 625.3009\n",
      "Epoch [183/200], Train Loss: 0.0007, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0986, Val RMSE: 24.9667, Val MAE: 14.5424, Val MSE: 623.3386\n",
      "Epoch [184/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0983, Val RMSE: 24.9369, Val MAE: 14.5203, Val MSE: 621.8500\n",
      "Epoch [185/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0982, Val RMSE: 24.9324, Val MAE: 14.5076, Val MSE: 621.6270\n",
      "Epoch [186/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0983, Val RMSE: 24.9209, Val MAE: 14.5012, Val MSE: 621.0527\n",
      "Epoch [187/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0983, Val RMSE: 24.9223, Val MAE: 14.4896, Val MSE: 621.1191\n",
      "Epoch [188/200], Train Loss: 0.0006, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0984, Val RMSE: 24.9271, Val MAE: 14.4888, Val MSE: 621.3599\n",
      "Epoch [189/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0985, Val RMSE: 24.9344, Val MAE: 14.4913, Val MSE: 621.7243\n",
      "Epoch [190/200], Train Loss: 0.0007, Val Loss: 0.0369, Val R2: 0.9723, Val MAPE: 0.0988, Val RMSE: 24.9436, Val MAE: 14.5065, Val MSE: 622.1818\n",
      "Epoch [191/200], Train Loss: 0.0006, Val Loss: 0.0369, Val R2: 0.9722, Val MAPE: 0.0989, Val RMSE: 24.9528, Val MAE: 14.5133, Val MSE: 622.6420\n",
      "Epoch [192/200], Train Loss: 0.0007, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0990, Val RMSE: 24.9610, Val MAE: 14.5214, Val MSE: 623.0515\n",
      "Epoch [193/200], Train Loss: 0.0007, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0990, Val RMSE: 24.9672, Val MAE: 14.5270, Val MSE: 623.3605\n",
      "Epoch [194/200], Train Loss: 0.0007, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0991, Val RMSE: 24.9710, Val MAE: 14.5324, Val MSE: 623.5507\n",
      "Epoch [195/200], Train Loss: 0.0006, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0991, Val RMSE: 24.9718, Val MAE: 14.5357, Val MSE: 623.5909\n",
      "Epoch [196/200], Train Loss: 0.0006, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0991, Val RMSE: 24.9719, Val MAE: 14.5371, Val MSE: 623.5964\n",
      "Epoch [197/200], Train Loss: 0.0006, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0991, Val RMSE: 24.9731, Val MAE: 14.5380, Val MSE: 623.6581\n",
      "Epoch [198/200], Train Loss: 0.0007, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0991, Val RMSE: 24.9732, Val MAE: 14.5382, Val MSE: 623.6619\n",
      "Epoch [199/200], Train Loss: 0.0006, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0991, Val RMSE: 24.9733, Val MAE: 14.5382, Val MSE: 623.6658\n",
      "Epoch [200/200], Train Loss: 0.0006, Val Loss: 0.0370, Val R2: 0.9722, Val MAPE: 0.0991, Val RMSE: 24.9733, Val MAE: 14.5382, Val MSE: 623.6666\n",
      "Training complete!\n",
      "Test (Normalized) Loss: 0.0370, Test R2: 0.9722, Test MAPE: 0.0991, Test RMSE: 24.9733, Test MAE: 14.5382, Test MSE: 623.6666\n",
      "Random seed set as 0\n",
      "Epoch [1/200], Train Loss: 1.1193, Val Loss: 0.9938, Val R2: -0.1508, Val MAPE: 1.8007, Val RMSE: 135.7834, Val MAE: 118.9374, Val MSE: 18437.1367\n",
      "Epoch [2/200], Train Loss: 1.1972, Val Loss: 0.9653, Val R2: -0.1178, Val MAPE: 1.7521, Val RMSE: 133.8231, Val MAE: 116.6184, Val MSE: 17908.6270\n",
      "Epoch [3/200], Train Loss: 1.0483, Val Loss: 0.9019, Val R2: -0.0443, Val MAPE: 0.9682, Val RMSE: 129.3500, Val MAE: 101.6732, Val MSE: 16731.4297\n",
      "Epoch [4/200], Train Loss: 1.0186, Val Loss: 0.8152, Val R2: 0.0560, Val MAPE: 1.4856, Val RMSE: 122.9816, Val MAE: 106.6364, Val MSE: 15124.4688\n",
      "Epoch [5/200], Train Loss: 0.9653, Val Loss: 0.8011, Val R2: 0.0723, Val MAPE: 1.5964, Val RMSE: 121.9108, Val MAE: 106.9725, Val MSE: 14862.2393\n",
      "Epoch [6/200], Train Loss: 0.7771, Val Loss: 0.4658, Val R2: 0.4607, Val MAPE: 0.7027, Val RMSE: 92.9557, Val MAE: 70.5992, Val MSE: 8640.7549\n",
      "Epoch [7/200], Train Loss: 0.5234, Val Loss: 0.1991, Val R2: 0.7694, Val MAPE: 0.4637, Val RMSE: 60.7769, Val MAE: 50.3264, Val MSE: 3693.8354\n",
      "Epoch [8/200], Train Loss: 0.3271, Val Loss: 0.3455, Val R2: 0.5999, Val MAPE: 0.4786, Val RMSE: 80.0615, Val MAE: 62.0188, Val MSE: 6409.8501\n",
      "Epoch [9/200], Train Loss: 0.3374, Val Loss: 0.1751, Val R2: 0.7972, Val MAPE: 0.4605, Val RMSE: 56.9963, Val MAE: 48.9086, Val MSE: 3248.5823\n",
      "Epoch [10/200], Train Loss: 0.2554, Val Loss: 0.2008, Val R2: 0.7675, Val MAPE: 0.2329, Val RMSE: 61.0338, Val MAE: 36.6566, Val MSE: 3725.1265\n",
      "Epoch [11/200], Train Loss: 0.2889, Val Loss: 0.0979, Val R2: 0.8867, Val MAPE: 0.2179, Val RMSE: 42.6092, Val MAE: 30.6356, Val MSE: 1815.5443\n",
      "Epoch [12/200], Train Loss: 0.1957, Val Loss: 0.1654, Val R2: 0.8085, Val MAPE: 0.4327, Val RMSE: 55.3955, Val MAE: 47.2836, Val MSE: 3068.6594\n",
      "Epoch [13/200], Train Loss: 0.1645, Val Loss: 0.0586, Val R2: 0.9321, Val MAPE: 0.2156, Val RMSE: 32.9746, Val MAE: 24.9896, Val MSE: 1087.3224\n",
      "Epoch [14/200], Train Loss: 0.1180, Val Loss: 0.0565, Val R2: 0.9346, Val MAPE: 0.2516, Val RMSE: 32.3642, Val MAE: 25.3699, Val MSE: 1047.4391\n",
      "Epoch [15/200], Train Loss: 0.1129, Val Loss: 0.2039, Val R2: 0.7639, Val MAPE: 0.4667, Val RMSE: 61.5009, Val MAE: 52.8374, Val MSE: 3782.3547\n",
      "Epoch [16/200], Train Loss: 0.1830, Val Loss: 0.0952, Val R2: 0.8898, Val MAPE: 0.2334, Val RMSE: 42.0162, Val MAE: 31.0961, Val MSE: 1765.3619\n",
      "Epoch [17/200], Train Loss: 0.1153, Val Loss: 0.0820, Val R2: 0.9050, Val MAPE: 0.3178, Val RMSE: 39.0114, Val MAE: 31.2336, Val MSE: 1521.8907\n",
      "Epoch [18/200], Train Loss: 0.0977, Val Loss: 0.0452, Val R2: 0.9477, Val MAPE: 0.1352, Val RMSE: 28.9482, Val MAE: 19.8711, Val MSE: 837.9962\n",
      "Epoch [19/200], Train Loss: 0.0725, Val Loss: 0.0233, Val R2: 0.9730, Val MAPE: 0.1317, Val RMSE: 20.7850, Val MAE: 14.9307, Val MSE: 432.0182\n",
      "Epoch [20/200], Train Loss: 0.0489, Val Loss: 0.0220, Val R2: 0.9745, Val MAPE: 0.1642, Val RMSE: 20.2250, Val MAE: 16.5191, Val MSE: 409.0492\n",
      "Epoch [21/200], Train Loss: 0.0486, Val Loss: 0.0162, Val R2: 0.9812, Val MAPE: 0.1079, Val RMSE: 17.3446, Val MAE: 13.3577, Val MSE: 300.8359\n",
      "Epoch [22/200], Train Loss: 0.0311, Val Loss: 0.0234, Val R2: 0.9729, Val MAPE: 0.1638, Val RMSE: 20.8386, Val MAE: 16.7734, Val MSE: 434.2452\n",
      "Epoch [23/200], Train Loss: 0.0241, Val Loss: 0.0278, Val R2: 0.9678, Val MAPE: 0.1533, Val RMSE: 22.7044, Val MAE: 17.6082, Val MSE: 515.4919\n",
      "Epoch [24/200], Train Loss: 0.0251, Val Loss: 0.0264, Val R2: 0.9695, Val MAPE: 0.1426, Val RMSE: 22.1103, Val MAE: 17.0331, Val MSE: 488.8654\n",
      "Epoch [25/200], Train Loss: 0.0271, Val Loss: 0.0142, Val R2: 0.9835, Val MAPE: 0.1246, Val RMSE: 16.2527, Val MAE: 13.1120, Val MSE: 264.1491\n",
      "Epoch [26/200], Train Loss: 0.0248, Val Loss: 0.0194, Val R2: 0.9775, Val MAPE: 0.1273, Val RMSE: 18.9758, Val MAE: 14.1977, Val MSE: 360.0822\n",
      "Epoch [27/200], Train Loss: 0.0231, Val Loss: 0.0137, Val R2: 0.9842, Val MAPE: 0.1128, Val RMSE: 15.9158, Val MAE: 11.9397, Val MSE: 253.3138\n",
      "Epoch [28/200], Train Loss: 0.0162, Val Loss: 0.0122, Val R2: 0.9859, Val MAPE: 0.1049, Val RMSE: 15.0174, Val MAE: 11.5999, Val MSE: 225.5210\n",
      "Epoch [29/200], Train Loss: 0.0147, Val Loss: 0.0158, Val R2: 0.9817, Val MAPE: 0.1112, Val RMSE: 17.1343, Val MAE: 13.2067, Val MSE: 293.5852\n",
      "Epoch [30/200], Train Loss: 0.0160, Val Loss: 0.0102, Val R2: 0.9881, Val MAPE: 0.0957, Val RMSE: 13.7792, Val MAE: 10.3486, Val MSE: 189.8654\n",
      "Epoch [31/200], Train Loss: 0.0112, Val Loss: 0.0167, Val R2: 0.9806, Val MAPE: 0.1025, Val RMSE: 17.6270, Val MAE: 12.8177, Val MSE: 310.7124\n",
      "Epoch [32/200], Train Loss: 0.0183, Val Loss: 0.0319, Val R2: 0.9630, Val MAPE: 0.1988, Val RMSE: 24.3436, Val MAE: 20.6193, Val MSE: 592.6125\n",
      "Epoch [33/200], Train Loss: 0.0175, Val Loss: 0.0245, Val R2: 0.9716, Val MAPE: 0.2260, Val RMSE: 21.3343, Val MAE: 18.2083, Val MSE: 455.1520\n",
      "Epoch [34/200], Train Loss: 0.0158, Val Loss: 0.0193, Val R2: 0.9776, Val MAPE: 0.1549, Val RMSE: 18.9325, Val MAE: 15.1387, Val MSE: 358.4404\n",
      "Epoch [35/200], Train Loss: 0.0357, Val Loss: 0.0206, Val R2: 0.9762, Val MAPE: 0.1538, Val RMSE: 19.5438, Val MAE: 14.5913, Val MSE: 381.9608\n",
      "Epoch [36/200], Train Loss: 0.0146, Val Loss: 0.0123, Val R2: 0.9858, Val MAPE: 0.1138, Val RMSE: 15.0914, Val MAE: 11.5841, Val MSE: 227.7506\n",
      "Epoch [37/200], Train Loss: 0.0115, Val Loss: 0.0133, Val R2: 0.9846, Val MAPE: 0.1047, Val RMSE: 15.7223, Val MAE: 11.9813, Val MSE: 247.1895\n",
      "Epoch [38/200], Train Loss: 0.0087, Val Loss: 0.0099, Val R2: 0.9886, Val MAPE: 0.0873, Val RMSE: 13.5426, Val MAE: 10.1161, Val MSE: 183.4009\n",
      "Epoch [39/200], Train Loss: 0.0093, Val Loss: 0.0127, Val R2: 0.9852, Val MAPE: 0.1099, Val RMSE: 15.3778, Val MAE: 12.0415, Val MSE: 236.4776\n",
      "Epoch [40/200], Train Loss: 0.0131, Val Loss: 0.0128, Val R2: 0.9852, Val MAPE: 0.1028, Val RMSE: 15.3916, Val MAE: 11.3130, Val MSE: 236.9016\n",
      "Epoch [41/200], Train Loss: 0.0111, Val Loss: 0.0168, Val R2: 0.9805, Val MAPE: 0.1274, Val RMSE: 17.6744, Val MAE: 13.5614, Val MSE: 312.3834\n",
      "Epoch [42/200], Train Loss: 0.0106, Val Loss: 0.0195, Val R2: 0.9774, Val MAPE: 0.1430, Val RMSE: 19.0292, Val MAE: 14.6341, Val MSE: 362.1115\n",
      "Epoch [43/200], Train Loss: 0.0134, Val Loss: 0.0230, Val R2: 0.9734, Val MAPE: 0.1389, Val RMSE: 20.6369, Val MAE: 15.6073, Val MSE: 425.8825\n",
      "Epoch [44/200], Train Loss: 0.0175, Val Loss: 0.0280, Val R2: 0.9676, Val MAPE: 0.1397, Val RMSE: 22.7948, Val MAE: 17.6250, Val MSE: 519.6026\n",
      "Epoch [45/200], Train Loss: 0.0201, Val Loss: 0.0282, Val R2: 0.9673, Val MAPE: 0.2335, Val RMSE: 22.8815, Val MAE: 19.0812, Val MSE: 523.5640\n",
      "Epoch [46/200], Train Loss: 0.0138, Val Loss: 0.0300, Val R2: 0.9653, Val MAPE: 0.1319, Val RMSE: 23.5746, Val MAE: 17.3216, Val MSE: 555.7626\n",
      "Epoch [47/200], Train Loss: 0.0563, Val Loss: 0.0219, Val R2: 0.9746, Val MAPE: 0.1609, Val RMSE: 20.1757, Val MAE: 15.2944, Val MSE: 407.0577\n",
      "Epoch [48/200], Train Loss: 0.0379, Val Loss: 0.0363, Val R2: 0.9580, Val MAPE: 0.2685, Val RMSE: 25.9331, Val MAE: 22.3502, Val MSE: 672.5238\n",
      "Epoch [49/200], Train Loss: 0.0480, Val Loss: 0.0229, Val R2: 0.9734, Val MAPE: 0.2304, Val RMSE: 20.6250, Val MAE: 16.6209, Val MSE: 425.3893\n",
      "Epoch [50/200], Train Loss: 0.0315, Val Loss: 0.0372, Val R2: 0.9569, Val MAPE: 0.2609, Val RMSE: 26.2838, Val MAE: 22.5350, Val MSE: 690.8383\n",
      "Epoch [51/200], Train Loss: 0.0240, Val Loss: 0.0117, Val R2: 0.9864, Val MAPE: 0.1222, Val RMSE: 14.7464, Val MAE: 11.3145, Val MSE: 217.4561\n",
      "Epoch [52/200], Train Loss: 0.0128, Val Loss: 0.0103, Val R2: 0.9881, Val MAPE: 0.0856, Val RMSE: 13.7954, Val MAE: 10.0720, Val MSE: 190.3131\n",
      "Epoch [53/200], Train Loss: 0.0130, Val Loss: 0.0135, Val R2: 0.9844, Val MAPE: 0.1295, Val RMSE: 15.8017, Val MAE: 12.3479, Val MSE: 249.6923\n",
      "Epoch [54/200], Train Loss: 0.0098, Val Loss: 0.0139, Val R2: 0.9839, Val MAPE: 0.1086, Val RMSE: 16.0420, Val MAE: 11.7328, Val MSE: 257.3463\n",
      "Epoch [55/200], Train Loss: 0.0111, Val Loss: 0.0192, Val R2: 0.9777, Val MAPE: 0.0930, Val RMSE: 18.8827, Val MAE: 12.8493, Val MSE: 356.5573\n",
      "Epoch [56/200], Train Loss: 0.0123, Val Loss: 0.0119, Val R2: 0.9862, Val MAPE: 0.0903, Val RMSE: 14.8615, Val MAE: 10.8321, Val MSE: 220.8635\n",
      "Epoch [57/200], Train Loss: 0.0142, Val Loss: 0.0087, Val R2: 0.9899, Val MAPE: 0.0752, Val RMSE: 12.7037, Val MAE: 8.8231, Val MSE: 161.3850\n",
      "Epoch [58/200], Train Loss: 0.0143, Val Loss: 0.0275, Val R2: 0.9682, Val MAPE: 0.1447, Val RMSE: 22.5858, Val MAE: 17.0241, Val MSE: 510.1191\n",
      "Epoch [59/200], Train Loss: 0.0173, Val Loss: 0.0111, Val R2: 0.9872, Val MAPE: 0.0920, Val RMSE: 14.3416, Val MAE: 10.6913, Val MSE: 205.6819\n",
      "Epoch [60/200], Train Loss: 0.0113, Val Loss: 0.0139, Val R2: 0.9840, Val MAPE: 0.1094, Val RMSE: 16.0307, Val MAE: 11.9223, Val MSE: 256.9821\n",
      "Epoch [61/200], Train Loss: 0.0081, Val Loss: 0.0130, Val R2: 0.9850, Val MAPE: 0.0952, Val RMSE: 15.5229, Val MAE: 10.9324, Val MSE: 240.9610\n",
      "Epoch [62/200], Train Loss: 0.0098, Val Loss: 0.0203, Val R2: 0.9765, Val MAPE: 0.1027, Val RMSE: 19.3903, Val MAE: 13.5104, Val MSE: 375.9822\n",
      "Epoch [63/200], Train Loss: 0.0108, Val Loss: 0.0098, Val R2: 0.9886, Val MAPE: 0.0811, Val RMSE: 13.4962, Val MAE: 9.7872, Val MSE: 182.1486\n",
      "Epoch [64/200], Train Loss: 0.0114, Val Loss: 0.0141, Val R2: 0.9836, Val MAPE: 0.1022, Val RMSE: 16.2018, Val MAE: 12.0699, Val MSE: 262.4969\n",
      "Epoch [65/200], Train Loss: 0.0106, Val Loss: 0.0096, Val R2: 0.9889, Val MAPE: 0.0960, Val RMSE: 13.3552, Val MAE: 10.3193, Val MSE: 178.3625\n",
      "Epoch [66/200], Train Loss: 0.0068, Val Loss: 0.0127, Val R2: 0.9853, Val MAPE: 0.1033, Val RMSE: 15.3633, Val MAE: 11.2469, Val MSE: 236.0311\n",
      "Epoch [67/200], Train Loss: 0.0081, Val Loss: 0.0110, Val R2: 0.9873, Val MAPE: 0.1099, Val RMSE: 14.2586, Val MAE: 10.9976, Val MSE: 203.3090\n",
      "Epoch [68/200], Train Loss: 0.0074, Val Loss: 0.0126, Val R2: 0.9855, Val MAPE: 0.0807, Val RMSE: 15.2591, Val MAE: 10.5443, Val MSE: 232.8401\n",
      "Epoch [69/200], Train Loss: 0.0073, Val Loss: 0.0109, Val R2: 0.9874, Val MAPE: 0.0958, Val RMSE: 14.2294, Val MAE: 10.8136, Val MSE: 202.4754\n",
      "Epoch [70/200], Train Loss: 0.0053, Val Loss: 0.0116, Val R2: 0.9866, Val MAPE: 0.0867, Val RMSE: 14.6788, Val MAE: 10.5840, Val MSE: 215.4684\n",
      "Epoch [71/200], Train Loss: 0.0061, Val Loss: 0.0100, Val R2: 0.9884, Val MAPE: 0.0824, Val RMSE: 13.6391, Val MAE: 10.0725, Val MSE: 186.0262\n",
      "Epoch [72/200], Train Loss: 0.0056, Val Loss: 0.0097, Val R2: 0.9888, Val MAPE: 0.0926, Val RMSE: 13.4112, Val MAE: 10.0932, Val MSE: 179.8599\n",
      "Epoch [73/200], Train Loss: 0.0049, Val Loss: 0.0099, Val R2: 0.9886, Val MAPE: 0.0827, Val RMSE: 13.5376, Val MAE: 10.0184, Val MSE: 183.2668\n",
      "Epoch [74/200], Train Loss: 0.0044, Val Loss: 0.0087, Val R2: 0.9900, Val MAPE: 0.0831, Val RMSE: 12.6867, Val MAE: 9.2930, Val MSE: 160.9519\n",
      "Epoch [75/200], Train Loss: 0.0031, Val Loss: 0.0084, Val R2: 0.9903, Val MAPE: 0.0765, Val RMSE: 12.4949, Val MAE: 8.8411, Val MSE: 156.1226\n",
      "Epoch [76/200], Train Loss: 0.0031, Val Loss: 0.0089, Val R2: 0.9897, Val MAPE: 0.0858, Val RMSE: 12.8751, Val MAE: 9.3744, Val MSE: 165.7679\n",
      "Epoch [77/200], Train Loss: 0.0029, Val Loss: 0.0091, Val R2: 0.9895, Val MAPE: 0.0796, Val RMSE: 12.9986, Val MAE: 9.5079, Val MSE: 168.9644\n",
      "Epoch [78/200], Train Loss: 0.0029, Val Loss: 0.0093, Val R2: 0.9893, Val MAPE: 0.0863, Val RMSE: 13.1185, Val MAE: 9.6929, Val MSE: 172.0946\n",
      "Epoch [79/200], Train Loss: 0.0029, Val Loss: 0.0087, Val R2: 0.9899, Val MAPE: 0.0843, Val RMSE: 12.6918, Val MAE: 9.1468, Val MSE: 161.0827\n",
      "Epoch [80/200], Train Loss: 0.0032, Val Loss: 0.0091, Val R2: 0.9895, Val MAPE: 0.0905, Val RMSE: 12.9761, Val MAE: 9.7395, Val MSE: 168.3803\n",
      "Epoch [81/200], Train Loss: 0.0027, Val Loss: 0.0095, Val R2: 0.9890, Val MAPE: 0.0774, Val RMSE: 13.2708, Val MAE: 9.4255, Val MSE: 176.1131\n",
      "Epoch [82/200], Train Loss: 0.0029, Val Loss: 0.0085, Val R2: 0.9902, Val MAPE: 0.0756, Val RMSE: 12.5583, Val MAE: 8.9381, Val MSE: 157.7116\n",
      "Epoch [83/200], Train Loss: 0.0024, Val Loss: 0.0090, Val R2: 0.9895, Val MAPE: 0.0860, Val RMSE: 12.9557, Val MAE: 9.3742, Val MSE: 167.8496\n",
      "Epoch [84/200], Train Loss: 0.0025, Val Loss: 0.0086, Val R2: 0.9900, Val MAPE: 0.0773, Val RMSE: 12.6426, Val MAE: 9.0858, Val MSE: 159.8345\n",
      "Epoch [85/200], Train Loss: 0.0024, Val Loss: 0.0079, Val R2: 0.9908, Val MAPE: 0.0749, Val RMSE: 12.1221, Val MAE: 8.7199, Val MSE: 146.9442\n",
      "Epoch [86/200], Train Loss: 0.0025, Val Loss: 0.0085, Val R2: 0.9902, Val MAPE: 0.0740, Val RMSE: 12.5480, Val MAE: 8.8424, Val MSE: 157.4528\n",
      "Epoch [87/200], Train Loss: 0.0023, Val Loss: 0.0088, Val R2: 0.9898, Val MAPE: 0.0779, Val RMSE: 12.8064, Val MAE: 9.3232, Val MSE: 164.0049\n",
      "Epoch [88/200], Train Loss: 0.0024, Val Loss: 0.0091, Val R2: 0.9894, Val MAPE: 0.0877, Val RMSE: 13.0021, Val MAE: 9.6717, Val MSE: 169.0538\n",
      "Epoch [89/200], Train Loss: 0.0025, Val Loss: 0.0090, Val R2: 0.9896, Val MAPE: 0.0741, Val RMSE: 12.9141, Val MAE: 9.1965, Val MSE: 166.7738\n",
      "Epoch [90/200], Train Loss: 0.0028, Val Loss: 0.0094, Val R2: 0.9891, Val MAPE: 0.0977, Val RMSE: 13.2134, Val MAE: 10.2694, Val MSE: 174.5946\n",
      "Epoch [91/200], Train Loss: 0.0023, Val Loss: 0.0087, Val R2: 0.9899, Val MAPE: 0.0770, Val RMSE: 12.7243, Val MAE: 9.1437, Val MSE: 161.9071\n",
      "Epoch [92/200], Train Loss: 0.0024, Val Loss: 0.0083, Val R2: 0.9904, Val MAPE: 0.0722, Val RMSE: 12.3906, Val MAE: 8.5673, Val MSE: 153.5281\n",
      "Epoch [93/200], Train Loss: 0.0024, Val Loss: 0.0095, Val R2: 0.9890, Val MAPE: 0.0867, Val RMSE: 13.2637, Val MAE: 10.2410, Val MSE: 175.9257\n",
      "Epoch [94/200], Train Loss: 0.0031, Val Loss: 0.0079, Val R2: 0.9909, Val MAPE: 0.0706, Val RMSE: 12.1004, Val MAE: 8.4132, Val MSE: 146.4205\n",
      "Epoch [95/200], Train Loss: 0.0018, Val Loss: 0.0081, Val R2: 0.9906, Val MAPE: 0.0754, Val RMSE: 12.2446, Val MAE: 8.6350, Val MSE: 149.9302\n",
      "Epoch [96/200], Train Loss: 0.0019, Val Loss: 0.0075, Val R2: 0.9913, Val MAPE: 0.0715, Val RMSE: 11.8175, Val MAE: 8.4588, Val MSE: 139.6535\n",
      "Epoch [97/200], Train Loss: 0.0017, Val Loss: 0.0074, Val R2: 0.9914, Val MAPE: 0.0750, Val RMSE: 11.7320, Val MAE: 8.4884, Val MSE: 137.6397\n",
      "Epoch [98/200], Train Loss: 0.0015, Val Loss: 0.0077, Val R2: 0.9911, Val MAPE: 0.0717, Val RMSE: 11.9633, Val MAE: 8.3469, Val MSE: 143.1214\n",
      "Epoch [99/200], Train Loss: 0.0017, Val Loss: 0.0076, Val R2: 0.9912, Val MAPE: 0.0767, Val RMSE: 11.8917, Val MAE: 8.6336, Val MSE: 141.4123\n",
      "Epoch [100/200], Train Loss: 0.0017, Val Loss: 0.0078, Val R2: 0.9910, Val MAPE: 0.0714, Val RMSE: 11.9934, Val MAE: 8.6766, Val MSE: 143.8425\n",
      "Epoch [101/200], Train Loss: 0.0018, Val Loss: 0.0082, Val R2: 0.9905, Val MAPE: 0.0718, Val RMSE: 12.3535, Val MAE: 8.5931, Val MSE: 152.6078\n",
      "Epoch [102/200], Train Loss: 0.0018, Val Loss: 0.0075, Val R2: 0.9913, Val MAPE: 0.0709, Val RMSE: 11.8293, Val MAE: 8.4579, Val MSE: 139.9331\n",
      "Epoch [103/200], Train Loss: 0.0017, Val Loss: 0.0078, Val R2: 0.9910, Val MAPE: 0.0802, Val RMSE: 12.0274, Val MAE: 8.9029, Val MSE: 144.6589\n",
      "Epoch [104/200], Train Loss: 0.0015, Val Loss: 0.0075, Val R2: 0.9913, Val MAPE: 0.0706, Val RMSE: 11.7953, Val MAE: 8.3147, Val MSE: 139.1299\n",
      "Epoch [105/200], Train Loss: 0.0014, Val Loss: 0.0078, Val R2: 0.9909, Val MAPE: 0.0771, Val RMSE: 12.0650, Val MAE: 8.7687, Val MSE: 145.5641\n",
      "Epoch [106/200], Train Loss: 0.0014, Val Loss: 0.0073, Val R2: 0.9915, Val MAPE: 0.0698, Val RMSE: 11.6627, Val MAE: 8.2788, Val MSE: 136.0175\n",
      "Epoch [107/200], Train Loss: 0.0013, Val Loss: 0.0075, Val R2: 0.9914, Val MAPE: 0.0690, Val RMSE: 11.7605, Val MAE: 7.9873, Val MSE: 138.3086\n",
      "Epoch [108/200], Train Loss: 0.0014, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0714, Val RMSE: 11.4604, Val MAE: 8.4604, Val MSE: 131.3415\n",
      "Epoch [109/200], Train Loss: 0.0015, Val Loss: 0.0075, Val R2: 0.9913, Val MAPE: 0.0688, Val RMSE: 11.8350, Val MAE: 7.9891, Val MSE: 140.0665\n",
      "Epoch [110/200], Train Loss: 0.0013, Val Loss: 0.0075, Val R2: 0.9913, Val MAPE: 0.0720, Val RMSE: 11.7954, Val MAE: 8.3022, Val MSE: 139.1313\n",
      "Epoch [111/200], Train Loss: 0.0012, Val Loss: 0.0076, Val R2: 0.9912, Val MAPE: 0.0716, Val RMSE: 11.8860, Val MAE: 8.4771, Val MSE: 141.2766\n",
      "Epoch [112/200], Train Loss: 0.0012, Val Loss: 0.0080, Val R2: 0.9908, Val MAPE: 0.0706, Val RMSE: 12.1708, Val MAE: 8.3531, Val MSE: 148.1294\n",
      "Epoch [113/200], Train Loss: 0.0013, Val Loss: 0.0074, Val R2: 0.9914, Val MAPE: 0.0724, Val RMSE: 11.7162, Val MAE: 8.5617, Val MSE: 137.2695\n",
      "Epoch [114/200], Train Loss: 0.0012, Val Loss: 0.0076, Val R2: 0.9912, Val MAPE: 0.0698, Val RMSE: 11.8646, Val MAE: 8.1806, Val MSE: 140.7684\n",
      "Epoch [115/200], Train Loss: 0.0012, Val Loss: 0.0072, Val R2: 0.9916, Val MAPE: 0.0694, Val RMSE: 11.5911, Val MAE: 8.1968, Val MSE: 134.3535\n",
      "Epoch [116/200], Train Loss: 0.0010, Val Loss: 0.0075, Val R2: 0.9913, Val MAPE: 0.0688, Val RMSE: 11.8329, Val MAE: 8.1815, Val MSE: 140.0170\n",
      "Epoch [117/200], Train Loss: 0.0010, Val Loss: 0.0075, Val R2: 0.9913, Val MAPE: 0.0713, Val RMSE: 11.7980, Val MAE: 8.3533, Val MSE: 139.1939\n",
      "Epoch [118/200], Train Loss: 0.0012, Val Loss: 0.0073, Val R2: 0.9915, Val MAPE: 0.0686, Val RMSE: 11.6479, Val MAE: 8.1623, Val MSE: 135.6731\n",
      "Epoch [119/200], Train Loss: 0.0010, Val Loss: 0.0074, Val R2: 0.9914, Val MAPE: 0.0692, Val RMSE: 11.7071, Val MAE: 8.0572, Val MSE: 137.0570\n",
      "Epoch [120/200], Train Loss: 0.0010, Val Loss: 0.0073, Val R2: 0.9915, Val MAPE: 0.0709, Val RMSE: 11.6558, Val MAE: 8.2555, Val MSE: 135.8579\n",
      "Epoch [121/200], Train Loss: 0.0010, Val Loss: 0.0074, Val R2: 0.9914, Val MAPE: 0.0684, Val RMSE: 11.7427, Val MAE: 8.1036, Val MSE: 137.8921\n",
      "Epoch [122/200], Train Loss: 0.0010, Val Loss: 0.0073, Val R2: 0.9915, Val MAPE: 0.0696, Val RMSE: 11.6732, Val MAE: 8.1763, Val MSE: 136.2631\n",
      "Epoch [123/200], Train Loss: 0.0008, Val Loss: 0.0074, Val R2: 0.9914, Val MAPE: 0.0683, Val RMSE: 11.7341, Val MAE: 8.1557, Val MSE: 137.6883\n",
      "Epoch [124/200], Train Loss: 0.0009, Val Loss: 0.0073, Val R2: 0.9915, Val MAPE: 0.0703, Val RMSE: 11.6678, Val MAE: 8.2896, Val MSE: 136.1367\n",
      "Epoch [125/200], Train Loss: 0.0010, Val Loss: 0.0074, Val R2: 0.9914, Val MAPE: 0.0692, Val RMSE: 11.7502, Val MAE: 8.1104, Val MSE: 138.0673\n",
      "Epoch [126/200], Train Loss: 0.0010, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0679, Val RMSE: 11.4868, Val MAE: 8.0092, Val MSE: 131.9469\n",
      "Epoch [127/200], Train Loss: 0.0009, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0682, Val RMSE: 11.3470, Val MAE: 7.9146, Val MSE: 128.7550\n",
      "Epoch [128/200], Train Loss: 0.0009, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0666, Val RMSE: 11.3510, Val MAE: 7.8449, Val MSE: 128.8443\n",
      "Epoch [129/200], Train Loss: 0.0008, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0677, Val RMSE: 11.4881, Val MAE: 7.9485, Val MSE: 131.9772\n",
      "Epoch [130/200], Train Loss: 0.0008, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0686, Val RMSE: 11.4767, Val MAE: 8.0709, Val MSE: 131.7142\n",
      "Epoch [131/200], Train Loss: 0.0008, Val Loss: 0.0072, Val R2: 0.9916, Val MAPE: 0.0671, Val RMSE: 11.5913, Val MAE: 7.9651, Val MSE: 134.3573\n",
      "Epoch [132/200], Train Loss: 0.0009, Val Loss: 0.0073, Val R2: 0.9915, Val MAPE: 0.0677, Val RMSE: 11.6536, Val MAE: 8.0528, Val MSE: 135.8069\n",
      "Epoch [133/200], Train Loss: 0.0008, Val Loss: 0.0073, Val R2: 0.9915, Val MAPE: 0.0686, Val RMSE: 11.6369, Val MAE: 8.0115, Val MSE: 135.4170\n",
      "Epoch [134/200], Train Loss: 0.0009, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0682, Val RMSE: 11.4793, Val MAE: 7.9916, Val MSE: 131.7745\n",
      "Epoch [135/200], Train Loss: 0.0007, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0664, Val RMSE: 11.4638, Val MAE: 7.9015, Val MSE: 131.4196\n",
      "Epoch [136/200], Train Loss: 0.0009, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0670, Val RMSE: 11.4037, Val MAE: 7.9478, Val MSE: 130.0450\n",
      "Epoch [137/200], Train Loss: 0.0007, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0672, Val RMSE: 11.4751, Val MAE: 7.8917, Val MSE: 131.6786\n",
      "Epoch [138/200], Train Loss: 0.0008, Val Loss: 0.0071, Val R2: 0.9917, Val MAPE: 0.0670, Val RMSE: 11.5109, Val MAE: 7.8666, Val MSE: 132.5012\n",
      "Epoch [139/200], Train Loss: 0.0008, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0676, Val RMSE: 11.4549, Val MAE: 8.1263, Val MSE: 131.2146\n",
      "Epoch [140/200], Train Loss: 0.0008, Val Loss: 0.0072, Val R2: 0.9916, Val MAPE: 0.0669, Val RMSE: 11.5895, Val MAE: 7.8911, Val MSE: 134.3170\n",
      "Epoch [141/200], Train Loss: 0.0008, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0677, Val RMSE: 11.4003, Val MAE: 7.9989, Val MSE: 129.9671\n",
      "Epoch [142/200], Train Loss: 0.0008, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0665, Val RMSE: 11.3717, Val MAE: 7.8726, Val MSE: 129.3153\n",
      "Epoch [143/200], Train Loss: 0.0007, Val Loss: 0.0073, Val R2: 0.9916, Val MAPE: 0.0666, Val RMSE: 11.6049, Val MAE: 7.8603, Val MSE: 134.6729\n",
      "Epoch [144/200], Train Loss: 0.0008, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0686, Val RMSE: 11.4942, Val MAE: 8.0958, Val MSE: 132.1168\n",
      "Epoch [145/200], Train Loss: 0.0007, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0678, Val RMSE: 11.4641, Val MAE: 7.9272, Val MSE: 131.4253\n",
      "Epoch [146/200], Train Loss: 0.0008, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0661, Val RMSE: 11.4681, Val MAE: 7.7988, Val MSE: 131.5170\n",
      "Epoch [147/200], Train Loss: 0.0007, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0658, Val RMSE: 11.3677, Val MAE: 7.7791, Val MSE: 129.2257\n",
      "Epoch [148/200], Train Loss: 0.0007, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0676, Val RMSE: 11.4023, Val MAE: 7.9220, Val MSE: 130.0120\n",
      "Epoch [149/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0662, Val RMSE: 11.3411, Val MAE: 7.7464, Val MSE: 128.6206\n",
      "Epoch [150/200], Train Loss: 0.0007, Val Loss: 0.0068, Val R2: 0.9922, Val MAPE: 0.0653, Val RMSE: 11.1968, Val MAE: 7.6820, Val MSE: 125.3675\n",
      "Epoch [151/200], Train Loss: 0.0007, Val Loss: 0.0068, Val R2: 0.9922, Val MAPE: 0.0656, Val RMSE: 11.2114, Val MAE: 7.7484, Val MSE: 125.6960\n",
      "Epoch [152/200], Train Loss: 0.0007, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0658, Val RMSE: 11.3448, Val MAE: 7.7630, Val MSE: 128.7048\n",
      "Epoch [153/200], Train Loss: 0.0007, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0656, Val RMSE: 11.3306, Val MAE: 7.7319, Val MSE: 128.3834\n",
      "Epoch [154/200], Train Loss: 0.0007, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0661, Val RMSE: 11.3016, Val MAE: 7.7914, Val MSE: 127.7253\n",
      "Epoch [155/200], Train Loss: 0.0006, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0661, Val RMSE: 11.3773, Val MAE: 7.7726, Val MSE: 129.4436\n",
      "Epoch [156/200], Train Loss: 0.0006, Val Loss: 0.0071, Val R2: 0.9918, Val MAPE: 0.0662, Val RMSE: 11.4676, Val MAE: 7.7967, Val MSE: 131.5052\n",
      "Epoch [157/200], Train Loss: 0.0007, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0666, Val RMSE: 11.4122, Val MAE: 7.8517, Val MSE: 130.2375\n",
      "Epoch [158/200], Train Loss: 0.0006, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0667, Val RMSE: 11.4211, Val MAE: 7.8790, Val MSE: 130.4422\n",
      "Epoch [159/200], Train Loss: 0.0007, Val Loss: 0.0070, Val R2: 0.9918, Val MAPE: 0.0663, Val RMSE: 11.4300, Val MAE: 7.8521, Val MSE: 130.6445\n",
      "Epoch [160/200], Train Loss: 0.0007, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0661, Val RMSE: 11.4026, Val MAE: 7.8135, Val MSE: 130.0188\n",
      "Epoch [161/200], Train Loss: 0.0007, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0658, Val RMSE: 11.3348, Val MAE: 7.7542, Val MSE: 128.4776\n",
      "Epoch [162/200], Train Loss: 0.0007, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0657, Val RMSE: 11.3348, Val MAE: 7.7237, Val MSE: 128.4770\n",
      "Epoch [163/200], Train Loss: 0.0006, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0657, Val RMSE: 11.3936, Val MAE: 7.7198, Val MSE: 129.8144\n",
      "Epoch [164/200], Train Loss: 0.0007, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0665, Val RMSE: 11.3998, Val MAE: 7.7888, Val MSE: 129.9560\n",
      "Epoch [165/200], Train Loss: 0.0007, Val Loss: 0.0070, Val R2: 0.9919, Val MAPE: 0.0672, Val RMSE: 11.3627, Val MAE: 7.8819, Val MSE: 129.1105\n",
      "Epoch [166/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0667, Val RMSE: 11.3318, Val MAE: 7.8234, Val MSE: 128.4107\n",
      "Epoch [167/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0657, Val RMSE: 11.2979, Val MAE: 7.7222, Val MSE: 127.6418\n",
      "Epoch [168/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9921, Val MAPE: 0.0653, Val RMSE: 11.2800, Val MAE: 7.6855, Val MSE: 127.2381\n",
      "Epoch [169/200], Train Loss: 0.0007, Val Loss: 0.0069, Val R2: 0.9921, Val MAPE: 0.0652, Val RMSE: 11.2765, Val MAE: 7.6814, Val MSE: 127.1589\n",
      "Epoch [170/200], Train Loss: 0.0006, Val Loss: 0.0068, Val R2: 0.9921, Val MAPE: 0.0652, Val RMSE: 11.2618, Val MAE: 7.7048, Val MSE: 126.8292\n",
      "Epoch [171/200], Train Loss: 0.0006, Val Loss: 0.0068, Val R2: 0.9921, Val MAPE: 0.0654, Val RMSE: 11.2674, Val MAE: 7.7309, Val MSE: 126.9533\n",
      "Epoch [172/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0656, Val RMSE: 11.2895, Val MAE: 7.7439, Val MSE: 127.4521\n",
      "Epoch [173/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0658, Val RMSE: 11.3074, Val MAE: 7.7494, Val MSE: 127.8571\n",
      "Epoch [174/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0660, Val RMSE: 11.3088, Val MAE: 7.7505, Val MSE: 127.8883\n",
      "Epoch [175/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0657, Val RMSE: 11.3158, Val MAE: 7.7207, Val MSE: 128.0473\n",
      "Epoch [176/200], Train Loss: 0.0007, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0655, Val RMSE: 11.3062, Val MAE: 7.7024, Val MSE: 127.8303\n",
      "Epoch [177/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9921, Val MAPE: 0.0654, Val RMSE: 11.2790, Val MAE: 7.6966, Val MSE: 127.2147\n",
      "Epoch [178/200], Train Loss: 0.0006, Val Loss: 0.0068, Val R2: 0.9921, Val MAPE: 0.0652, Val RMSE: 11.2648, Val MAE: 7.6929, Val MSE: 126.8956\n",
      "Epoch [179/200], Train Loss: 0.0006, Val Loss: 0.0068, Val R2: 0.9921, Val MAPE: 0.0651, Val RMSE: 11.2608, Val MAE: 7.6919, Val MSE: 126.8048\n",
      "Epoch [180/200], Train Loss: 0.0005, Val Loss: 0.0068, Val R2: 0.9921, Val MAPE: 0.0651, Val RMSE: 11.2601, Val MAE: 7.6966, Val MSE: 126.7892\n",
      "Epoch [181/200], Train Loss: 0.0006, Val Loss: 0.0068, Val R2: 0.9921, Val MAPE: 0.0651, Val RMSE: 11.2620, Val MAE: 7.7058, Val MSE: 126.8322\n",
      "Epoch [182/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9921, Val MAPE: 0.0652, Val RMSE: 11.2758, Val MAE: 7.6996, Val MSE: 127.1443\n",
      "Epoch [183/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0652, Val RMSE: 11.2922, Val MAE: 7.6960, Val MSE: 127.5147\n",
      "Epoch [184/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0653, Val RMSE: 11.3044, Val MAE: 7.6997, Val MSE: 127.7902\n",
      "Epoch [185/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.3054, Val MAE: 7.7039, Val MSE: 127.8132\n",
      "Epoch [186/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.3054, Val MAE: 7.7051, Val MSE: 127.8115\n",
      "Epoch [187/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.3014, Val MAE: 7.7067, Val MSE: 127.7225\n",
      "Epoch [188/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.2977, Val MAE: 7.7083, Val MSE: 127.6376\n",
      "Epoch [189/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.2962, Val MAE: 7.7053, Val MSE: 127.6049\n",
      "Epoch [190/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.2953, Val MAE: 7.7066, Val MSE: 127.5827\n",
      "Epoch [191/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.2932, Val MAE: 7.7064, Val MSE: 127.5358\n",
      "Epoch [192/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.2912, Val MAE: 7.7071, Val MSE: 127.4921\n",
      "Epoch [193/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.2908, Val MAE: 7.7076, Val MSE: 127.4820\n",
      "Epoch [194/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0654, Val RMSE: 11.2916, Val MAE: 7.7079, Val MSE: 127.4992\n",
      "Epoch [195/200], Train Loss: 0.0005, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0653, Val RMSE: 11.2910, Val MAE: 7.7065, Val MSE: 127.4869\n",
      "Epoch [196/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0653, Val RMSE: 11.2913, Val MAE: 7.7063, Val MSE: 127.4934\n",
      "Epoch [197/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0653, Val RMSE: 11.2914, Val MAE: 7.7062, Val MSE: 127.4959\n",
      "Epoch [198/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0653, Val RMSE: 11.2915, Val MAE: 7.7062, Val MSE: 127.4970\n",
      "Epoch [199/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0653, Val RMSE: 11.2916, Val MAE: 7.7061, Val MSE: 127.4992\n",
      "Epoch [200/200], Train Loss: 0.0006, Val Loss: 0.0069, Val R2: 0.9920, Val MAPE: 0.0653, Val RMSE: 11.2913, Val MAE: 7.7060, Val MSE: 127.4935\n",
      "Training complete!\n",
      "Test (Normalized) Loss: 0.0069, Test R2: 0.9920, Test MAPE: 0.0653, Test RMSE: 11.2913, Test MAE: 7.7060, Test MSE: 127.4935\n",
      "Random seed set as 0\n",
      "Epoch [1/200], Train Loss: 1.1353, Val Loss: 0.9817, Val R2: -0.0400, Val MAPE: 1.5543, Val RMSE: 133.8823, Val MAE: 121.3297, Val MSE: 17924.4785\n",
      "Epoch [2/200], Train Loss: 1.1594, Val Loss: 0.9236, Val R2: 0.0215, Val MAPE: 1.4100, Val RMSE: 129.8595, Val MAE: 117.9635, Val MSE: 16863.4824\n",
      "Epoch [3/200], Train Loss: 1.0380, Val Loss: 1.1956, Val R2: -0.2666, Val MAPE: 0.7565, Val RMSE: 147.7466, Val MAE: 112.9701, Val MSE: 21829.0684\n",
      "Epoch [4/200], Train Loss: 1.0831, Val Loss: 0.8557, Val R2: 0.0935, Val MAPE: 1.3740, Val RMSE: 124.9969, Val MAE: 113.5288, Val MSE: 15624.2373\n",
      "Epoch [5/200], Train Loss: 1.0173, Val Loss: 0.7438, Val R2: 0.2121, Val MAPE: 1.2268, Val RMSE: 116.5317, Val MAE: 106.0884, Val MSE: 13579.6338\n",
      "Epoch [6/200], Train Loss: 0.7811, Val Loss: 0.5818, Val R2: 0.3837, Val MAPE: 0.6437, Val RMSE: 103.0651, Val MAE: 82.3482, Val MSE: 10622.4199\n",
      "Epoch [7/200], Train Loss: 0.5292, Val Loss: 0.2388, Val R2: 0.7470, Val MAPE: 0.4163, Val RMSE: 66.0318, Val MAE: 52.9221, Val MSE: 4360.2002\n",
      "Epoch [8/200], Train Loss: 0.2761, Val Loss: 0.3075, Val R2: 0.6742, Val MAPE: 0.4737, Val RMSE: 74.9342, Val MAE: 57.9267, Val MSE: 5615.1396\n",
      "Epoch [9/200], Train Loss: 0.3182, Val Loss: 0.1624, Val R2: 0.8279, Val MAPE: 0.3126, Val RMSE: 54.4563, Val MAE: 41.3893, Val MSE: 2965.4910\n",
      "Epoch [10/200], Train Loss: 0.2226, Val Loss: 0.2174, Val R2: 0.7697, Val MAPE: 0.2577, Val RMSE: 63.0069, Val MAE: 45.6962, Val MSE: 3969.8704\n",
      "Epoch [11/200], Train Loss: 0.1914, Val Loss: 0.1878, Val R2: 0.8011, Val MAPE: 0.3032, Val RMSE: 58.5519, Val MAE: 37.3520, Val MSE: 3428.3257\n",
      "Epoch [12/200], Train Loss: 0.1632, Val Loss: 0.1974, Val R2: 0.7909, Val MAPE: 0.2377, Val RMSE: 60.0300, Val MAE: 39.7380, Val MSE: 3603.6030\n",
      "Epoch [13/200], Train Loss: 0.1986, Val Loss: 0.1213, Val R2: 0.8716, Val MAPE: 0.1889, Val RMSE: 47.0512, Val MAE: 28.9287, Val MSE: 2213.8152\n",
      "Epoch [14/200], Train Loss: 0.1083, Val Loss: 0.1387, Val R2: 0.8531, Val MAPE: 0.2992, Val RMSE: 50.3250, Val MAE: 35.2800, Val MSE: 2532.6079\n",
      "Epoch [15/200], Train Loss: 0.2116, Val Loss: 0.0855, Val R2: 0.9094, Val MAPE: 0.2477, Val RMSE: 39.5148, Val MAE: 30.1164, Val MSE: 1561.4203\n",
      "Epoch [16/200], Train Loss: 0.2252, Val Loss: 0.2513, Val R2: 0.7338, Val MAPE: 0.3434, Val RMSE: 67.7298, Val MAE: 51.7041, Val MSE: 4587.3281\n",
      "Epoch [17/200], Train Loss: 0.2033, Val Loss: 0.1661, Val R2: 0.8241, Val MAPE: 0.3063, Val RMSE: 55.0651, Val MAE: 40.1282, Val MSE: 3032.1667\n",
      "Epoch [18/200], Train Loss: 0.1117, Val Loss: 0.0908, Val R2: 0.9038, Val MAPE: 0.1965, Val RMSE: 40.7111, Val MAE: 30.7705, Val MSE: 1657.3905\n",
      "Epoch [19/200], Train Loss: 0.0572, Val Loss: 0.0545, Val R2: 0.9423, Val MAPE: 0.1708, Val RMSE: 31.5340, Val MAE: 24.7553, Val MSE: 994.3932\n",
      "Epoch [20/200], Train Loss: 0.0446, Val Loss: 0.0721, Val R2: 0.9236, Val MAPE: 0.1392, Val RMSE: 36.2855, Val MAE: 24.7222, Val MSE: 1316.6376\n",
      "Epoch [21/200], Train Loss: 0.0376, Val Loss: 0.0668, Val R2: 0.9292, Val MAPE: 0.1949, Val RMSE: 34.9323, Val MAE: 26.5227, Val MSE: 1220.2635\n",
      "Epoch [22/200], Train Loss: 0.0473, Val Loss: 0.0830, Val R2: 0.9120, Val MAPE: 0.1448, Val RMSE: 38.9349, Val MAE: 26.2221, Val MSE: 1515.9240\n",
      "Epoch [23/200], Train Loss: 0.0406, Val Loss: 0.0509, Val R2: 0.9461, Val MAPE: 0.1275, Val RMSE: 30.4835, Val MAE: 21.1133, Val MSE: 929.2440\n",
      "Epoch [24/200], Train Loss: 0.0384, Val Loss: 0.1137, Val R2: 0.8795, Val MAPE: 0.3470, Val RMSE: 45.5693, Val MAE: 36.6603, Val MSE: 2076.5581\n",
      "Epoch [25/200], Train Loss: 0.0348, Val Loss: 0.0413, Val R2: 0.9562, Val MAPE: 0.2295, Val RMSE: 27.4709, Val MAE: 23.8260, Val MSE: 754.6508\n",
      "Epoch [26/200], Train Loss: 0.0305, Val Loss: 0.0827, Val R2: 0.9124, Val MAPE: 0.1488, Val RMSE: 38.8565, Val MAE: 25.6022, Val MSE: 1509.8278\n",
      "Epoch [27/200], Train Loss: 0.0224, Val Loss: 0.0449, Val R2: 0.9524, Val MAPE: 0.2174, Val RMSE: 28.6383, Val MAE: 23.0282, Val MSE: 820.1550\n",
      "Epoch [28/200], Train Loss: 0.0217, Val Loss: 0.0628, Val R2: 0.9335, Val MAPE: 0.1380, Val RMSE: 33.8583, Val MAE: 23.3493, Val MSE: 1146.3854\n",
      "Epoch [29/200], Train Loss: 0.0208, Val Loss: 0.0441, Val R2: 0.9533, Val MAPE: 0.1206, Val RMSE: 28.3798, Val MAE: 20.6323, Val MSE: 805.4144\n",
      "Epoch [30/200], Train Loss: 0.0133, Val Loss: 0.0556, Val R2: 0.9411, Val MAPE: 0.1472, Val RMSE: 31.8636, Val MAE: 21.8235, Val MSE: 1015.2874\n",
      "Epoch [31/200], Train Loss: 0.0147, Val Loss: 0.0509, Val R2: 0.9461, Val MAPE: 0.1278, Val RMSE: 30.4871, Val MAE: 21.0526, Val MSE: 929.4648\n",
      "Epoch [32/200], Train Loss: 0.0130, Val Loss: 0.0367, Val R2: 0.9612, Val MAPE: 0.0937, Val RMSE: 25.8756, Val MAE: 17.8406, Val MSE: 669.5446\n",
      "Epoch [33/200], Train Loss: 0.0109, Val Loss: 0.0573, Val R2: 0.9393, Val MAPE: 0.1149, Val RMSE: 32.3434, Val MAE: 21.0345, Val MSE: 1046.0931\n",
      "Epoch [34/200], Train Loss: 0.0121, Val Loss: 0.0518, Val R2: 0.9451, Val MAPE: 0.1280, Val RMSE: 30.7681, Val MAE: 21.4545, Val MSE: 946.6747\n",
      "Epoch [35/200], Train Loss: 0.0152, Val Loss: 0.0545, Val R2: 0.9423, Val MAPE: 0.1027, Val RMSE: 31.5344, Val MAE: 19.9228, Val MSE: 994.4196\n",
      "Epoch [36/200], Train Loss: 0.0131, Val Loss: 0.0402, Val R2: 0.9575, Val MAPE: 0.0985, Val RMSE: 27.0762, Val MAE: 18.5353, Val MSE: 733.1197\n",
      "Epoch [37/200], Train Loss: 0.0119, Val Loss: 0.0479, Val R2: 0.9493, Val MAPE: 0.1244, Val RMSE: 29.5700, Val MAE: 20.6264, Val MSE: 874.3851\n",
      "Epoch [38/200], Train Loss: 0.0118, Val Loss: 0.0385, Val R2: 0.9592, Val MAPE: 0.0947, Val RMSE: 26.5238, Val MAE: 17.6501, Val MSE: 703.5108\n",
      "Epoch [39/200], Train Loss: 0.0076, Val Loss: 0.0524, Val R2: 0.9445, Val MAPE: 0.0977, Val RMSE: 30.9203, Val MAE: 19.9395, Val MSE: 956.0650\n",
      "Epoch [40/200], Train Loss: 0.0093, Val Loss: 0.0366, Val R2: 0.9612, Val MAPE: 0.0968, Val RMSE: 25.8671, Val MAE: 17.7398, Val MSE: 669.1070\n",
      "Epoch [41/200], Train Loss: 0.0076, Val Loss: 0.0395, Val R2: 0.9582, Val MAPE: 0.0982, Val RMSE: 26.8407, Val MAE: 18.0763, Val MSE: 720.4246\n",
      "Epoch [42/200], Train Loss: 0.0075, Val Loss: 0.0448, Val R2: 0.9525, Val MAPE: 0.0972, Val RMSE: 28.6094, Val MAE: 18.8844, Val MSE: 818.4973\n",
      "Epoch [43/200], Train Loss: 0.0078, Val Loss: 0.0351, Val R2: 0.9628, Val MAPE: 0.0940, Val RMSE: 25.3117, Val MAE: 17.1667, Val MSE: 640.6798\n",
      "Epoch [44/200], Train Loss: 0.0065, Val Loss: 0.0436, Val R2: 0.9538, Val MAPE: 0.0990, Val RMSE: 28.2280, Val MAE: 18.2723, Val MSE: 796.8209\n",
      "Epoch [45/200], Train Loss: 0.0062, Val Loss: 0.0370, Val R2: 0.9608, Val MAPE: 0.0903, Val RMSE: 25.9900, Val MAE: 17.5262, Val MSE: 675.4778\n",
      "Epoch [46/200], Train Loss: 0.0080, Val Loss: 0.0347, Val R2: 0.9632, Val MAPE: 0.0975, Val RMSE: 25.1824, Val MAE: 17.3826, Val MSE: 634.1537\n",
      "Epoch [47/200], Train Loss: 0.0064, Val Loss: 0.0433, Val R2: 0.9541, Val MAPE: 0.1291, Val RMSE: 28.1296, Val MAE: 19.8265, Val MSE: 791.2720\n",
      "Epoch [48/200], Train Loss: 0.0096, Val Loss: 0.0373, Val R2: 0.9605, Val MAPE: 0.1078, Val RMSE: 26.1061, Val MAE: 17.6844, Val MSE: 681.5295\n",
      "Epoch [49/200], Train Loss: 0.0070, Val Loss: 0.0368, Val R2: 0.9610, Val MAPE: 0.0928, Val RMSE: 25.9195, Val MAE: 17.5847, Val MSE: 671.8190\n",
      "Epoch [50/200], Train Loss: 0.0103, Val Loss: 0.0591, Val R2: 0.9374, Val MAPE: 0.1977, Val RMSE: 32.8596, Val MAE: 26.1727, Val MSE: 1079.7518\n",
      "Epoch [51/200], Train Loss: 0.0172, Val Loss: 0.0359, Val R2: 0.9619, Val MAPE: 0.1490, Val RMSE: 25.6170, Val MAE: 19.4603, Val MSE: 656.2313\n",
      "Epoch [52/200], Train Loss: 0.0092, Val Loss: 0.0461, Val R2: 0.9512, Val MAPE: 0.1282, Val RMSE: 29.0067, Val MAE: 20.0103, Val MSE: 841.3874\n",
      "Epoch [53/200], Train Loss: 0.0093, Val Loss: 0.0329, Val R2: 0.9652, Val MAPE: 0.1200, Val RMSE: 24.4953, Val MAE: 17.1708, Val MSE: 600.0212\n",
      "Epoch [54/200], Train Loss: 0.0064, Val Loss: 0.0386, Val R2: 0.9591, Val MAPE: 0.1172, Val RMSE: 26.5567, Val MAE: 18.5153, Val MSE: 705.2599\n",
      "Epoch [55/200], Train Loss: 0.0069, Val Loss: 0.0349, Val R2: 0.9630, Val MAPE: 0.0938, Val RMSE: 25.2562, Val MAE: 17.3876, Val MSE: 637.8777\n",
      "Epoch [56/200], Train Loss: 0.0069, Val Loss: 0.0317, Val R2: 0.9664, Val MAPE: 0.0894, Val RMSE: 24.0679, Val MAE: 15.8880, Val MSE: 579.2640\n",
      "Epoch [57/200], Train Loss: 0.0059, Val Loss: 0.0425, Val R2: 0.9550, Val MAPE: 0.1110, Val RMSE: 27.8551, Val MAE: 18.8404, Val MSE: 775.9086\n",
      "Epoch [58/200], Train Loss: 0.0068, Val Loss: 0.0317, Val R2: 0.9664, Val MAPE: 0.0799, Val RMSE: 24.0756, Val MAE: 15.8639, Val MSE: 579.6326\n",
      "Epoch [59/200], Train Loss: 0.0057, Val Loss: 0.0394, Val R2: 0.9583, Val MAPE: 0.0917, Val RMSE: 26.8178, Val MAE: 17.7252, Val MSE: 719.1924\n",
      "Epoch [60/200], Train Loss: 0.0063, Val Loss: 0.0359, Val R2: 0.9619, Val MAPE: 0.1080, Val RMSE: 25.6158, Val MAE: 17.6003, Val MSE: 656.1713\n",
      "Epoch [61/200], Train Loss: 0.0054, Val Loss: 0.0324, Val R2: 0.9657, Val MAPE: 0.0855, Val RMSE: 24.3091, Val MAE: 15.6700, Val MSE: 590.9311\n",
      "Epoch [62/200], Train Loss: 0.0048, Val Loss: 0.0294, Val R2: 0.9689, Val MAPE: 0.0903, Val RMSE: 23.1701, Val MAE: 15.5175, Val MSE: 536.8554\n",
      "Epoch [63/200], Train Loss: 0.0054, Val Loss: 0.0399, Val R2: 0.9577, Val MAPE: 0.0873, Val RMSE: 26.9933, Val MAE: 16.4969, Val MSE: 728.6379\n",
      "Epoch [64/200], Train Loss: 0.0068, Val Loss: 0.0257, Val R2: 0.9727, Val MAPE: 0.0996, Val RMSE: 21.6742, Val MAE: 15.1485, Val MSE: 469.7730\n",
      "Epoch [65/200], Train Loss: 0.0072, Val Loss: 0.0360, Val R2: 0.9618, Val MAPE: 0.1005, Val RMSE: 25.6492, Val MAE: 16.4159, Val MSE: 657.8802\n",
      "Epoch [66/200], Train Loss: 0.0042, Val Loss: 0.0254, Val R2: 0.9731, Val MAPE: 0.0800, Val RMSE: 21.5254, Val MAE: 14.6947, Val MSE: 463.3417\n",
      "Epoch [67/200], Train Loss: 0.0048, Val Loss: 0.0349, Val R2: 0.9630, Val MAPE: 0.0981, Val RMSE: 25.2606, Val MAE: 16.6236, Val MSE: 638.0992\n",
      "Epoch [68/200], Train Loss: 0.0030, Val Loss: 0.0303, Val R2: 0.9679, Val MAPE: 0.1045, Val RMSE: 23.5049, Val MAE: 16.0845, Val MSE: 552.4808\n",
      "Epoch [69/200], Train Loss: 0.0036, Val Loss: 0.0333, Val R2: 0.9647, Val MAPE: 0.0920, Val RMSE: 24.6708, Val MAE: 15.7173, Val MSE: 608.6472\n",
      "Epoch [70/200], Train Loss: 0.0031, Val Loss: 0.0261, Val R2: 0.9724, Val MAPE: 0.0803, Val RMSE: 21.8232, Val MAE: 14.1709, Val MSE: 476.2528\n",
      "Epoch [71/200], Train Loss: 0.0027, Val Loss: 0.0344, Val R2: 0.9635, Val MAPE: 0.0857, Val RMSE: 25.0738, Val MAE: 15.8426, Val MSE: 628.6931\n",
      "Epoch [72/200], Train Loss: 0.0032, Val Loss: 0.0312, Val R2: 0.9669, Val MAPE: 0.0834, Val RMSE: 23.8674, Val MAE: 15.0178, Val MSE: 569.6517\n",
      "Epoch [73/200], Train Loss: 0.0029, Val Loss: 0.0312, Val R2: 0.9669, Val MAPE: 0.0819, Val RMSE: 23.8727, Val MAE: 14.9375, Val MSE: 569.9042\n",
      "Epoch [74/200], Train Loss: 0.0033, Val Loss: 0.0317, Val R2: 0.9664, Val MAPE: 0.0811, Val RMSE: 24.0677, Val MAE: 15.1575, Val MSE: 579.2522\n",
      "Epoch [75/200], Train Loss: 0.0036, Val Loss: 0.0311, Val R2: 0.9670, Val MAPE: 0.0767, Val RMSE: 23.8478, Val MAE: 14.9603, Val MSE: 568.7195\n",
      "Epoch [76/200], Train Loss: 0.0027, Val Loss: 0.0340, Val R2: 0.9640, Val MAPE: 0.0797, Val RMSE: 24.9206, Val MAE: 15.7022, Val MSE: 621.0368\n",
      "Epoch [77/200], Train Loss: 0.0032, Val Loss: 0.0277, Val R2: 0.9707, Val MAPE: 0.0741, Val RMSE: 22.4779, Val MAE: 13.7272, Val MSE: 505.2552\n",
      "Epoch [78/200], Train Loss: 0.0023, Val Loss: 0.0316, Val R2: 0.9665, Val MAPE: 0.0978, Val RMSE: 24.0381, Val MAE: 15.2977, Val MSE: 577.8280\n",
      "Epoch [79/200], Train Loss: 0.0030, Val Loss: 0.0279, Val R2: 0.9705, Val MAPE: 0.0781, Val RMSE: 22.5534, Val MAE: 14.5922, Val MSE: 508.6552\n",
      "Epoch [80/200], Train Loss: 0.0023, Val Loss: 0.0329, Val R2: 0.9652, Val MAPE: 0.0800, Val RMSE: 24.4967, Val MAE: 15.7131, Val MSE: 600.0863\n",
      "Epoch [81/200], Train Loss: 0.0029, Val Loss: 0.0299, Val R2: 0.9684, Val MAPE: 0.0768, Val RMSE: 23.3555, Val MAE: 14.4590, Val MSE: 545.4794\n",
      "Epoch [82/200], Train Loss: 0.0023, Val Loss: 0.0318, Val R2: 0.9663, Val MAPE: 0.0761, Val RMSE: 24.1016, Val MAE: 14.5122, Val MSE: 580.8879\n",
      "Epoch [83/200], Train Loss: 0.0026, Val Loss: 0.0314, Val R2: 0.9668, Val MAPE: 0.0824, Val RMSE: 23.9313, Val MAE: 14.9047, Val MSE: 572.7074\n",
      "Epoch [84/200], Train Loss: 0.0028, Val Loss: 0.0272, Val R2: 0.9712, Val MAPE: 0.0744, Val RMSE: 22.2659, Val MAE: 13.8331, Val MSE: 495.7719\n",
      "Epoch [85/200], Train Loss: 0.0026, Val Loss: 0.0320, Val R2: 0.9661, Val MAPE: 0.0834, Val RMSE: 24.1715, Val MAE: 15.2040, Val MSE: 584.2631\n",
      "Epoch [86/200], Train Loss: 0.0019, Val Loss: 0.0296, Val R2: 0.9687, Val MAPE: 0.0831, Val RMSE: 23.2295, Val MAE: 14.8887, Val MSE: 539.6082\n",
      "Epoch [87/200], Train Loss: 0.0017, Val Loss: 0.0275, Val R2: 0.9709, Val MAPE: 0.0712, Val RMSE: 22.4016, Val MAE: 13.4711, Val MSE: 501.8319\n",
      "Epoch [88/200], Train Loss: 0.0020, Val Loss: 0.0296, Val R2: 0.9687, Val MAPE: 0.0802, Val RMSE: 23.2377, Val MAE: 14.3701, Val MSE: 539.9894\n",
      "Epoch [89/200], Train Loss: 0.0017, Val Loss: 0.0268, Val R2: 0.9716, Val MAPE: 0.0716, Val RMSE: 22.1241, Val MAE: 13.8971, Val MSE: 489.4738\n",
      "Epoch [90/200], Train Loss: 0.0017, Val Loss: 0.0293, Val R2: 0.9690, Val MAPE: 0.0723, Val RMSE: 23.1293, Val MAE: 14.1131, Val MSE: 534.9640\n",
      "Epoch [91/200], Train Loss: 0.0015, Val Loss: 0.0274, Val R2: 0.9710, Val MAPE: 0.0730, Val RMSE: 22.3575, Val MAE: 13.5555, Val MSE: 499.8574\n",
      "Epoch [92/200], Train Loss: 0.0015, Val Loss: 0.0298, Val R2: 0.9685, Val MAPE: 0.0702, Val RMSE: 23.3186, Val MAE: 13.5545, Val MSE: 543.7557\n",
      "Epoch [93/200], Train Loss: 0.0019, Val Loss: 0.0250, Val R2: 0.9735, Val MAPE: 0.0741, Val RMSE: 21.3575, Val MAE: 13.7501, Val MSE: 456.1430\n",
      "Epoch [94/200], Train Loss: 0.0019, Val Loss: 0.0311, Val R2: 0.9671, Val MAPE: 0.0731, Val RMSE: 23.8160, Val MAE: 14.5560, Val MSE: 567.2004\n",
      "Epoch [95/200], Train Loss: 0.0015, Val Loss: 0.0282, Val R2: 0.9702, Val MAPE: 0.0703, Val RMSE: 22.6784, Val MAE: 13.6814, Val MSE: 514.3100\n",
      "Epoch [96/200], Train Loss: 0.0013, Val Loss: 0.0276, Val R2: 0.9707, Val MAPE: 0.0741, Val RMSE: 22.4629, Val MAE: 13.6079, Val MSE: 504.5835\n",
      "Epoch [97/200], Train Loss: 0.0014, Val Loss: 0.0281, Val R2: 0.9702, Val MAPE: 0.0709, Val RMSE: 22.6495, Val MAE: 13.6526, Val MSE: 512.9988\n",
      "Epoch [98/200], Train Loss: 0.0015, Val Loss: 0.0254, Val R2: 0.9731, Val MAPE: 0.0698, Val RMSE: 21.5251, Val MAE: 13.3600, Val MSE: 463.3282\n",
      "Epoch [99/200], Train Loss: 0.0010, Val Loss: 0.0311, Val R2: 0.9671, Val MAPE: 0.0710, Val RMSE: 23.8272, Val MAE: 13.9710, Val MSE: 567.7366\n",
      "Epoch [100/200], Train Loss: 0.0014, Val Loss: 0.0247, Val R2: 0.9738, Val MAPE: 0.0683, Val RMSE: 21.2317, Val MAE: 12.9812, Val MSE: 450.7870\n",
      "Epoch [101/200], Train Loss: 0.0014, Val Loss: 0.0277, Val R2: 0.9707, Val MAPE: 0.0700, Val RMSE: 22.4770, Val MAE: 13.8327, Val MSE: 505.2173\n",
      "Epoch [102/200], Train Loss: 0.0015, Val Loss: 0.0297, Val R2: 0.9685, Val MAPE: 0.0702, Val RMSE: 23.2910, Val MAE: 13.6873, Val MSE: 542.4700\n",
      "Epoch [103/200], Train Loss: 0.0014, Val Loss: 0.0245, Val R2: 0.9740, Val MAPE: 0.0695, Val RMSE: 21.1697, Val MAE: 12.7901, Val MSE: 448.1562\n",
      "Epoch [104/200], Train Loss: 0.0016, Val Loss: 0.0308, Val R2: 0.9674, Val MAPE: 0.0758, Val RMSE: 23.7164, Val MAE: 14.9428, Val MSE: 562.4691\n",
      "Epoch [105/200], Train Loss: 0.0022, Val Loss: 0.0269, Val R2: 0.9715, Val MAPE: 0.0715, Val RMSE: 22.1624, Val MAE: 13.3952, Val MSE: 491.1737\n",
      "Epoch [106/200], Train Loss: 0.0014, Val Loss: 0.0245, Val R2: 0.9740, Val MAPE: 0.0758, Val RMSE: 21.1485, Val MAE: 13.3159, Val MSE: 447.2605\n",
      "Epoch [107/200], Train Loss: 0.0012, Val Loss: 0.0303, Val R2: 0.9679, Val MAPE: 0.0712, Val RMSE: 23.5049, Val MAE: 14.0659, Val MSE: 552.4822\n",
      "Epoch [108/200], Train Loss: 0.0011, Val Loss: 0.0254, Val R2: 0.9730, Val MAPE: 0.0722, Val RMSE: 21.5557, Val MAE: 13.1210, Val MSE: 464.6487\n",
      "Epoch [109/200], Train Loss: 0.0013, Val Loss: 0.0266, Val R2: 0.9718, Val MAPE: 0.0697, Val RMSE: 22.0375, Val MAE: 13.1147, Val MSE: 485.6534\n",
      "Epoch [110/200], Train Loss: 0.0010, Val Loss: 0.0274, Val R2: 0.9709, Val MAPE: 0.0705, Val RMSE: 22.3796, Val MAE: 13.6706, Val MSE: 500.8485\n",
      "Epoch [111/200], Train Loss: 0.0010, Val Loss: 0.0276, Val R2: 0.9708, Val MAPE: 0.0687, Val RMSE: 22.4482, Val MAE: 13.1056, Val MSE: 503.9203\n",
      "Epoch [112/200], Train Loss: 0.0011, Val Loss: 0.0282, Val R2: 0.9702, Val MAPE: 0.0723, Val RMSE: 22.6771, Val MAE: 13.8874, Val MSE: 514.2518\n",
      "Epoch [113/200], Train Loss: 0.0012, Val Loss: 0.0263, Val R2: 0.9721, Val MAPE: 0.0670, Val RMSE: 21.9105, Val MAE: 13.0301, Val MSE: 480.0716\n",
      "Epoch [114/200], Train Loss: 0.0011, Val Loss: 0.0238, Val R2: 0.9747, Val MAPE: 0.0699, Val RMSE: 20.8635, Val MAE: 12.6818, Val MSE: 435.2863\n",
      "Epoch [115/200], Train Loss: 0.0010, Val Loss: 0.0288, Val R2: 0.9695, Val MAPE: 0.0686, Val RMSE: 22.9272, Val MAE: 13.6417, Val MSE: 525.6561\n",
      "Epoch [116/200], Train Loss: 0.0010, Val Loss: 0.0257, Val R2: 0.9728, Val MAPE: 0.0692, Val RMSE: 21.6441, Val MAE: 13.1261, Val MSE: 468.4684\n",
      "Epoch [117/200], Train Loss: 0.0009, Val Loss: 0.0243, Val R2: 0.9743, Val MAPE: 0.0662, Val RMSE: 21.0455, Val MAE: 12.6792, Val MSE: 442.9111\n",
      "Epoch [118/200], Train Loss: 0.0009, Val Loss: 0.0279, Val R2: 0.9705, Val MAPE: 0.0674, Val RMSE: 22.5593, Val MAE: 13.3471, Val MSE: 508.9234\n",
      "Epoch [119/200], Train Loss: 0.0009, Val Loss: 0.0249, Val R2: 0.9736, Val MAPE: 0.0672, Val RMSE: 21.3257, Val MAE: 12.8209, Val MSE: 454.7860\n",
      "Epoch [120/200], Train Loss: 0.0008, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0668, Val RMSE: 21.4636, Val MAE: 12.8772, Val MSE: 460.6841\n",
      "Epoch [121/200], Train Loss: 0.0009, Val Loss: 0.0279, Val R2: 0.9704, Val MAPE: 0.0716, Val RMSE: 22.5829, Val MAE: 13.3624, Val MSE: 509.9873\n",
      "Epoch [122/200], Train Loss: 0.0008, Val Loss: 0.0268, Val R2: 0.9716, Val MAPE: 0.0692, Val RMSE: 22.1225, Val MAE: 13.2077, Val MSE: 489.4056\n",
      "Epoch [123/200], Train Loss: 0.0007, Val Loss: 0.0244, Val R2: 0.9741, Val MAPE: 0.0681, Val RMSE: 21.1263, Val MAE: 12.8081, Val MSE: 446.3224\n",
      "Epoch [124/200], Train Loss: 0.0008, Val Loss: 0.0261, Val R2: 0.9724, Val MAPE: 0.0657, Val RMSE: 21.8264, Val MAE: 12.7707, Val MSE: 476.3912\n",
      "Epoch [125/200], Train Loss: 0.0007, Val Loss: 0.0279, Val R2: 0.9704, Val MAPE: 0.0681, Val RMSE: 22.5703, Val MAE: 13.0611, Val MSE: 509.4200\n",
      "Epoch [126/200], Train Loss: 0.0007, Val Loss: 0.0255, Val R2: 0.9730, Val MAPE: 0.0671, Val RMSE: 21.5664, Val MAE: 12.9841, Val MSE: 465.1079\n",
      "Epoch [127/200], Train Loss: 0.0007, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0667, Val RMSE: 21.4510, Val MAE: 12.7505, Val MSE: 460.1454\n",
      "Epoch [128/200], Train Loss: 0.0007, Val Loss: 0.0263, Val R2: 0.9721, Val MAPE: 0.0677, Val RMSE: 21.9149, Val MAE: 13.0749, Val MSE: 480.2623\n",
      "Epoch [129/200], Train Loss: 0.0006, Val Loss: 0.0266, Val R2: 0.9718, Val MAPE: 0.0656, Val RMSE: 22.0464, Val MAE: 12.7918, Val MSE: 486.0431\n",
      "Epoch [130/200], Train Loss: 0.0006, Val Loss: 0.0256, Val R2: 0.9729, Val MAPE: 0.0662, Val RMSE: 21.6261, Val MAE: 12.8534, Val MSE: 467.6888\n",
      "Epoch [131/200], Train Loss: 0.0006, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0663, Val RMSE: 21.4993, Val MAE: 12.7764, Val MSE: 462.2187\n",
      "Epoch [132/200], Train Loss: 0.0006, Val Loss: 0.0267, Val R2: 0.9718, Val MAPE: 0.0659, Val RMSE: 22.0601, Val MAE: 12.9204, Val MSE: 486.6472\n",
      "Epoch [133/200], Train Loss: 0.0006, Val Loss: 0.0253, Val R2: 0.9731, Val MAPE: 0.0663, Val RMSE: 21.5128, Val MAE: 12.7582, Val MSE: 462.8020\n",
      "Epoch [134/200], Train Loss: 0.0006, Val Loss: 0.0250, Val R2: 0.9736, Val MAPE: 0.0646, Val RMSE: 21.3487, Val MAE: 12.5406, Val MSE: 455.7659\n",
      "Epoch [135/200], Train Loss: 0.0006, Val Loss: 0.0264, Val R2: 0.9721, Val MAPE: 0.0655, Val RMSE: 21.9461, Val MAE: 12.9510, Val MSE: 481.6311\n",
      "Epoch [136/200], Train Loss: 0.0006, Val Loss: 0.0257, Val R2: 0.9728, Val MAPE: 0.0657, Val RMSE: 21.6653, Val MAE: 12.7944, Val MSE: 469.3839\n",
      "Epoch [137/200], Train Loss: 0.0006, Val Loss: 0.0243, Val R2: 0.9743, Val MAPE: 0.0649, Val RMSE: 21.0482, Val MAE: 12.5700, Val MSE: 443.0250\n",
      "Epoch [138/200], Train Loss: 0.0006, Val Loss: 0.0254, Val R2: 0.9731, Val MAPE: 0.0652, Val RMSE: 21.5180, Val MAE: 12.5931, Val MSE: 463.0234\n",
      "Epoch [139/200], Train Loss: 0.0005, Val Loss: 0.0265, Val R2: 0.9720, Val MAPE: 0.0659, Val RMSE: 21.9865, Val MAE: 12.9050, Val MSE: 483.4055\n",
      "Epoch [140/200], Train Loss: 0.0006, Val Loss: 0.0256, Val R2: 0.9728, Val MAPE: 0.0656, Val RMSE: 21.6334, Val MAE: 12.6877, Val MSE: 468.0049\n",
      "Epoch [141/200], Train Loss: 0.0006, Val Loss: 0.0255, Val R2: 0.9730, Val MAPE: 0.0649, Val RMSE: 21.5701, Val MAE: 12.7099, Val MSE: 465.2686\n",
      "Epoch [142/200], Train Loss: 0.0005, Val Loss: 0.0258, Val R2: 0.9727, Val MAPE: 0.0649, Val RMSE: 21.6926, Val MAE: 12.7874, Val MSE: 470.5692\n",
      "Epoch [143/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0646, Val RMSE: 21.5084, Val MAE: 12.5668, Val MSE: 462.6125\n",
      "Epoch [144/200], Train Loss: 0.0005, Val Loss: 0.0256, Val R2: 0.9729, Val MAPE: 0.0643, Val RMSE: 21.6060, Val MAE: 12.5061, Val MSE: 466.8174\n",
      "Epoch [145/200], Train Loss: 0.0005, Val Loss: 0.0262, Val R2: 0.9723, Val MAPE: 0.0651, Val RMSE: 21.8658, Val MAE: 12.7542, Val MSE: 478.1128\n",
      "Epoch [146/200], Train Loss: 0.0006, Val Loss: 0.0261, Val R2: 0.9723, Val MAPE: 0.0655, Val RMSE: 21.8411, Val MAE: 12.8379, Val MSE: 477.0338\n",
      "Epoch [147/200], Train Loss: 0.0005, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0650, Val RMSE: 21.3962, Val MAE: 12.6239, Val MSE: 457.7992\n",
      "Epoch [148/200], Train Loss: 0.0005, Val Loss: 0.0249, Val R2: 0.9736, Val MAPE: 0.0645, Val RMSE: 21.3232, Val MAE: 12.5420, Val MSE: 454.6772\n",
      "Epoch [149/200], Train Loss: 0.0005, Val Loss: 0.0255, Val R2: 0.9730, Val MAPE: 0.0646, Val RMSE: 21.5614, Val MAE: 12.6326, Val MSE: 464.8943\n",
      "Epoch [150/200], Train Loss: 0.0005, Val Loss: 0.0259, Val R2: 0.9726, Val MAPE: 0.0644, Val RMSE: 21.7409, Val MAE: 12.6458, Val MSE: 472.6667\n",
      "Epoch [151/200], Train Loss: 0.0005, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0641, Val RMSE: 21.4399, Val MAE: 12.4823, Val MSE: 459.6689\n",
      "Epoch [152/200], Train Loss: 0.0005, Val Loss: 0.0250, Val R2: 0.9736, Val MAPE: 0.0641, Val RMSE: 21.3457, Val MAE: 12.5731, Val MSE: 455.6371\n",
      "Epoch [153/200], Train Loss: 0.0005, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0645, Val RMSE: 21.4635, Val MAE: 12.6220, Val MSE: 460.6838\n",
      "Epoch [154/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0647, Val RMSE: 21.4439, Val MAE: 12.5832, Val MSE: 459.8395\n",
      "Epoch [155/200], Train Loss: 0.0005, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0644, Val RMSE: 21.4254, Val MAE: 12.5584, Val MSE: 459.0465\n",
      "Epoch [156/200], Train Loss: 0.0005, Val Loss: 0.0255, Val R2: 0.9730, Val MAPE: 0.0645, Val RMSE: 21.5684, Val MAE: 12.6489, Val MSE: 465.1956\n",
      "Epoch [157/200], Train Loss: 0.0005, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0643, Val RMSE: 21.4482, Val MAE: 12.5381, Val MSE: 460.0270\n",
      "Epoch [158/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0648, Val RMSE: 21.4764, Val MAE: 12.5318, Val MSE: 461.2346\n",
      "Epoch [159/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0643, Val RMSE: 21.4947, Val MAE: 12.5767, Val MSE: 462.0201\n",
      "Epoch [160/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0641, Val RMSE: 21.4258, Val MAE: 12.6100, Val MSE: 459.0635\n",
      "Epoch [161/200], Train Loss: 0.0004, Val Loss: 0.0248, Val R2: 0.9737, Val MAPE: 0.0638, Val RMSE: 21.2705, Val MAE: 12.4723, Val MSE: 452.4350\n",
      "Epoch [162/200], Train Loss: 0.0005, Val Loss: 0.0247, Val R2: 0.9738, Val MAPE: 0.0639, Val RMSE: 21.2430, Val MAE: 12.3912, Val MSE: 451.2639\n",
      "Epoch [163/200], Train Loss: 0.0005, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0641, Val RMSE: 21.3918, Val MAE: 12.5023, Val MSE: 457.6099\n",
      "Epoch [164/200], Train Loss: 0.0005, Val Loss: 0.0256, Val R2: 0.9729, Val MAPE: 0.0643, Val RMSE: 21.5985, Val MAE: 12.6675, Val MSE: 466.4939\n",
      "Epoch [165/200], Train Loss: 0.0005, Val Loss: 0.0254, Val R2: 0.9731, Val MAPE: 0.0645, Val RMSE: 21.5320, Val MAE: 12.6095, Val MSE: 463.6259\n",
      "Epoch [166/200], Train Loss: 0.0005, Val Loss: 0.0254, Val R2: 0.9731, Val MAPE: 0.0646, Val RMSE: 21.5216, Val MAE: 12.5551, Val MSE: 463.1808\n",
      "Epoch [167/200], Train Loss: 0.0005, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0642, Val RMSE: 21.4486, Val MAE: 12.5243, Val MSE: 460.0418\n",
      "Epoch [168/200], Train Loss: 0.0005, Val Loss: 0.0250, Val R2: 0.9735, Val MAPE: 0.0642, Val RMSE: 21.3828, Val MAE: 12.5577, Val MSE: 457.2229\n",
      "Epoch [169/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0642, Val RMSE: 21.4325, Val MAE: 12.5476, Val MSE: 459.3540\n",
      "Epoch [170/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0642, Val RMSE: 21.4972, Val MAE: 12.5314, Val MSE: 462.1290\n",
      "Epoch [171/200], Train Loss: 0.0004, Val Loss: 0.0254, Val R2: 0.9731, Val MAPE: 0.0642, Val RMSE: 21.5406, Val MAE: 12.5530, Val MSE: 463.9964\n",
      "Epoch [172/200], Train Loss: 0.0004, Val Loss: 0.0255, Val R2: 0.9730, Val MAPE: 0.0642, Val RMSE: 21.5741, Val MAE: 12.5817, Val MSE: 465.4425\n",
      "Epoch [173/200], Train Loss: 0.0005, Val Loss: 0.0254, Val R2: 0.9731, Val MAPE: 0.0641, Val RMSE: 21.5277, Val MAE: 12.5617, Val MSE: 463.4425\n",
      "Epoch [174/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0641, Val RMSE: 21.5016, Val MAE: 12.5436, Val MSE: 462.3190\n",
      "Epoch [175/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0640, Val RMSE: 21.4643, Val MAE: 12.5123, Val MSE: 460.7167\n",
      "Epoch [176/200], Train Loss: 0.0005, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0641, Val RMSE: 21.4366, Val MAE: 12.5065, Val MSE: 459.5277\n",
      "Epoch [177/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0640, Val RMSE: 21.4408, Val MAE: 12.5010, Val MSE: 459.7071\n",
      "Epoch [178/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0639, Val RMSE: 21.4422, Val MAE: 12.4883, Val MSE: 459.7692\n",
      "Epoch [179/200], Train Loss: 0.0005, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0639, Val RMSE: 21.4615, Val MAE: 12.4865, Val MSE: 460.5960\n",
      "Epoch [180/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0639, Val RMSE: 21.4645, Val MAE: 12.4933, Val MSE: 460.7228\n",
      "Epoch [181/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0638, Val RMSE: 21.4732, Val MAE: 12.5012, Val MSE: 461.0977\n",
      "Epoch [182/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0639, Val RMSE: 21.4874, Val MAE: 12.5098, Val MSE: 461.7089\n",
      "Epoch [183/200], Train Loss: 0.0004, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0638, Val RMSE: 21.4896, Val MAE: 12.5124, Val MSE: 461.8017\n",
      "Epoch [184/200], Train Loss: 0.0005, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0639, Val RMSE: 21.4936, Val MAE: 12.5125, Val MSE: 461.9739\n",
      "Epoch [185/200], Train Loss: 0.0004, Val Loss: 0.0253, Val R2: 0.9732, Val MAPE: 0.0639, Val RMSE: 21.4840, Val MAE: 12.5096, Val MSE: 461.5617\n",
      "Epoch [186/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0639, Val RMSE: 21.4681, Val MAE: 12.5066, Val MSE: 460.8813\n",
      "Epoch [187/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0638, Val RMSE: 21.4496, Val MAE: 12.5019, Val MSE: 460.0839\n",
      "Epoch [188/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0639, Val RMSE: 21.4379, Val MAE: 12.5044, Val MSE: 459.5828\n",
      "Epoch [189/200], Train Loss: 0.0004, Val Loss: 0.0252, Val R2: 0.9733, Val MAPE: 0.0639, Val RMSE: 21.4328, Val MAE: 12.5043, Val MSE: 459.3660\n",
      "Epoch [190/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4278, Val MAE: 12.5046, Val MSE: 459.1516\n",
      "Epoch [191/200], Train Loss: 0.0005, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4277, Val MAE: 12.5070, Val MSE: 459.1483\n",
      "Epoch [192/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4245, Val MAE: 12.5070, Val MSE: 459.0097\n",
      "Epoch [193/200], Train Loss: 0.0005, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4248, Val MAE: 12.5091, Val MSE: 459.0229\n",
      "Epoch [194/200], Train Loss: 0.0005, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4231, Val MAE: 12.5086, Val MSE: 458.9500\n",
      "Epoch [195/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4231, Val MAE: 12.5075, Val MSE: 458.9473\n",
      "Epoch [196/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4226, Val MAE: 12.5065, Val MSE: 458.9297\n",
      "Epoch [197/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4224, Val MAE: 12.5059, Val MSE: 458.9197\n",
      "Epoch [198/200], Train Loss: 0.0005, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4223, Val MAE: 12.5055, Val MSE: 458.9159\n",
      "Epoch [199/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4224, Val MAE: 12.5055, Val MSE: 458.9184\n",
      "Epoch [200/200], Train Loss: 0.0004, Val Loss: 0.0251, Val R2: 0.9734, Val MAPE: 0.0639, Val RMSE: 21.4224, Val MAE: 12.5056, Val MSE: 458.9192\n",
      "Training complete!\n",
      "Test (Normalized) Loss: 0.0251, Test R2: 0.9734, Test MAPE: 0.0639, Test RMSE: 21.4224, Test MAE: 12.5056, Test MSE: 458.9192\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"data_dir\": \"./data_cropped_con\",\n",
    "    \"lr\": 0.002,\n",
    "    \"weight_decay\": 0.002,\n",
    "    \"num_epochs\": 200,\n",
    "    \"omega\": 32,\n",
    "    \"film_hidden_size\": 32,\n",
    "    \"head_hidden_size\": 1024,\n",
    "    \"mse\": True,\n",
    "    \"width\": 2,\n",
    "    \"dropout\": 0.0,\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\"\n",
    "    }\n",
    "\n",
    "test_results = train_cross_val(config, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>denormed_loss</th>\n",
       "      <th>r2</th>\n",
       "      <th>absolute_percentage_error</th>\n",
       "      <th>root_mse</th>\n",
       "      <th>absolute_error</th>\n",
       "      <th>squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.016251</td>\n",
       "      <td>287.194919</td>\n",
       "      <td>0.984632</td>\n",
       "      <td>0.076876</td>\n",
       "      <td>15.760473</td>\n",
       "      <td>9.912320</td>\n",
       "      <td>287.194916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Deviation</th>\n",
       "      <td>0.014195</td>\n",
       "      <td>239.923802</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>6.964409</td>\n",
       "      <td>3.427573</td>\n",
       "      <td>239.923813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        loss  denormed_loss        r2  \\\n",
       "Mean                0.016251     287.194919  0.984632   \n",
       "Standard Deviation  0.014195     239.923802  0.010969   \n",
       "\n",
       "                    absolute_percentage_error   root_mse  absolute_error  \\\n",
       "Mean                                 0.076876  15.760473        9.912320   \n",
       "Standard Deviation                   0.025206   6.964409        3.427573   \n",
       "\n",
       "                    squared_error  \n",
       "Mean                   287.194916  \n",
       "Standard Deviation     239.923813  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test_results)\n",
    "\n",
    "mean_summary = df.mean()\n",
    "std_summary = df.std()\n",
    "\n",
    "summary = pd.DataFrame({'Mean': mean_summary, 'Standard Deviation': std_summary}).T\n",
    "\n",
    "# summary.to_csv('./results/SmallSineMLPHighestConcentration.csv')\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
